{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5bef62-be4a-4a51-8607-b00b63490a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.json import JSON\n",
    "from rich.markdown import Markdown\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d8ff51-bd3f-446c-8e80-906cbc15a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7a654c-7a64-48f5-83cd-6499047981c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsyn_path=\"../ToolMind/graph_syn_datasets/graphsyn.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bf2c17-314f-41f2-8b48-5a2b9d5a085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '/dfs/data/.cache/huggingface/datasets/generator'\n",
    "if os.path.exists(cache_path):\n",
    "    print(f\"正在清理缓存: {cache_path}\")\n",
    "    try:\n",
    "        shutil.rmtree(cache_path)\n",
    "    except Exception as e:\n",
    "        print(f\"缓存清理失败 (通常不影响运行): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9debeebc-3d3f-400e-8a11-63b78087cecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def robust_data_generator(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                row = json.loads(line)\n",
    "                \n",
    "                # --- 深度清洗逻辑 ---\n",
    "                if \"conversations\" in row:\n",
    "                    for conv in row[\"conversations\"]:\n",
    "                        # 1. 确保 content 是字符串 (有些数据集里 content 可能是 null)\n",
    "                        if conv.get(\"content\") is None:\n",
    "                            conv[\"content\"] = \"\"\n",
    "                            \n",
    "                        # 2. 处理 tool_calls\n",
    "                        if \"tool_calls\" in conv:\n",
    "                            tc_data = conv[\"tool_calls\"]\n",
    "                            \n",
    "                            # 情况 A: tool_calls 是 None -> 转为空列表\n",
    "                            if tc_data is None:\n",
    "                                conv[\"tool_calls\"] = []\n",
    "                                continue\n",
    "                                \n",
    "                            # 情况 B: tool_calls 是列表 -> 检查内部\n",
    "                            if isinstance(tc_data, list):\n",
    "                                for tc in tc_data:\n",
    "                                    # 检查 function.arguments\n",
    "                                    if \"function\" in tc:\n",
    "                                        func = tc[\"function\"]\n",
    "                                        args = func.get(\"arguments\")\n",
    "                                        \n",
    "                                        # === 核心修复 ===\n",
    "                                        # 无论 arguments 是字典还是字符串，统一转为字符串\n",
    "                                        # 这样可以避免 \"cannot mix struct and non-struct\"\n",
    "                                        if isinstance(args, dict):\n",
    "                                            func[\"arguments\"] = json.dumps(args, ensure_ascii=False)\n",
    "                                        elif args is None:\n",
    "                                            func[\"arguments\"] = \"{}\"\n",
    "                                        # 如果已经是 string，保持不变\n",
    "                            \n",
    "                yield row\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2064015e-9a28-4557-9485-481a86ea7d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 999 examples [00:00, 4620.23 examples/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: '/dfs/data/.cache/huggingface/datasets/generator/default-554e5d0fbe88b8bb/0.0.0.incomplete'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1626\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[39m\n\u001b[32m   1625\u001b[39m example = \u001b[38;5;28mself\u001b[39m.info.features.encode_example(record) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m record\n\u001b[32m-> \u001b[39m\u001b[32m1626\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m num_examples_progress_update += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:552\u001b[39m, in \u001b[36mArrowWriter.write\u001b[39m\u001b[34m(self, example, key, writer_batch_size)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28mself\u001b[39m.hkey_record = []\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:510\u001b[39m, in \u001b[36mArrowWriter.write_examples_on_file\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    506\u001b[39m         batch_examples[col] = [\n\u001b[32m    507\u001b[39m             row[\u001b[32m0\u001b[39m][col].to_pylist()[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[32m0\u001b[39m][col], (pa.Array, pa.ChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[32m0\u001b[39m][col]\n\u001b[32m    508\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_examples\n\u001b[32m    509\u001b[39m         ]\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28mself\u001b[39m.current_examples = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:626\u001b[39m, in \u001b[36mArrowWriter.write_batch\u001b[39m\u001b[34m(self, batch_examples, writer_batch_size, try_original_type)\u001b[39m\n\u001b[32m    625\u001b[39m typed_sequence = OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m=col_type, try_type=col_try_type, col=col)\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m arrays.append(\u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    627\u001b[39m inferred_features[col] = typed_sequence.get_inferred_type()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:256\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:118\u001b[39m, in \u001b[36mpyarrow.lib._handle_arrow_array_protocol\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:243\u001b[39m, in \u001b[36mTypedSequence.__arrow_array__\u001b[39m\u001b[34m(self, type)\u001b[39m\n\u001b[32m    242\u001b[39m     trying_cast_to_python_objects = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     out = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:375\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:46\u001b[39m, in \u001b[36mpyarrow.lib._sequence_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowInvalid\u001b[39m: cannot mix list and non-list, non-null values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1635\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[39m\n\u001b[32m   1634\u001b[39m num_shards = shard_id + \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1635\u001b[39m num_examples, num_bytes = \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1636\u001b[39m writer.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:657\u001b[39m, in \u001b[36mArrowWriter.finalize\u001b[39m\u001b[34m(self, close_stream)\u001b[39m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28mself\u001b[39m.hkey_record = []\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m# If schema is known, infer features even if no examples were written\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:510\u001b[39m, in \u001b[36mArrowWriter.write_examples_on_file\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    506\u001b[39m         batch_examples[col] = [\n\u001b[32m    507\u001b[39m             row[\u001b[32m0\u001b[39m][col].to_pylist()[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[32m0\u001b[39m][col], (pa.Array, pa.ChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[32m0\u001b[39m][col]\n\u001b[32m    508\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_examples\n\u001b[32m    509\u001b[39m         ]\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28mself\u001b[39m.current_examples = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:626\u001b[39m, in \u001b[36mArrowWriter.write_batch\u001b[39m\u001b[34m(self, batch_examples, writer_batch_size, try_original_type)\u001b[39m\n\u001b[32m    625\u001b[39m typed_sequence = OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m=col_type, try_type=col_try_type, col=col)\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m arrays.append(\u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    627\u001b[39m inferred_features[col] = typed_sequence.get_inferred_type()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:256\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:118\u001b[39m, in \u001b[36mpyarrow.lib._handle_arrow_array_protocol\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_writer.py:243\u001b[39m, in \u001b[36mTypedSequence.__arrow_array__\u001b[39m\u001b[34m(self, type)\u001b[39m\n\u001b[32m    242\u001b[39m     trying_cast_to_python_objects = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     out = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:375\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/array.pxi:46\u001b[39m, in \u001b[36mpyarrow.lib._sequence_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowInvalid\u001b[39m: cannot mix list and non-list, non-null values",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetGenerationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:890\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[39m\u001b[34m(dirname)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m tmp_dir\n\u001b[32m    891\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(dirname):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:925\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1649\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[39m\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, **prepare_splits_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1649\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1001\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    999\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1000\u001b[39m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1487\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split\u001b[39m\u001b[34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[39m\n\u001b[32m   1486\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:1644\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[39m\n\u001b[32m   1643\u001b[39m         e = e.__context__\n\u001b[32m-> \u001b[39m\u001b[32m1644\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[33m\"\u001b[39m\u001b[33mAn error occurred while generating the dataset\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer._features, num_shards, shard_lengths)\n",
      "\u001b[31mDatasetGenerationError\u001b[39m: An error occurred while generating the dataset",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobust_data_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphsyn_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m console.print(ds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/arrow_dataset.py:1114\u001b[39m, in \u001b[36mDataset.from_generator\u001b[39m\u001b[34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, split, **kwargs)\u001b[39m\n\u001b[32m   1052\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a Dataset from a generator.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \n\u001b[32m   1054\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1101\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m   1102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/io/generator.py:49\u001b[39m, in \u001b[36mGeneratorDatasetInputStream.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     46\u001b[39m     verification_mode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     47\u001b[39m     base_path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m.builder.as_dataset(\n\u001b[32m     57\u001b[39m         split=\u001b[38;5;28mself\u001b[39m.builder.config.split, verification_mode=verification_mode, in_memory=\u001b[38;5;28mself\u001b[39m.keep_in_memory\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:916\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28mself\u001b[39m._check_manual_download(dl_manager)\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# Create a tmp dir and rename to self._output_dir on successful exit.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mincomplete_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtmp_output_dir\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Temporarily assign _output_dir to tmp_data_dir to avoid having to forward\u001b[39;49;00m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# it to every sub function.\u001b[39;49;00m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtemporary_assignment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_output_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_output_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_format\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dfs/data/uv-venv/modelscope/lib/python3.12/site-packages/datasets/builder.py:897\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[39m\u001b[34m(dirname)\u001b[39m\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(tmp_dir):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m         \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:796\u001b[39m, in \u001b[36mrmtree\u001b[39m\u001b[34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[39m\n\u001b[32m    794\u001b[39m         os.rmdir(path, dir_fd=dir_fd)\n\u001b[32m    795\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m         \u001b[43monexc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    798\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    799\u001b[39m         \u001b[38;5;66;03m# symlinks to directories are forbidden, see bug #1669\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:794\u001b[39m, in \u001b[36mrmtree\u001b[39m\u001b[34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[39m\n\u001b[32m    792\u001b[39m fd_closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    796\u001b[39m     onexc(os.rmdir, path, err)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 39] Directory not empty: '/dfs/data/.cache/huggingface/datasets/generator/default-554e5d0fbe88b8bb/0.0.0.incomplete'"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_generator(robust_data_generator, gen_kwargs={\"file_path\": graphsyn_path})\n",
    "\n",
    "console.print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e49a6-d8d4-49da-812f-2c0b7f844107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "modelscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
