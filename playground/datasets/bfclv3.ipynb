{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f196270-c372-407f-a176-56e21fc91aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨åŠ è½½å…¨é‡æ•°æ®...\n",
      "ğŸš€ å¼€å§‹å…¨é‡è¯„æµ‹ (å…± 200 æ¡æ•°æ®)...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Mock Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 558.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âŒ è¿è¡Œæ—¶å´©æºƒ ID multi_turn_base_154: list index out of range\n",
      "\n",
      "==================================================\n",
      "ğŸ“Š è¯„æµ‹å®ŒæˆæŠ¥å‘Š\n",
      "Total: 200\n",
      "Passed: 199\n",
      "Failed: 1\n",
      "Accuracy: 99.50%\n",
      "\n",
      "âŒ å¤±è´¥ç”¨ä¾‹åˆ—è¡¨:\n",
      "{'id': 'multi_turn_base_154', 'error': 'list index out of range'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡ï¼Œè®©ä½ çŸ¥é“è·‘åˆ°äº†å“ªé‡Œ\n",
    "\n",
    "# --- å¯¼å…¥ BFCL æ ¸å¿ƒç»„ä»¶ ---\n",
    "from bfcl_eval.eval_checker.multi_turn_eval.multi_turn_utils import execute_multi_turn_func_call\n",
    "from bfcl_eval.eval_checker.multi_turn_eval.multi_turn_checker import multi_turn_checker\n",
    "\n",
    "# --- 1. å¥å£®çš„æ•°æ®åŠ è½½å™¨ ---\n",
    "def smart_load_data(file_path):\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        print(f\"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}\")\n",
    "        return None\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read().strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "    except json.JSONDecodeError:\n",
    "        pass \n",
    "\n",
    "    try:\n",
    "        data = []\n",
    "        lines = content.splitlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if not line: continue \n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        if len(data) > 0:\n",
    "            return data\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"âŒ é”™è¯¯ï¼šæ— æ³•è§£ææ–‡ä»¶æ•°æ®ã€‚\")\n",
    "    return None\n",
    "\n",
    "# --- 2. æ¨¡æ‹Ÿ LLM (ä½œå¼Šæ¨¡å¼ï¼šç›´æ¥è¿”å›ç­”æ¡ˆ) ---\n",
    "def mock_llm_inference(history, current_turn_ground_truth):\n",
    "    # ç›´æ¥è¿”å›æ ‡å‡†ç­”æ¡ˆï¼Œæ¨¡æ‹Ÿä¸€ä¸ªå®Œç¾æ¨¡å‹\n",
    "    return current_turn_ground_truth\n",
    "\n",
    "# --- 3. ReAct Agent (å¢åŠ  verbose å‚æ•°æ§åˆ¶æ—¥å¿—) ---\n",
    "# --- 3. ReAct Agent (ä¿®å¤ç‰ˆ) ---\n",
    "def run_react_agent(test_entry, ground_truth_turns, verbose=False):\n",
    "    test_id = test_entry[\"id\"]\n",
    "    initial_config = test_entry[\"initial_config\"]\n",
    "    involved_classes = test_entry[\"involved_classes\"]\n",
    "    turns = test_entry[\"question\"]\n",
    "    \n",
    "    all_turns_decoded_results = []\n",
    "    history = [] \n",
    "    \n",
    "    # 1. åˆå§‹åŒ–ç¯å¢ƒ\n",
    "    _, involved_instances = execute_multi_turn_func_call(\n",
    "        func_call_list=[], \n",
    "        initial_config=initial_config,\n",
    "        involved_classes=involved_classes,\n",
    "        model_name=\"demo_runner\",\n",
    "        test_entry_id=test_id\n",
    "    )\n",
    "\n",
    "    # 2. å¤šè½®å¾ªç¯\n",
    "    for turn_idx, user_turn in enumerate(turns):\n",
    "        user_msg = user_turn[0]\n",
    "        history.append(user_msg)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ‘¤ Turn {turn_idx}: {user_msg['content']}\")\n",
    "        \n",
    "        # [ä¿®å¤ç‚¹] å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç­”æ¡ˆé•¿åº¦å°äºé—®é¢˜é•¿åº¦\n",
    "        if turn_idx < len(ground_truth_turns):\n",
    "            current_ground_truth = ground_truth_turns[turn_idx]\n",
    "        else:\n",
    "            # å¦‚æœæ²¡æœ‰å¯¹åº”çš„ç­”æ¡ˆï¼Œé€šå¸¸æ„å‘³ç€è¿™ä¸€è½®ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œæˆ–è€…æ•°æ®æœ‰é—®é¢˜\n",
    "            # è¿™é‡Œæˆ‘ä»¬é»˜è®¤ä¸åšæ“ä½œï¼Œæˆ–è€…æ‰“ä¸ªæ—¥å¿—\n",
    "            if verbose: print(f\"âš ï¸ Warning: Turn {turn_idx} æ²¡æœ‰å¯¹åº”çš„ Ground Truthï¼Œè·³è¿‡å·¥å…·è°ƒç”¨ã€‚\")\n",
    "            current_ground_truth = [] # å‡å®šä¸ºç©º\n",
    "\n",
    "        current_turn_steps_decoded = []\n",
    "        \n",
    "        # 3. æ¨¡æ‹Ÿæ¨ç†\n",
    "        func_call_strs = mock_llm_inference(history, current_ground_truth)\n",
    "        \n",
    "        step_decoded = []\n",
    "        for call_str in func_call_strs:\n",
    "            step_decoded.append(call_str)\n",
    "        current_turn_steps_decoded.append(step_decoded)\n",
    "        \n",
    "        # 4. æ‰§è¡Œå·¥å…·\n",
    "        if func_call_strs:\n",
    "            if verbose: print(f\"âš¡ æ‰§è¡Œ: {func_call_strs}\")\n",
    "            execution_results, _ = execute_multi_turn_func_call(\n",
    "                func_call_list=func_call_strs,\n",
    "                initial_config=initial_config,\n",
    "                involved_classes=involved_classes,\n",
    "                model_name=\"demo_runner\",\n",
    "                test_entry_id=test_id\n",
    "            )\n",
    "            for exec_res in execution_results:\n",
    "                history.append({\"role\": \"tool\", \"content\": str(exec_res)})\n",
    "\n",
    "        all_turns_decoded_results.append(current_turn_steps_decoded)\n",
    "\n",
    "    return all_turns_decoded_results\n",
    "\n",
    "# --- 4. ä¸»å…¥å£ (å…¨é‡è¿è¡Œç‰ˆ) ---\n",
    "def main():\n",
    "    # âš ï¸ è¯·ç¡®è®¤è·¯å¾„æ­£ç¡®\n",
    "    prompt_file = \"/dfs/data/work/gorilla/berkeley-function-call-leaderboard/bfcl_eval/data/BFCL_v3_multi_turn_base.json\"\n",
    "    answer_file = \"/dfs/data/work/gorilla/berkeley-function-call-leaderboard/bfcl_eval/data/possible_answer/BFCL_v3_multi_turn_base.json\"\n",
    "    \n",
    "    print(f\"ğŸ“‚ æ­£åœ¨åŠ è½½å…¨é‡æ•°æ®...\")\n",
    "    all_prompts = smart_load_data(prompt_file)\n",
    "    all_answers = smart_load_data(answer_file)\n",
    "    \n",
    "    if not all_prompts or not all_answers:\n",
    "        return\n",
    "\n",
    "    # å»ºç«‹ç´¢å¼•åŠ é€ŸæŸ¥æ‰¾\n",
    "    answer_map = {item['id']: item for item in all_answers}\n",
    "    \n",
    "    # ç»Ÿè®¡å˜é‡\n",
    "    total_cases = len(all_prompts)\n",
    "    passed_count = 0\n",
    "    failed_cases = []\n",
    "\n",
    "    print(f\"ğŸš€ å¼€å§‹å…¨é‡è¯„æµ‹ (å…± {total_cases} æ¡æ•°æ®)...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for test_entry in tqdm(all_prompts, desc=\"Running Mock Evaluation\"):\n",
    "        test_id = test_entry['id']\n",
    "        \n",
    "        # 1. è·å–ç­”æ¡ˆ\n",
    "        if test_id not in answer_map:\n",
    "            print(f\"\\nâš ï¸ è·³è¿‡: æ‰¾ä¸åˆ° ID {test_id} çš„ç­”æ¡ˆ\")\n",
    "            failed_cases.append(test_id)\n",
    "            continue\n",
    "        \n",
    "        ground_truth_entry = answer_map[test_id]\n",
    "\n",
    "        try:\n",
    "            # 2. è¿è¡Œ Agent (verbose=False å…³é—­è¯¦ç»†æ—¥å¿—ï¼Œåªè·‘é€»è¾‘)\n",
    "            model_decoded_output = run_react_agent(\n",
    "                test_entry, \n",
    "                ground_truth_entry[\"ground_truth\"], \n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # 3. æ‰“åˆ†\n",
    "            score_result = multi_turn_checker(\n",
    "                model_decoded_output, \n",
    "                ground_truth_entry[\"ground_truth\"], \n",
    "                test_entry, \n",
    "                \"multi_turn_base\", \n",
    "                \"demo_runner\"\n",
    "            )\n",
    "            \n",
    "            if score_result[\"valid\"]:\n",
    "                passed_count += 1\n",
    "            else:\n",
    "                # è®°å½•å¤±è´¥è¯¦æƒ…\n",
    "                failed_cases.append({\n",
    "                    \"id\": test_id,\n",
    "                    \"error\": score_result.get(\"error\")\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ è¿è¡Œæ—¶å´©æºƒ ID {test_id}: {e}\")\n",
    "            failed_cases.append({\"id\": test_id, \"error\": str(e)})\n",
    "\n",
    "    # --- æœ€ç»ˆæŠ¥å‘Š ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ“Š è¯„æµ‹å®ŒæˆæŠ¥å‘Š\")\n",
    "    print(f\"Total: {total_cases}\")\n",
    "    print(f\"Passed: {passed_count}\")\n",
    "    print(f\"Failed: {len(failed_cases)}\")\n",
    "    \n",
    "    if total_cases > 0:\n",
    "        accuracy = (passed_count / total_cases) * 100\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    if failed_cases:\n",
    "        print(\"\\nâŒ å¤±è´¥ç”¨ä¾‹åˆ—è¡¨:\")\n",
    "        for fail in failed_cases:\n",
    "            print(fail)\n",
    "    else:\n",
    "        print(\"\\nğŸ‰ å®Œç¾ï¼Mock æ¨¡å‹å…¨éƒ¨é€šè¿‡ï¼Pipeline éªŒè¯æ— è¯¯ã€‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cd659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gorilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
