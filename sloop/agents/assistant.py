"""
åŠ©æ‰‹æ¨¡æ‹Ÿå™¨ (Assistant Agent)

æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
"""

import logging
import json
import re
from typing import List, Optional, Dict, Any
from ..models import ToolDefinition, ChatMessage, ToolCall
from ..utils.llm import chat_completion
from ..utils.template import (
    render_assistant_prompt,
    render_assistant_think_prompt,
    render_assistant_decide_prompt,
    render_tool_call_gen_prompt,
    render_assistant_reply_prompt
)

logger = logging.getLogger(__name__)


class AssistantAgent:
    """
    åŠ©æ‰‹æ™ºèƒ½ä½“

    è´Ÿè´£æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²ç”Ÿæˆå“åº”ï¼Œ
    å¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ã€‚
    """

    def __init__(self, tools: List[ToolDefinition]):
        """
        åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“

        å‚æ•°:
            tools: å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

        logger.info(f"AssistantAgent initialized with {len(tools)} tools")

    def generate_response(
        self,
        conversation_history: List[ChatMessage]
    ) -> str:
        """
        ç”ŸæˆåŠ©æ‰‹å“åº”

        å‚æ•°:
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²ï¼Œå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
        """
        logger.info("Generating assistant response")

        # æ„é€ æç¤º
        prompt = render_assistant_prompt(self.tools, conversation_history)

        # è°ƒç”¨LLMç”Ÿæˆå“åº”
        response = chat_completion(
            prompt=prompt,
            system_message="You are a helpful AI assistant with access to various tools. Use tools when appropriate to help the user.",
            json_mode=False  # è®©æ¨¡å‹è‡ªç”±è¾“å‡ºï¼Œå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨
        )

        if not response or response.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate assistant response: {response}")
            return "I'm sorry, I encountered an error. How can I help you?"  # é»˜è®¤å“åº”

        logger.info(f"Generated assistant response: {response[:100]}...")
        return response.strip()

    def parse_tool_calls(self, response: str) -> List[ToolCall]:
        """
        ä»å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []

        # å°è¯•è§£æJSONæ ¼å¼çš„å·¥å…·è°ƒç”¨
        # æŸ¥æ‰¾ç±»ä¼¼ {"tool_name": "...", "arguments": {...}} çš„æ¨¡å¼ï¼ˆå…¼å®¹nameå­—æ®µï¼‰
        json_pattern = r'\{[^}]*"(?:tool_name|name)"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
        matches = re.findall(json_pattern, response, re.DOTALL)

        for match in matches:
            tool_name, args_str = match
            try:
                arguments = json.loads(args_str)
                if tool_name in self.tool_map:
                    tool_call = ToolCall(
                        name=tool_name,
                        arguments=arguments
                    )
                    tool_calls.append(tool_call)
                    logger.info(f"Parsed tool call: {tool_name}")
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse tool call arguments: {args_str}")

        # å¦‚æœæ²¡æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾å‡½æ•°è°ƒç”¨æ¨¡å¼
        if not tool_calls:
            # æŸ¥æ‰¾ function_call æ¨¡å¼
            func_pattern = r'"function_call"\s*:\s*\{[^}]*"name"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
            func_matches = re.findall(func_pattern, response, re.DOTALL)

            for match in func_matches:
                tool_name, args_str = match
                try:
                    arguments = json.loads(args_str)
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(
                            name=tool_name,
                            arguments=arguments
                        )
                        tool_calls.append(tool_call)
                        logger.info(f"Parsed function call: {tool_name}")
                except json.JSONDecodeError:
                    logger.warning(f"Failed to parse function call arguments: {args_str}")

        return tool_calls

    def should_call_tools(self, response: str) -> bool:
        """
        åˆ¤æ–­å“åº”æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
        """
        return len(self.parse_tool_calls(response)) > 0

    def generate_thought(self, conversation_history: List[ChatMessage], context_hint: str = "") -> str:
        """
        ç”ŸæˆåŠ©æ‰‹æ€è€ƒè¿‡ç¨‹ (Chain of Thought)

        å‚æ•°:
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨
            context_hint: æ ˆä¸Šä¸‹æ–‡æç¤ºä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        """
        logger.info("Generating assistant thought process (CoT)")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_think_prompt(conversation_history, context_hint)

        # è°ƒç”¨LLMç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thought = chat_completion(
            prompt=prompt,
            system_message="ä½ æ˜¯ç”Ÿæˆè¯¦ç»†æ€è€ƒè¿‡ç¨‹çš„æ¨ç†AIã€‚è¯·ä¿æŒé€»è¾‘æ€§å’Œå…¨é¢æ€§ã€‚",
            json_mode=False
        )

        if not thought or thought.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate thought: {thought}")
            return "æˆ‘éœ€è¦åˆ†æç”¨æˆ·çš„è¯·æ±‚å¹¶ç¡®å®šæœ€ä½³å“åº”æ–¹å¼ã€‚"

        logger.info(f"Generated thought: {thought[:100]}...")
        return thought.strip()

    def decide_tool_use(self, thought: str) -> bool:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        """
        logger.info("Deciding whether to use tools based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_decide_prompt(thought, self.tools)

        decision = chat_completion(
            prompt=prompt,
            system_message="ä½ æ˜¯å†³ç­–AIã€‚åªå›ç­”YESæˆ–NOã€‚",
            json_mode=False
        ).strip().upper()

        needs_tools = decision.startswith('YES')
        logger.info(f"Tool use decision: {needs_tools}")
        return needs_tools

    def generate_tool_calls(self, thought: str, tools: List[ToolDefinition]) -> List[ToolCall]:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨

        è¿”å›:
            å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        logger.info("Generating tool calls based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_tool_call_gen_prompt(thought, tools)

        response = chat_completion(
            prompt=prompt,
            system_message="ä½ æ˜¯å·¥å…·è°ƒç”¨AIã€‚è¯·ç”Ÿæˆæœ‰æ•ˆçš„JSONæ ¼å¼å·¥å…·è°ƒç”¨ã€‚",
            json_mode=True
        )

        try:
            tool_calls_data = json.loads(response)
            if not isinstance(tool_calls_data, list):
                tool_calls_data = [tool_calls_data]

            tool_calls = []
            for call_data in tool_calls_data:
                if isinstance(call_data, dict) and 'name' in call_data and 'arguments' in call_data:
                    tool_name = call_data['name']
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(
                            name=tool_name,
                            arguments=call_data['arguments']
                        )
                        tool_calls.append(tool_call)
                        logger.info(f"Generated tool call: {tool_name}")

            return tool_calls

        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Failed to parse generated tool calls: {e}")
            return []

    def generate_reply(self, thought: str, conversation_history: List[ChatMessage]) -> str:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            æœ€ç»ˆå›å¤å­—ç¬¦ä¸²
        """
        logger.info("Generating final reply based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_reply_prompt(thought, conversation_history)

        reply = chat_completion(
            prompt=prompt,
            system_message="ä½ æ˜¯ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚è¯·ç”Ÿæˆè‡ªç„¶ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚",
            json_mode=False
        )

        if not reply or reply.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate reply: {reply}")
            return "æˆ‘å¾ˆä¹æ„ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼æœ‰ä»€ä¹ˆå¯ä»¥æ•ˆåŠ³çš„å—ï¼Ÿ"

        logger.info(f"Generated reply: {reply[:100]}...")
        return reply.strip()


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    print("ğŸ¤– Assistant Agent æµ‹è¯•")
    print("=" * 50)

    from ..models import ToolDefinition, ChatMessage

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·
    mock_tools = [
        ToolDefinition(
            name="search_restaurants",
            description="Search for restaurants in a city",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"},
                    "cuisine": {"type": "string", "description": "Type of cuisine"}
                },
                "required": ["city"]
            }
        ),
        ToolDefinition(
            name="book_restaurant",
            description="Book a table at a restaurant",
            parameters={
                "type": "object",
                "properties": {
                    "restaurant_id": {"type": "string", "description": "Restaurant ID"},
                    "date": {"type": "string", "description": "Booking date"},
                    "time": {"type": "string", "description": "Booking time"},
                    "party_size": {"type": "integer", "description": "Number of people"}
                },
                "required": ["restaurant_id", "date", "time"]
            }
        )
    ]

    # åˆ›å»ºæ¨¡æ‹Ÿå¯¹è¯å†å²
    mock_history = [
        ChatMessage(role="user", content="æˆ‘æƒ³åœ¨ä¸Šæµ·æ‰¾ä¸€å®¶æ„å¤§åˆ©é¤å…åƒé¥­"),
        ChatMessage(role="assistant", content="æˆ‘æ¥å¸®ä½ æ‰¾ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚ä½ æƒ³è¦ä»€ä¹ˆæ ·çš„ä»·ä½æˆ–åœ°ç‚¹å—ï¼Ÿ"),
        ChatMessage(role="user", content="å¸‚ä¸­å¿ƒå°±å¯ä»¥ï¼Œé€‚åˆ4ä¸ªäºº"),
    ]

    print("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    print(f"  å¯ç”¨å·¥å…·æ•°: {len(mock_tools)}")
    for tool in mock_tools:
        print(f"    - {tool.name}: {tool.description}")
    print(f"  å¯¹è¯å†å²: {len(mock_history)} æ¡æ¶ˆæ¯")
    print()

    # åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“
    print("ğŸ”§ åˆå§‹åŒ–AssistantAgent...")
    assistant_agent = AssistantAgent(mock_tools)

    print("ğŸ’­ ç”ŸæˆåŠ©æ‰‹å“åº”...")
    try:
        response = assistant_agent.generate_response(mock_history)

        print("âœ… ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ å“åº”å†…å®¹: {response}")

        # è§£æå·¥å…·è°ƒç”¨
        tool_calls = assistant_agent.parse_tool_calls(response)
        if tool_calls:
            print(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for i, tool_call in enumerate(tool_calls, 1):
                print(f"  {i}. {tool_call.tool_name}: {tool_call.arguments}")
        else:
            print("ğŸ’¬ çº¯æ–‡æœ¬å“åº”ï¼Œæ— å·¥å…·è°ƒç”¨")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
        print("\nğŸ”§ æä¾›æ¨¡æ‹ŸåŠ©æ‰‹å“åº”:")
        mock_response = 'æˆ‘æ¥å¸®ä½ æœç´¢ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚{"tool_name": "search_restaurants", "arguments": {"city": "ä¸Šæµ·", "cuisine": "æ„å¤§åˆ©èœ"}}'
        print(mock_response)

        # æµ‹è¯•è§£æ
        tool_calls = assistant_agent.parse_tool_calls(mock_response)
        if tool_calls:
            print(f"ğŸ”§ è§£æå‡º {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for tool_call in tool_calls:
                print(f"  - {tool_call.name}: {tool_call.arguments}")

    print("\nâœ… Assistant Agent æµ‹è¯•å®Œæˆï¼")
