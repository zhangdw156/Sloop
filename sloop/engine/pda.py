"""
ä¸‹æ¨è‡ªåŠ¨æœº (PDA) æ ¸å¿ƒå¼•æ“

å®ç°å¯¹è¯ç”Ÿæˆçš„æ ¸å¿ƒå¾ªç¯é€»è¾‘ï¼Œä½¿ç”¨ transitions åº“ç®¡ç†çŠ¶æ€æµè½¬ï¼Œæ”¯æŒæ ˆæ“ä½œã€‚
"""

import json
import random
from typing import List

from transitions import Machine

from sloop.agents import AssistantAgent, ServiceAgent, UserAgent
from sloop.models import (
    Blueprint,
    ChatMessage,
    ConversationContext,
    ToolDefinition,
)
from sloop.utils.logger import logger

# è®¾ç½®æ—¥å¿—


# çŠ¶æ€å¸¸é‡å®šä¹‰
class PDAStates:
    """PDA çŠ¶æ€å¸¸é‡ - ç»†ç²’åº¦çŠ¶æ€ç®¡ç†"""

    USER_GEN = "user_gen"
    ASSISTANT_THINK = "assistant_think"
    ASSISTANT_DECIDE = "assistant_decide"
    TOOL_CALL_GEN = "tool_call_gen"
    TOOL_EXEC = "tool_exec"
    ASSISTANT_REPLY_GEN = "assistant_reply_gen"
    EVALUATION = "evaluation"
    FINISH = "finish"


class ConversationPDA:
    """
    å¯¹è¯å¾ªç¯ä¸‹æ¨è‡ªåŠ¨æœº

    ç®¡ç†å®Œæ•´çš„å¯¹è¯ç”Ÿæˆæµç¨‹ï¼Œä»åˆå§‹åŒ–åˆ°ç»“æŸã€‚
    ä½¿ç”¨ transitions.Machine å®ç°çŠ¶æ€æµè½¬ï¼Œæ”¯æŒæ ˆæ“ä½œã€‚
    """

    def __init__(
        self,
        blueprint: Blueprint,
        tools: List[ToolDefinition],
        conversation_id: str = None,
        max_turns: int = 20,
        auto_start: bool = True,
    ):
        """
        åˆå§‹åŒ–å¯¹è¯å¾ªç¯

        å‚æ•°:
            blueprint: ä»»åŠ¡è“å›¾
            tools: å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
            conversation_id: å¯¹è¯IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
            max_turns: æœ€å¤§å¯¹è¯è½®æ•°
            auto_start: æ˜¯å¦è‡ªåŠ¨å¯åŠ¨å¯¹è¯ï¼Œé»˜è®¤ä¸ºTrueã€‚å¯¹äºæµ‹è¯•å¯ä»¥è®¾ä¸ºFalse
        """
        self.blueprint = blueprint
        self.tools = tools
        self.conversation_id = conversation_id or f"conv_{random.randint(1000, 9999)}"

        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.user_agent = UserAgent()
        self.assistant_agent = AssistantAgent(tools)
        self.service_agent = ServiceAgent()

        # åˆå§‹åŒ–å¯¹è¯ä¸Šä¸‹æ–‡
        self.context = ConversationContext(
            conversation_id=self.conversation_id,
            blueprint_id=getattr(blueprint, "id", None),
            initial_state=blueprint.initial_state.copy(),
            current_user_intent=blueprint.intent,
            max_turns=max_turns,
        )

        # åˆå§‹åŒ–ç¯å¢ƒçŠ¶æ€
        self.context.env_state.update(blueprint.initial_state)

        # åˆå§‹åŒ–ç”¨æˆ·è½®æ•°è®¡æ•°å™¨
        self.user_turn_count = 0

        # è®¾ç½®çŠ¶æ€æœº
        self._setup_state_machine()

        # æ ¹æ®auto_startå‚æ•°å†³å®šæ˜¯å¦è‡ªåŠ¨å¯åŠ¨å¯¹è¯
        if auto_start:
            logger.info(
                f"ğŸ¬ ConversationPDA initialized and started: {self.conversation_id}"
            )
        else:
            logger.info(
                f"ğŸ¬ ConversationPDA initialized (auto_start=False): {self.conversation_id}"
            )

    def _setup_state_machine(self):
        """è®¾ç½®çŠ¶æ€æœº"""
        # å®šä¹‰çŠ¶æ€
        states = [
            PDAStates.USER_GEN,
            PDAStates.ASSISTANT_THINK,
            PDAStates.ASSISTANT_DECIDE,
            PDAStates.TOOL_CALL_GEN,
            PDAStates.TOOL_EXEC,
            PDAStates.ASSISTANT_REPLY_GEN,
            PDAStates.EVALUATION,
            PDAStates.FINISH,
        ]

        # å®šä¹‰çŠ¶æ€æœº
        self.machine = Machine(
            model=self,
            states=states,
            initial=PDAStates.USER_GEN,
            model_attribute="current_state",
        )

        # å®šä¹‰çŠ¶æ€è½¬æ¢
        self.machine.add_transition(
            "user_generated", PDAStates.USER_GEN, PDAStates.ASSISTANT_THINK
        )
        self.machine.add_transition(
            "thought_generated", PDAStates.ASSISTANT_THINK, PDAStates.ASSISTANT_DECIDE
        )
        self.machine.add_transition(
            "decide_tool_call", PDAStates.ASSISTANT_DECIDE, PDAStates.TOOL_CALL_GEN
        )
        self.machine.add_transition(
            "decide_reply", PDAStates.ASSISTANT_DECIDE, PDAStates.ASSISTANT_REPLY_GEN
        )
        self.machine.add_transition(
            "tool_calls_generated", PDAStates.TOOL_CALL_GEN, PDAStates.TOOL_EXEC
        )
        self.machine.add_transition(
            "skip_tools_reply", PDAStates.TOOL_CALL_GEN, PDAStates.ASSISTANT_REPLY_GEN
        )  # æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶ç›´æ¥å›å¤
        self.machine.add_transition(
            "tools_executed", PDAStates.TOOL_EXEC, PDAStates.ASSISTANT_THINK
        )  # ReAct é—­ç¯
        self.machine.add_transition(
            "reply_generated", PDAStates.ASSISTANT_REPLY_GEN, PDAStates.EVALUATION
        )
        self.machine.add_transition(
            "continue_dialogue", PDAStates.EVALUATION, PDAStates.USER_GEN
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.EVALUATION, PDAStates.FINISH
        )
        # å…è®¸ä»ä»»ä½•çŠ¶æ€ç›´æ¥ç»“æŸå¯¹è¯
        self.machine.add_transition(
            "finish_dialogue", PDAStates.USER_GEN, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_THINK, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_DECIDE, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.TOOL_CALL_GEN, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.TOOL_EXEC, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_REPLY_GEN, PDAStates.FINISH
        )

        # æ³¨æ„ï¼štransitionsåº“ä¼šè‡ªåŠ¨ç»‘å®šåä¸º on_enter_{state_name} çš„æ–¹æ³•ä½œä¸ºçŠ¶æ€è¿›å…¥å›è°ƒ
        # æ— éœ€æ‰‹åŠ¨ç»‘å®šï¼Œä»¥é¿å…é‡å¤ç»‘å®šå¯¼è‡´çš„å›è°ƒæ‰§è¡Œé—®é¢˜

    def _generate_context_hint(self) -> str:
        """ç”Ÿæˆæ ˆä¸Šä¸‹æ–‡æç¤ºä¿¡æ¯"""
        stack_top = self.context.peek_context()
        if not stack_top or stack_top["type"] == "ROOT":
            return ""

        if stack_top["type"] == "WAITING_FOR_TOOLS":
            tool_names = stack_top["data"].get("tool_names", [])
            intent = stack_top["data"].get("intent", "æœªçŸ¥æ„å›¾")
            nested_level = stack_top["data"].get("nested_level", 0)
            indent = "  " * nested_level
            return f"{indent}ç³»ç»Ÿæç¤ºï¼šä½ æ­£åœ¨ç­‰å¾…å·¥å…·ç»“æœæ¥å®Œæˆå­ä»»åŠ¡ã€‚ç­‰å¾…çš„å·¥å…·ï¼š{', '.join(tool_names)}ã€‚ä»»åŠ¡æ„å›¾ï¼š{intent}ã€‚è¯·åŸºäºæœ€æ–°å·¥å…·ç»“æœç»§ç»­æ¨ç†ã€‚"

        return ""

    def _extract_intent_from_thought(self, thought: str) -> str:
        """ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–æ„å›¾æ‘˜è¦"""
        if not thought:
            return "æœªçŸ¥æ„å›¾"
        # ç®€å•æå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ„å›¾æ‘˜è¦
        return thought[:50].strip() + "..." if len(thought) > 50 else thought.strip()

    # ==================== çŠ¶æ€å›è°ƒæ–¹æ³• ====================

    def _process_user_gen(self):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ç”ŸæˆçŠ¶æ€"""
        logger.info("ğŸ‘¤ [USER_GEN] ç”¨æˆ·æ¶ˆæ¯ç”Ÿæˆ")
        self.user_turn_count += 1
        logger.info(f"ğŸ‘¤ [USER_GEN] ç”¨æˆ·è½®æ¬¡ {self.user_turn_count}")

        # æ¸…ç©ºä¸Šä¸€è½®çš„ç¼“å†²åŒº
        self.context.clear_buffers()

        # è°ƒç”¨ç”¨æˆ·æ™ºèƒ½ä½“ç”Ÿæˆæ¶ˆæ¯
        user_message_content = self.user_agent.generate_message(
            self.blueprint, self.context.messages
        )

        # æ£€æŸ¥æ˜¯å¦ä»»åŠ¡å®Œæˆï¼Œå¹¶å¤„ç†åœæ­¢æ ‡è®°
        should_stop = self.user_agent.is_task_complete(user_message_content)
        if should_stop:
            # å‰¥ç¦»åœæ­¢æ ‡è®°ï¼Œä¿ç•™å¹²å‡€çš„æ¶ˆæ¯å†…å®¹
            user_message_content = user_message_content.replace(
                "###STOP###", ""
            ).strip()
            logger.info("   âœ… ç”¨æˆ·è¡¨ç¤ºä»»åŠ¡å®Œæˆ")

        # å¦‚æœæ¶ˆæ¯å†…å®¹ä¸ä¸ºç©ºï¼Œå§‹ç»ˆæ·»åŠ åˆ°å¯¹è¯å†å²
        if user_message_content:
            # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡å¹¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            user_message = ChatMessage(role="user", content=user_message_content)
            self.context.add_message(user_message)
            logger.info(f"   ğŸ’¬ ç”¨æˆ·: {user_message.content}")

        # å¦‚æœéœ€è¦åœæ­¢ï¼Œåˆ™æ ‡è®°å®Œæˆå¹¶ç»“æŸå¯¹è¯
        if should_stop:
            self.context.is_completed = True
            return "finish_dialogue"

        # è¿”å›ä¸‹ä¸€æ­¥è§¦å‘
        return "user_generated"

    def _process_assistant_think(self):
        """å¤„ç†åŠ©æ‰‹æ€è€ƒçŠ¶æ€ - ç”Ÿæˆ CoT"""
        logger.info("ğŸ¤– [ASSISTANT_THINK] åŠ©æ‰‹æ­£åœ¨ç”Ÿæˆæ€è€ƒè¿‡ç¨‹")
        logger.info("ğŸ¤– [ASSISTANT_THINK] åŠ©æ‰‹æ­£åœ¨ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ (CoT)...")
        logger.info(
            f"   ğŸ“š å½“å‰æ ˆçŠ¶æ€: {[frame['type'] for frame in self.context.stack]}"
        )

        # ç”Ÿæˆæ ˆä¸Šä¸‹æ–‡æç¤º
        context_hint = self._generate_context_hint()

        # è°ƒç”¨åŠ©æ‰‹æ™ºèƒ½ä½“ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thought_content = self.assistant_agent.generate_thought(
            self.context.messages, context_hint
        )

        # å­˜å‚¨åˆ°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        self.context.current_thought = thought_content
        logger.info(f"   ğŸ’­ æ€è€ƒè¿‡ç¨‹: {thought_content[:100]}...")

        # è¿”å›ä¸‹ä¸€æ­¥è§¦å‘
        return "thought_generated"

    def _process_assistant_decide(self):
        """å¤„ç†åŠ©æ‰‹å†³ç­–çŠ¶æ€ - åŸºäºæ€è€ƒå†³å®šä¸‹ä¸€æ­¥"""
        logger.info("ğŸ¤– [ASSISTANT_DECIDE] åŠ©æ‰‹æ­£åœ¨å†³ç­–")
        logger.info("ğŸ¤– [ASSISTANT_DECIDE] åŸºäºæ€è€ƒè¿‡ç¨‹è¿›è¡Œå†³ç­–...")

        # æ£€æŸ¥æ ˆé¡¶æ˜¯å¦ä¸ºWAITING_FOR_TOOLSï¼Œå¦‚æœæ˜¯åˆ™æ ¹æ®å†³ç­–è¿›è¡ŒPOPæ“ä½œ
        stack_top = self.context.peek_context()
        was_waiting = stack_top and stack_top["type"] == "WAITING_FOR_TOOLS"

        # åŸºäºæ€è€ƒè¿‡ç¨‹å†³å®šæ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
        needs_tools = self.assistant_agent.decide_tool_use(self.context.current_thought)

        if needs_tools:
            if was_waiting:
                # ä»»åŠ¡è¿›å±•ï¼šPOPæ—§çš„WAITINGå¸§ï¼Œä¸ºæ–°çš„å·¥å…·è°ƒç”¨è®©è·¯
                popped = self.context.pop_context()
                logger.info(f"   ğŸ“š POP æ ˆ: {popped['type']} - ä»»åŠ¡è¿›å±•ï¼Œç»§ç»­è°ƒç”¨å·¥å…·")
            logger.info("   ğŸ”§ å†³ç­–: éœ€è¦è°ƒç”¨å·¥å…·")
            return "decide_tool_call"
        else:
            if was_waiting:
                # å­ä»»åŠ¡å®Œæˆï¼šPOP WAITINGå¸§
                popped = self.context.pop_context()
                logger.info(f"   ğŸ“š POP æ ˆ: {popped['type']} - å­ä»»åŠ¡å®Œæˆ")
            logger.info("   ğŸ’¬ å†³ç­–: ç›´æ¥å›å¤")
            return "decide_reply"

    def _process_tool_call_gen(self):
        """å¤„ç†å·¥å…·è°ƒç”¨ç”ŸæˆçŠ¶æ€ - ç”Ÿæˆå…·ä½“çš„å·¥å…·è°ƒç”¨å‚æ•°"""
        logger.info("ğŸ”§ [TOOL_CALL_GEN] ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°")
        logger.info("ğŸ”§ [TOOL_CALL_GEN] åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°...")

        # åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨
        tool_calls = self.assistant_agent.generate_tool_calls(
            self.context.current_thought, self.tools
        )

        if tool_calls:
            # PUSH ç­‰å¾…å·¥å…·ç»“æœçš„ä¸Šä¸‹æ–‡å¸§
            tool_names = [tc.name for tc in tool_calls]
            nested_level = self.context.get_stack_depth()
            self.context.push_context(
                "WAITING_FOR_TOOLS",
                {
                    "tool_names": tool_names,
                    "intent": self._extract_intent_from_thought(
                        self.context.current_thought
                    ),
                    "nested_level": nested_level,
                },
            )
            logger.info(f"   ğŸ“š PUSH æ ˆ: WAITING_FOR_TOOLS - å·¥å…·: {tool_names}")

            # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºç‹¬ç«‹çš„ tool_call æ¶ˆæ¯ï¼ˆæ‰å¹³åŒ–æ ¼å¼ï¼‰
            for tool_call in tool_calls:
                tool_call_data = {
                    "name": tool_call.name,
                    "arguments": tool_call.arguments,
                }
                tool_call_message = ChatMessage(
                    role="tool_call",
                    content=json.dumps(tool_call_data, ensure_ascii=False),
                )
                self.context.add_message(tool_call_message)

            # åŒæ—¶å­˜å‚¨åˆ°pendingåˆ—è¡¨ä¾›åç»­æ‰§è¡Œ
            self.context.pending_tool_calls.extend(tool_calls)
            logger.info(f"   ğŸ“ ç”Ÿæˆ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯")

            # è¿”å›ä¸‹ä¸€æ­¥è§¦å‘
            return "tool_calls_generated"
        else:
            logger.info("   ğŸ“ æ²¡æœ‰ç”Ÿæˆå·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿›å…¥å›å¤ç”Ÿæˆ")
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿›å…¥å›å¤ç”ŸæˆçŠ¶æ€
            return "skip_tools_reply"

    def _process_tool_exec(self):
        """å¤„ç†å·¥å…·æ‰§è¡ŒçŠ¶æ€"""
        logger.info("ğŸ› ï¸ [TOOL_EXEC] æ­£åœ¨æ‰§è¡Œå·¥å…·")
        logger.info("ğŸ› ï¸ [TOOL_EXEC] æ‰§è¡Œå·¥å…·è°ƒç”¨...")

        # å¤„ç†æ‰€æœ‰pendingçš„å·¥å…·è°ƒç”¨
        while self.context.pending_tool_calls:
            tool_call = self.context.pending_tool_calls.pop(0)

            logger.info(f"   ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call.name}")

            # è°ƒç”¨æœåŠ¡æ™ºèƒ½ä½“æ‰§è¡Œå·¥å…·
            execution_result = self.service_agent.execute_tool(
                tool_call, self.context.env_state, self.blueprint
            )

            # æ›´æ–°ç¯å¢ƒçŠ¶æ€
            if execution_result["state_updates"]:
                self.service_agent.update_state(
                    self.context.env_state, execution_result["state_updates"]
                )
                logger.info(f"   ğŸ“Š çŠ¶æ€æ›´æ–°: {execution_result['state_updates']}")

            # åˆ›å»ºå·¥å…·æ¶ˆæ¯
            tool_message = ChatMessage(
                role="tool",
                content=execution_result["response"],
                tool_call_id=f"call_{random.randint(1000, 9999)}",
            )
            self.context.add_message(tool_message)

            logger.info(f"   âœ… å·¥å…·æ‰§è¡Œç»“æœ: {execution_result['response']}")

        # è¿”å›åˆ°åŠ©æ‰‹æ€è€ƒï¼ˆReActé—­ç¯ï¼‰
        return "tools_executed"

    def _process_assistant_reply_gen(self):
        """å¤„ç†åŠ©æ‰‹å›å¤ç”ŸæˆçŠ¶æ€ - ç”Ÿæˆæœ€ç»ˆå›å¤æ–‡æœ¬"""
        logger.info("ğŸ¤– [ASSISTANT_REPLY_GEN] ç”Ÿæˆæœ€ç»ˆå›å¤")
        logger.info("ğŸ¤– [ASSISTANT_REPLY_GEN] åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤...")

        # åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤
        reply_content = self.assistant_agent.generate_reply(
            self.context.current_thought, self.context.messages
        )

        # å°†æ€è€ƒè¿‡ç¨‹å’Œå›å¤æ‹¼æ¥ä¸ºå®Œæ•´å†…å®¹ï¼ˆç”¨äºè®­ç»ƒæ•°æ®æ ¼å¼ï¼‰
        full_content = (
            f"<think>\n{self.context.current_thought}\n</think>\n\n{reply_content}"
        )

        # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆåŒ…å«æ€è€ƒå’Œå›å¤ï¼‰
        assistant_message = ChatMessage(role="assistant", content=full_content)
        self.context.add_message(assistant_message)

        logger.info(f"   ğŸ’¬ åŠ©æ‰‹å›å¤: {full_content[:100]}...")

        # è¿”å›ä¸‹ä¸€æ­¥è§¦å‘
        return "reply_generated"

    def _process_evaluation(self):
        """å¤„ç†è¯„ä¼°çŠ¶æ€"""
        logger.info("ğŸ“Š [EVALUATION] è¯„ä¼°å¯¹è¯çŠ¶æ€")
        logger.info("ğŸ“Š [EVALUATION] è¯„ä¼°å¯¹è¯çŠ¶æ€...")

        # å¦‚æœå·²ç»å®Œæˆï¼Œä¸è¦é‡å¤å¤„ç†
        if self.context.is_completed:
            logger.info("   âœ… å¯¹è¯å·²å®Œæˆï¼Œè·³è¿‡è¯„ä¼°")
            return "finish_dialogue"

        self.context.increment_turn()

        # è¯„ä¼°ç»“æŸæ¡ä»¶ï¼ˆç§»é™¤éšæœºç»“æŸé€»è¾‘ï¼Œç¡®ä¿å¯¹è¯å……åˆ†å±•å¼€ï¼‰
        should_finish = (
            self.context.turn_count >= self.context.max_turns
            or self.context.env_state.validate_transition(self.blueprint.expected_state)
        )

        if should_finish:
            logger.info("   ğŸ æ»¡è¶³ç»“æŸæ¡ä»¶ï¼Œå®Œæˆå¯¹è¯")
            return "finish_dialogue"
        else:
            logger.info("   ğŸ”„ ç»§ç»­ä¸‹ä¸€è½®å¯¹è¯")
            return "continue_dialogue"

    def on_enter_finish(self):
        """è¿›å…¥ç»“æŸçŠ¶æ€"""
        logger.info("âœ… [FINISH] å¯¹è¯å®Œæˆ")
        logger.info(f"âœ… [FINISH] å¯¹è¯ {self.conversation_id} å®Œæˆ")
        logger.info(f"   ğŸ“ˆ æ€»è½®æ¬¡: {self.context.turn_count}")
        logger.info(f"   ğŸ“ æ¶ˆæ¯æ•°é‡: {len(self.context.messages)}")
        logger.info(f"   ğŸ¯ æœ€ç»ˆçŠ¶æ€: {self.context.env_state.state}")

    def run(self):
        """è¿è¡Œå®Œæ•´çš„å¯¹è¯å¾ªç¯ï¼ˆå¾ªç¯é©±åŠ¨æ¨¡å¼ï¼Œé¿å…é€’å½’æº¢å‡ºï¼‰"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œå¯¹è¯å¾ªç¯")

        while self.current_state != PDAStates.FINISH:
            trigger = None

            # æ ¹æ®å½“å‰çŠ¶æ€åˆ†å‘å¤„ç†é€»è¾‘
            if self.current_state == PDAStates.USER_GEN:
                trigger = self._process_user_gen()
            elif self.current_state == PDAStates.ASSISTANT_THINK:
                trigger = self._process_assistant_think()
            elif self.current_state == PDAStates.ASSISTANT_DECIDE:
                trigger = self._process_assistant_decide()
            elif self.current_state == PDAStates.TOOL_CALL_GEN:
                trigger = self._process_tool_call_gen()
            elif self.current_state == PDAStates.TOOL_EXEC:
                trigger = self._process_tool_exec()
            elif self.current_state == PDAStates.ASSISTANT_REPLY_GEN:
                trigger = self._process_assistant_reply_gen()
            elif self.current_state == PDAStates.EVALUATION:
                trigger = self._process_evaluation()

            # æ‰§è¡ŒçŠ¶æ€è½¬æ¢
            if trigger:
                logger.debug(f"âš¡ è§¦å‘çŠ¶æ€è½¬æ¢: {trigger}")
                self.trigger(trigger)

        self.on_enter_finish()

    # æ³¨æ„ï¼šcurrent_state ç”± transitions åº“è‡ªåŠ¨è®¾ç½®ï¼Œæ— éœ€ property

    def get_status(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return {
            "conversation_id": self.conversation_id,
            "current_state": self.current_state,
            "turn_count": self.context.turn_count,
            "is_completed": self.context.is_completed,
            "message_count": len(self.context.messages),
        }
