"""
å‘é‡æ£€ç´¢å¼•æ“

å®ç°åŸºäº FAISS çš„å·¥å…·å‘é‡æ£€ç´¢ï¼Œç”¨äº RAG å¢å¼ºçš„é‡‡æ ·é€»è¾‘ã€‚
"""

import json
import os
from pathlib import Path
from typing import List

import faiss
import numpy as np
from tqdm import tqdm

from sloop.config import get_settings
from sloop.models import ToolDefinition
from sloop.utils.logger import logger


class ToolRetrievalEngine:
    """
    å·¥å…·å‘é‡æ£€ç´¢å¼•æ“

    ä½¿ç”¨ FAISS æ„å»ºå·¥å…·å‘é‡ç´¢å¼•ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢ç›¸ä¼¼å·¥å…·ã€‚
    """

    def __init__(self, cache_dir: str = ".cache"):
        """
        åˆå§‹åŒ–æ£€ç´¢å¼•æ“

        å‚æ•°:
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„ï¼Œç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.index_path = self.cache_dir / "tool_index.faiss"
        self.names_path = self.cache_dir / "tool_names.json"

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–å±æ€§
        self.index = None
        self.tool_names = []

        # å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•
        self._load_index()

        # è·å–é…ç½®
        self.settings = get_settings()

    def _load_index(self):
        """åŠ è½½ç°æœ‰ç´¢å¼•"""
        if self.index_path.exists() and self.names_path.exists():
            try:
                # åŠ è½½ FAISS ç´¢å¼•
                self.index = faiss.read_index(str(self.index_path))

                # åŠ è½½å·¥å…·åç§°æ˜ å°„
                with open(self.names_path, 'r', encoding='utf-8') as f:
                    self.tool_names = json.load(f)

                logger.info(f"Loaded index successfully: {len(self.tool_names)} tools")

            except Exception as e:
                logger.warning(f"Failed to load index: {e}")
                self.index = None
                self.tool_names = []
        else:
            logger.info("No existing index files found")

    def _save_index(self):
        """ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜"""
        if self.index is not None and self.tool_names:
            try:
                # ä¿å­˜ FAISS ç´¢å¼•
                faiss.write_index(self.index, str(self.index_path))

                # ä¿å­˜å·¥å…·åç§°æ˜ å°„
                with open(self.names_path, 'w', encoding='utf-8') as f:
                    json.dump(self.tool_names, f, ensure_ascii=False, indent=2)

                logger.info(f"Index saved successfully: {self.index_path}, {self.names_path}")

            except Exception as e:
                logger.error(f"Failed to save index: {e}")

    def _get_embedding(self, text: str | List[str]) -> List[float] | List[List[float]]:
        """
        è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º

        å‚æ•°:
            text: è¾“å…¥æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨

        è¿”å›:
            å‘é‡åˆ—è¡¨æˆ–å‘é‡åˆ—è¡¨çš„åˆ—è¡¨
        """
        import litellm

        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = litellm.embedding(
                    model=f"{self.settings.embedding_provider}/{self.settings.embedding_model}",
                    input=text,
                    api_key=self.settings.embedding_api_key,
                    api_base=self.settings.embedding_base_url,
                    encoding_format="float",
                )

                if response and response.data:
                    if isinstance(text, str):
                        # å•æ¡è¾“å…¥
                        if len(response.data) > 0:
                            item = response.data[0]
                            if hasattr(item, 'embedding'):
                                return item.embedding
                            elif isinstance(item, dict) and 'embedding' in item:
                                return item['embedding']
                            else:
                                # å‡è®¾ item å°±æ˜¯å‘é‡åˆ—è¡¨
                                return item
                    else:
                        # æ‰¹é‡è¾“å…¥
                        embeddings = []
                        for item in response.data:
                            if hasattr(item, 'embedding'):
                                embeddings.append(item.embedding)
                            elif isinstance(item, dict) and 'embedding' in item:
                                embeddings.append(item['embedding'])
                            else:
                                # å‡è®¾ item å°±æ˜¯å‘é‡åˆ—è¡¨
                                embeddings.append(item)
                        return embeddings

            except Exception as e:
                logger.warning(f"Embedding call failed (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    continue

        # å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        raise RuntimeError("Embedding call failed after all retries")

    def build(self, tools: List[ToolDefinition], force: bool = False):
        """
        æ„å»ºå·¥å…·å‘é‡ç´¢å¼•

        å‚æ•°:
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ„å»º
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡æ„å»º
        if not force and self.index is not None and self.tool_names:
            logger.info("Index already exists, skipping build (use force=True to rebuild)")
            return

        logger.info(f"Starting to build index: {len(tools)} tools")

        # å‡†å¤‡æ•°æ®
        texts = []
        self.tool_names = []

        for tool in tools:
            # æ„é€ è¯­ä¹‰æ–‡æœ¬
            params_str = json.dumps(tool.parameters.model_dump(), ensure_ascii=False)
            text = f"name: {tool.name} description: {tool.description} params: {params_str}"
            texts.append(text)
            self.tool_names.append(tool.name)

        logger.info("Generating embeddings...")

        # æ‰¹é‡ç”Ÿæˆå‘é‡ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œé¿å… API é™åˆ¶ï¼‰
        batch_size = 10
        all_embeddings = []

        for i in tqdm(range(0, len(texts), batch_size), desc="Generating embeddings"):
            batch_texts = texts[i:i + batch_size]

            # æ‰¹é‡è°ƒç”¨ embedding API
            batch_embeddings = self._get_embedding(batch_texts)
            all_embeddings.extend(batch_embeddings)

        # è½¬æ¢ä¸º numpy æ•°ç»„
        embeddings = np.array(all_embeddings, dtype=np.float32)

        logger.info(f"Embeddings shape: {embeddings.shape}")

        # æ„å»º FAISS ç´¢å¼•
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings)

        logger.info(f"Index build completed: {len(self.tool_names)} tools")

        # ä¿å­˜ç´¢å¼•
        self._save_index()

    def search(self, query_tool: ToolDefinition, top_k: int = 10) -> List[str]:
        """
        æœç´¢ç›¸ä¼¼çš„å·¥å…·

        å‚æ•°:
            query_tool: æŸ¥è¯¢å·¥å…·å®šä¹‰
            top_k: è¿”å›çš„ç›¸ä¼¼å·¥å…·æ•°é‡

        è¿”å›:
            ç›¸ä¼¼å·¥å…·åç§°åˆ—è¡¨
        """
        if self.index is None or not self.tool_names:
            logger.error("Index not built, cannot search")
            return []

        # æ„é€ æŸ¥è¯¢æ–‡æœ¬
        params_str = json.dumps(query_tool.parameters.model_dump(), ensure_ascii=False)
        query_text = f"name: {query_tool.name} description: {query_tool.description} params: {params_str}"

        # è·å–æŸ¥è¯¢å‘é‡
        query_embedding = self._get_embedding(query_text)
        query_vector = np.array([query_embedding], dtype=np.float32)

        # æœç´¢ç›¸ä¼¼å‘é‡
        distances, indices = self.index.search(query_vector, min(top_k, len(self.tool_names)))

        # è¿”å›å·¥å…·åç§°
        results = []
        for idx in indices[0]:
            if idx < len(self.tool_names):
                results.append(self.tool_names[idx])

        return results


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    print("ğŸ” ToolRetrievalEngine æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·
    mock_tools = [
        ToolDefinition(
            name="get_weather",
            description="è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                    "date": {"type": "string", "description": "æ—¥æœŸ"},
                },
                "required": ["city"],
            },
        ),
        ToolDefinition(
            name="search_restaurants",
            description="æœç´¢æŒ‡å®šåŸå¸‚çš„é¤å…",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                    "cuisine": {"type": "string", "description": "èœç³»ç±»å‹"},
                    "price_range": {"type": "string", "description": "ä»·æ ¼èŒƒå›´"},
                },
                "required": ["city"],
            },
        ),
        ToolDefinition(
            name="book_hotel",
            description="é¢„è®¢é…’åº—æˆ¿é—´",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                    "check_in": {"type": "string", "description": "å…¥ä½æ—¥æœŸ"},
                    "check_out": {"type": "string", "description": "é€€æˆ¿æ—¥æœŸ"},
                    "guests": {"type": "integer", "description": "å…¥ä½äººæ•°"},
                },
                "required": ["city", "check_in", "check_out"],
            },
        ),
        ToolDefinition(
            name="send_email",
            description="å‘é€ç”µå­é‚®ä»¶",
            parameters={
                "type": "object",
                "properties": {
                    "to": {"type": "string", "description": "æ”¶ä»¶äººé‚®ç®±"},
                    "subject": {"type": "string", "description": "é‚®ä»¶ä¸»é¢˜"},
                    "body": {"type": "string", "description": "é‚®ä»¶æ­£æ–‡"},
                },
                "required": ["to", "subject", "body"],
            },
        ),
        ToolDefinition(
            name="calculate_distance",
            description="è®¡ç®—ä¸¤åœ°ä¹‹é—´çš„è·ç¦»",
            parameters={
                "type": "object",
                "properties": {
                    "origin": {"type": "string", "description": "èµ·ç‚¹"},
                    "destination": {"type": "string", "description": "ç»ˆç‚¹"},
                    "mode": {"type": "string", "description": "å‡ºè¡Œæ–¹å¼", "enum": ["driving", "walking", "transit"]},
                },
                "required": ["origin", "destination"],
            },
        ),
    ]

    print(f"ğŸ“‹ æµ‹è¯•æ•°æ®: {len(mock_tools)} ä¸ªå·¥å…·")
    for tool in mock_tools:
        print(f"  - {tool.name}: {tool.description}")

    # åˆå§‹åŒ–å¼•æ“
    print("\nğŸ”§ åˆå§‹åŒ– ToolRetrievalEngine...")
    engine = ToolRetrievalEngine()

    # æ„å»ºç´¢å¼•
    print("\nğŸ—ï¸ æ„å»ºç´¢å¼•...")
    engine.build(mock_tools, force=True)

    # æµ‹è¯•æœç´¢
    print("\nğŸ” æµ‹è¯•æœç´¢...")

    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥å…·ä½œä¸ºæŸ¥è¯¢
    query_tool = mock_tools[0]  # get_weather
    print(f"ğŸ“ æŸ¥è¯¢å·¥å…·: {query_tool.name} - {query_tool.description}")

    results = engine.search(query_tool, top_k=3)
    print(f"ğŸ¯ ç›¸ä¼¼å·¥å…· (Top-3): {results}")

    # ä½¿ç”¨å¦ä¸€ä¸ªå·¥å…·æµ‹è¯•
    query_tool2 = mock_tools[3]  # send_email
    print(f"\nğŸ“ æŸ¥è¯¢å·¥å…·: {query_tool2.name} - {query_tool2.description}")

    results2 = engine.search(query_tool2, top_k=3)
    print(f"ğŸ¯ ç›¸ä¼¼å·¥å…· (Top-3): {results2}")

    print("\nâœ… ToolRetrievalEngine æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ æ£€æŸ¥ç¼“å­˜æ–‡ä»¶: {engine.cache_dir}")
