"""
é…ç½®ç®¡ç†æ¨¡å—

è´Ÿè´£åŠ è½½ç¯å¢ƒå˜é‡å’Œé…ç½®å‚æ•°ï¼Œæ”¯æŒé€šè¿‡.envæ–‡ä»¶è¿›è¡Œé…ç½®ã€‚
"""

import logging
import os
from dataclasses import dataclass
from typing import Optional

from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

# å»¶è¿Ÿå¯¼å…¥loggerï¼Œé¿å…å¾ªç¯å¯¼å…¥
try:
    from sloop.utils.logger import logger
except ImportError:
    logger = None


# å»¶è¿Ÿå¯¼å…¥loggerï¼Œé¿å…å¾ªç¯å¯¼å…¥
def _get_logger():
    if logger is not None:
        return logger
    return logging.getLogger(__name__)


@dataclass
class Settings:
    """åº”ç”¨é…ç½®ç±»"""

    # LLMé…ç½®
    llm_provider: str = "openai"
    llm_model: str = "gpt-4o-mini"
    openai_api_key: Optional[str] = None
    openai_api_base: Optional[str] = None
    temperature: float = 0.7

    # ç³»ç»Ÿé…ç½®
    max_tokens: int = 2048
    timeout: int = 60

    # Embedding é…ç½®
    embedding_provider: str = "openai"
    embedding_model: str = "text-embedding-3-small"
    embedding_api_key: Optional[str] = None
    embedding_base_url: Optional[str] = None

    def __post_init__(self):
        """ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–"""
        # LLMé…ç½®
        self.llm_provider = os.getenv("LLM_PROVIDER", self.llm_provider)
        self.llm_model = os.getenv("MODEL_NAME", self.llm_model)
        self.openai_api_key = os.getenv("API_KEY", self.openai_api_key)
        self.openai_api_base = os.getenv("API_BASE", self.openai_api_base)

        # æ¸©åº¦å‚æ•°
        try:
            temp_str = os.getenv("TEMPERATURE")
            if temp_str:
                self.temperature = float(temp_str)
        except (ValueError, TypeError):
            pass  # ä½¿ç”¨é»˜è®¤å€¼

        # ç³»ç»Ÿé…ç½®
        try:
            max_tokens_str = os.getenv("MAX_TOKENS")
            if max_tokens_str:
                self.max_tokens = int(max_tokens_str)
        except (ValueError, TypeError):
            pass

        try:
            timeout_str = os.getenv("TIMEOUT")
            if timeout_str:
                self.timeout = int(timeout_str)
        except (ValueError, TypeError):
            pass

        # Embeddingé…ç½®
        self.embedding_provider = os.getenv("EMBEDDING_PROVIDER", self.embedding_provider)
        self.embedding_model = os.getenv("EMBEDDING_MODEL", self.embedding_model)
        self.embedding_api_key = os.getenv("EMBEDDING_API_KEY", self.embedding_api_key)
        self.embedding_base_url = os.getenv("EMBEDDING_API_BASE", self.embedding_base_url)

        # å¦‚æœembeddingå‚æ•°æœªè®¾ç½®ï¼Œåˆ™å¤ç”¨llmå‚æ•°
        if not self.embedding_provider:
            self.embedding_provider = self.llm_provider
        if not self.embedding_api_key:
            self.embedding_api_key = self.openai_api_key
        if not self.embedding_base_url:
            self.embedding_base_url = self.openai_api_base

    def get_llm_model_id(self) -> str:
        """è·å– LLM æ¨¡å‹ IDï¼Œç”¨äº litellm è°ƒç”¨"""
        if self.llm_provider == "openai":
            return self.llm_model
        return f"{self.llm_provider}/{self.llm_model}"

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        if not self.openai_api_key:
            _get_logger().error("âŒ é”™è¯¯: æœªé…ç½® API_KEY")
            return False

        if self.temperature < 0.0 or self.temperature > 2.0:
            _get_logger().error("âŒ é”™è¯¯: TEMPERATURE å¿…é¡»åœ¨ 0.0-2.0 ä¹‹é—´")
            return False

        return True

    def get_safe_display(self) -> dict:
        """è·å–å®‰å…¨çš„é…ç½®æ˜¾ç¤ºï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
        return {
            "llm_provider": self.llm_provider,
            "llm_model": self.llm_model,
            "openai_api_key": f"{self.openai_api_key[:4]}***"
            if self.openai_api_key
            else "æœªè®¾ç½®",
            "openai_api_base": self.openai_api_base or "é»˜è®¤",
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
            "embedding_provider": self.embedding_provider,
            "embedding_model": self.embedding_model,
            "embedding_api_key": f"{self.embedding_api_key[:4]}***" if self.embedding_api_key else "æœªè®¾ç½®",
            "embedding_base_url": self.embedding_base_url or "é»˜è®¤",
        }


# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()


def get_settings() -> Settings:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    return settings


def reload_settings() -> Settings:
    """é‡æ–°åŠ è½½é…ç½®ï¼ˆç”¨äºæµ‹è¯•æˆ–åŠ¨æ€æ›´æ–°ï¼‰"""
    global settings
    settings = Settings()
    return settings


if __name__ == "__main__":
    logger = _get_logger()
    logger.info("ğŸ”§ é…ç½®éªŒè¯")
    logger.info("=" * 50)

    # éªŒè¯é…ç½®
    if settings.validate():
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        logger.info("\nğŸ“‹ å½“å‰é…ç½®:")
        safe_config = settings.get_safe_display()
        for key, value in safe_config.items():
            logger.info(f"  {key}: {value}")
    else:
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥")
        logger.info("\nè¯·æ£€æŸ¥ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        logger.info("  - API_KEY: å¿…éœ€")
        logger.info("  - LLM_PROVIDER: å¯é€‰ï¼Œé»˜è®¤ openai")
        logger.info("  - MODEL_NAME (æˆ– LLM_MODEL): å¯é€‰ï¼Œé»˜è®¤ gpt-4o-mini")
        logger.info("  - API_BASE: å¯é€‰")
        logger.info("  - TEMPERATURE: å¯é€‰ï¼Œé»˜è®¤ 0.7")
        logger.info("  - MAX_TOKENS: å¯é€‰ï¼Œé»˜è®¤ 4096")
        logger.info("  - TIMEOUT: å¯é€‰ï¼Œé»˜è®¤ 60")
        logger.info("  - EMBEDDING_PROVIDER: å¯é€‰ï¼Œé»˜è®¤å¤ç”¨ LLM_PROVIDER")
        logger.info("  - EMBEDDING_MODEL: å¯é€‰ï¼Œé»˜è®¤ text-embedding-3-small")
        logger.info("  - EMBEDDING_API_KEY: å¯é€‰ï¼Œé»˜è®¤å¤ç”¨ API_KEY")
        logger.info("  - EMBEDDING_API_BASE: å¯é€‰ï¼Œé»˜è®¤å¤ç”¨ API_BASE")
