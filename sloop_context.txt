# Project Directory Structure

./
    config.py
    __init__.py
    core/
    agents/
        service.py
        user.py
        assistant.py
        __init__.py
    utils/
        __init__.py
        llm.py
        logger.py
        template.py
    models/
        blueprint.py
        __init__.py
        state.py
        schema.py
    cli/
        main.py
    templates/
        assistant_think.j2
        assistant_decide.j2
        __init__.py
        assistant_reply.j2
        tool_call_gen.j2
        planner.j2
        user.j2
        service.j2
    engine/
        blueprint.py
        graph.py
        __init__.py
        pda.py

==================================================


==================== FILE: config.py ====================
"""
é…ç½®ç®¡ç†æ¨¡å—

è´Ÿè´£åŠ è½½ç¯å¢ƒå˜é‡å’Œé…ç½®å‚æ•°ï¼Œæ”¯æŒé€šè¿‡.envæ–‡ä»¶è¿›è¡Œé…ç½®ã€‚
"""

import os
from dataclasses import dataclass
from typing import Optional

from dotenv import load_dotenv

from sloop.utils.logger import logger

# åŠ è½½.envæ–‡ä»¶
load_dotenv()


@dataclass
class Settings:
    """åº”ç”¨é…ç½®ç±»"""

    # LLMé…ç½®
    model_name: str = "gpt-4o-mini"
    openai_api_key: Optional[str] = None
    openai_api_base: Optional[str] = None
    temperature: float = 0.7

    # ç³»ç»Ÿé…ç½®
    max_tokens: int = 4096
    timeout: int = 60

    def __post_init__(self):
        """ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–"""
        # LLMé…ç½®
        self.model_name = os.getenv("MODEL_NAME", self.model_name)
        self.openai_api_key = os.getenv("OPENAI_API_KEY", self.openai_api_key)
        self.openai_api_base = os.getenv("OPENAI_API_BASE", self.openai_api_base)

        # æ¸©åº¦å‚æ•°
        try:
            temp_str = os.getenv("TEMPERATURE")
            if temp_str:
                self.temperature = float(temp_str)
        except (ValueError, TypeError):
            pass  # ä½¿ç”¨é»˜è®¤å€¼

        # ç³»ç»Ÿé…ç½®
        try:
            max_tokens_str = os.getenv("MAX_TOKENS")
            if max_tokens_str:
                self.max_tokens = int(max_tokens_str)
        except (ValueError, TypeError):
            pass

        try:
            timeout_str = os.getenv("TIMEOUT")
            if timeout_str:
                self.timeout = int(timeout_str)
        except (ValueError, TypeError):
            pass

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        if not self.openai_api_key:
            logger.error("âŒ é”™è¯¯: æœªé…ç½® OPENAI_API_KEY")
            return False

        if self.temperature < 0.0 or self.temperature > 2.0:
            logger.error("âŒ é”™è¯¯: TEMPERATURE å¿…é¡»åœ¨ 0.0-2.0 ä¹‹é—´")
            return False

        return True

    def get_safe_display(self) -> dict:
        """è·å–å®‰å…¨çš„é…ç½®æ˜¾ç¤ºï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
        return {
            "model_name": self.model_name,
            "openai_api_key": f"{self.openai_api_key[:4]}***"
            if self.openai_api_key
            else "æœªè®¾ç½®",
            "openai_api_base": self.openai_api_base or "é»˜è®¤",
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "timeout": self.timeout,
        }


# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()


def get_settings() -> Settings:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    return settings


def reload_settings() -> Settings:
    """é‡æ–°åŠ è½½é…ç½®ï¼ˆç”¨äºæµ‹è¯•æˆ–åŠ¨æ€æ›´æ–°ï¼‰"""
    global settings
    settings = Settings()
    return settings


if __name__ == "__main__":
    logger.info("ğŸ”§ é…ç½®éªŒè¯")
    logger.info("=" * 50)

    # éªŒè¯é…ç½®
    if settings.validate():
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        logger.info("\nğŸ“‹ å½“å‰é…ç½®:")
        safe_config = settings.get_safe_display()
        for key, value in safe_config.items():
            logger.info(f"  {key}: {value}")
    else:
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥")
        logger.info("\nè¯·æ£€æŸ¥ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        logger.info("  - OPENAI_API_KEY: å¿…éœ€")
        logger.info("  - MODEL_NAME: å¯é€‰ï¼Œé»˜è®¤ gpt-4o-mini")
        logger.info("  - OPENAI_API_BASE: å¯é€‰")
        logger.info("  - TEMPERATURE: å¯é€‰ï¼Œé»˜è®¤ 0.7")
        logger.info("  - MAX_TOKENS: å¯é€‰ï¼Œé»˜è®¤ 4096")
        logger.info("  - TIMEOUT: å¯é€‰ï¼Œé»˜è®¤ 60")


==================== FILE: __init__.py ====================
"""
Sloop - æ™ºèƒ½å¯¹è¯å¾ªç¯ç³»ç»Ÿ

ä¸€ä¸ªåŸºäºä¸‹æ¨è‡ªåŠ¨æœº(PDA)çš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ã€çŠ¶æ€ç®¡ç†å’Œæ ˆæ“ä½œã€‚
"""

__version__ = "0.1.1"

# å¯¼å‡ºä¸»è¦ç»„ä»¶
from sloop import config, engine, models, utils


==================== FILE: agents/service.py ====================
"""
æœåŠ¡æ¨¡æ‹Ÿå™¨ (Service Agent)

æ¨¡æ‹ŸAPIæœåŠ¡æ‰§è¡Œï¼Œæ ¹æ®å·¥å…·è°ƒç”¨æ›´æ–°ç¯å¢ƒçŠ¶æ€ã€‚
"""

import json
from typing import Any, Dict

from sloop.models import Blueprint, EnvState, ToolCall
from sloop.utils.llm import chat_completion
from sloop.utils.logger import logger
from sloop.utils.template import render_service_prompt


class ServiceAgent:
    """
    æœåŠ¡æ™ºèƒ½ä½“

    è´Ÿè´£æ¨¡æ‹ŸAPIæœåŠ¡è°ƒç”¨ï¼Œæ ¹æ®å·¥å…·è°ƒç”¨å’Œå½“å‰çŠ¶æ€ç”Ÿæˆåˆç†çš„å“åº”ï¼Œ
    å¹¶æ›´æ–°ç¯å¢ƒçŠ¶æ€ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡æ™ºèƒ½ä½“"""
        logger.info("ServiceAgent initialized")

    def execute_tool(
        self, tool_call: ToolCall, current_state: EnvState, blueprint: Blueprint
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨

        å‚æ•°:
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            current_state: å½“å‰ç¯å¢ƒçŠ¶æ€
            blueprint: å¯¹è¯è“å›¾ï¼ˆç”¨äºå‚è€ƒï¼‰

        è¿”å›:
            åŒ…å«å“åº”å’ŒçŠ¶æ€æ›´æ–°çš„å­—å…¸
        """
        logger.info(f"Executing tool: {tool_call.name}")

        # æ„é€ æç¤º
        prompt = render_service_prompt(tool_call, current_state, blueprint)

        # è°ƒç”¨LLMç”ŸæˆæœåŠ¡å“åº”
        response = chat_completion(
            prompt=prompt,
            system_message="",
            json_mode=True,
        )

        if not response or response.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to execute tool: {response}")
            return {
                "response": f"Error executing {tool_call.name}",
                "state_updates": {},
            }

        try:
            # è§£æLLMå“åº”
            result = json.loads(response)
            logger.info(f"Tool execution successful: {tool_call.name}")

            # éªŒè¯å“åº”æ ¼å¼
            if not isinstance(result, dict):
                raise ValueError("Response must be a dictionary")

            if "response" not in result:
                result["response"] = f"Executed {tool_call.name}"

            if "state_updates" not in result:
                result["state_updates"] = {}

            # ç¡®ä¿state_updatesæ˜¯å­—å…¸
            if not isinstance(result["state_updates"], dict):
                result["state_updates"] = {}

            return result

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse service response: {e}")
            return {
                "response": f"Executed {tool_call.name} (response parsing failed)",
                "state_updates": {},
            }

    def update_state(
        self, current_state: EnvState, state_updates: Dict[str, Any]
    ) -> EnvState:
        """
        æ›´æ–°ç¯å¢ƒçŠ¶æ€

        å‚æ•°:
            current_state: å½“å‰çŠ¶æ€
            state_updates: çŠ¶æ€æ›´æ–°å­—å…¸

        è¿”å›:
            æ›´æ–°åçš„æ–°çŠ¶æ€
        """
        # åˆ›å»ºçŠ¶æ€å‰¯æœ¬
        new_state = current_state.model_copy()

        # åº”ç”¨æ›´æ–°åˆ°çŠ¶æ€å­—å…¸
        new_state.update(state_updates)

        logger.info(f"State updated with {len(state_updates)} changes")
        return new_state


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    logger.info("ğŸ”§ Service Agent æµ‹è¯•")
    logger.info("=" * 50)

    from sloop.models import Blueprint, EnvState, ToolCall

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·è°ƒç”¨
    mock_tool_call = ToolCall(
        tool_name="search_restaurants",
        arguments={"city": "Shanghai", "cuisine": "Italian"},
    )

    # åˆ›å»ºæ¨¡æ‹ŸçŠ¶æ€
    mock_state = EnvState(
        state={
            "restaurant_found": False,
            "menu_loaded": False,
            "booking_confirmed": False,
        }
    )

    # åˆ›å»ºæ¨¡æ‹Ÿblueprint
    mock_blueprint = Blueprint(
        intent="æŸ¥æ‰¾é¤å…å¹¶é¢„è®¢",
        required_tools=["search_restaurants", "book_restaurant"],
        ground_truth=["search_restaurants", "book_restaurant"],
        initial_state={"restaurant_found": False, "booking_confirmed": False},
        expected_state={"restaurant_found": True, "booking_confirmed": True},
    )

    logger.info("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    logger.info(f"  å·¥å…·è°ƒç”¨: {mock_tool_call.name}")
    logger.info(f"  å‚æ•°: {mock_tool_call.arguments}")
    logger.info(f"  å½“å‰çŠ¶æ€: {mock_state.model_dump()}")
    logger.info("")

    # åˆå§‹åŒ–æœåŠ¡æ™ºèƒ½ä½“
    logger.info("ğŸ”§ åˆå§‹åŒ–ServiceAgent...")
    service_agent = ServiceAgent()

    logger.info("âš™ï¸ æ‰§è¡Œå·¥å…·è°ƒç”¨...")
    try:
        result = service_agent.execute_tool(mock_tool_call, mock_state, mock_blueprint)

        logger.info("âœ… æ‰§è¡ŒæˆåŠŸï¼")
        logger.info(f"ğŸ“ å“åº”: {result['response']}")
        logger.info(f"ğŸ”„ çŠ¶æ€æ›´æ–°: {result['state_updates']}")

        # åº”ç”¨çŠ¶æ€æ›´æ–°
        updated_state = service_agent.update_state(mock_state, result["state_updates"])
        logger.info(f"ğŸ“Š æ›´æ–°åçŠ¶æ€: {updated_state.model_dump()}")

    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
        logger.info("\nğŸ”§ æä¾›æ¨¡æ‹ŸæœåŠ¡å“åº”:")
        mock_result = {
            "response": "Found 5 Italian restaurants in Shanghai",
            "state_updates": {"restaurant_found": True},
        }
        logger.info(f"å“åº”: {mock_result['response']}")
        logger.info(f"çŠ¶æ€æ›´æ–°: {mock_result['state_updates']}")

        # åº”ç”¨æ¨¡æ‹Ÿæ›´æ–°
        updated_state = service_agent.update_state(
            mock_state, mock_result["state_updates"]
        )
        logger.info(f"æ›´æ–°åçŠ¶æ€: {updated_state.model_dump()}")

    logger.info("\nâœ… Service Agent æµ‹è¯•å®Œæˆï¼")


==================== FILE: agents/user.py ====================
"""
ç”¨æˆ·æ¨¡æ‹Ÿå™¨ (User Agent)

æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºï¼Œæ ¹æ®blueprintçš„æ„å›¾å’Œå¯¹è¯å†å²ç”Ÿæˆä¸‹ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ã€‚
"""

from typing import List

from sloop.models import Blueprint, ChatMessage
from sloop.utils.llm import chat_completion
from sloop.utils.logger import logger
from sloop.utils.template import render_user_prompt


class UserAgent:
    """
    ç”¨æˆ·æ™ºèƒ½ä½“

    è´Ÿè´£æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºï¼Œæ ¹æ®ç»™å®šçš„æ„å›¾å’Œå¯¹è¯å†å²ç”Ÿæˆåˆç†çš„ç”¨æˆ·æ¶ˆæ¯ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–ç”¨æˆ·æ™ºèƒ½ä½“"""
        logger.info("UserAgent initialized")

    def generate_message(
        self, blueprint: Blueprint, conversation_history: List[ChatMessage]
    ) -> str:
        """
        ç”Ÿæˆç”¨æˆ·æ¶ˆæ¯

        å‚æ•°:
            blueprint: å¯¹è¯è“å›¾ï¼ŒåŒ…å«ç”¨æˆ·æ„å›¾
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            ç”Ÿæˆçš„ç”¨æˆ·æ¶ˆæ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœä»»åŠ¡å®Œæˆåˆ™è¿”å›"###STOP###"
        """
        logger.info(f"Generating user message for intent: {blueprint.intent}")

        # æ„é€ æç¤º
        prompt = render_user_prompt(blueprint.intent, conversation_history)

        # è°ƒç”¨LLMç”Ÿæˆæ¶ˆæ¯
        response = chat_completion(
            prompt=prompt,
            system_message="",
            json_mode=False,
        )

        if not response or response.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate user message: {response}")
            return "I need help with something."  # é»˜è®¤æ¶ˆæ¯

        # æ£€æŸ¥æ˜¯å¦åŒ…å«åœæ­¢æ ‡è®°
        response = response.strip()
        if "###STOP###" in response:
            logger.info("User indicated task completion")
            return "###STOP###"

        logger.info(f"Generated user message: {response[:100]}...")
        return response

    def is_task_complete(self, message: str) -> bool:
        """
        æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ

        å‚æ•°:
            message: ç”¨æˆ·æ¶ˆæ¯

        è¿”å›:
            æ˜¯å¦å®Œæˆä»»åŠ¡
        """
        return "###STOP###" in message


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    logger.info("ğŸ¤– User Agent æµ‹è¯•")
    logger.info("=" * 50)

    from sloop.models import Blueprint

    # åˆ›å»ºæ¨¡æ‹Ÿblueprint
    mock_blueprint = Blueprint(
        intent="æŸ¥æ‰¾é¤å…å¹¶ç‚¹é¤",
        required_tools=["find_restaurants", "get_menu"],
        ground_truth=["find_restaurants", "get_menu"],
        initial_state={"restaurant_found": False},
        expected_state={"restaurant_found": True, "menu_loaded": True},
    )

    # åˆ›å»ºæ¨¡æ‹Ÿå¯¹è¯å†å²
    mock_history = [
        ChatMessage(role="assistant", content="ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"),
        ChatMessage(role="user", content="æˆ‘æƒ³æ‰¾ä¸€å®¶é¤å…åƒé¥­"),
    ]

    logger.info("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    logger.info(f"  æ„å›¾: {mock_blueprint.intent}")
    logger.info(f"  å†å²æ¶ˆæ¯æ•°: {len(mock_history)}")
    logger.info("")

    # åˆå§‹åŒ–ç”¨æˆ·æ™ºèƒ½ä½“
    logger.info("ğŸ”§ åˆå§‹åŒ–UserAgent...")
    user_agent = UserAgent()

    logger.info("ğŸ’¬ ç”Ÿæˆç”¨æˆ·æ¶ˆæ¯...")
    try:
        message = user_agent.generate_message(mock_blueprint, mock_history)

        logger.info("âœ… ç”ŸæˆæˆåŠŸï¼")
        logger.info(f"ğŸ“ æ¶ˆæ¯å†…å®¹: {message}")

        if user_agent.is_task_complete(message):
            logger.info("ğŸ¯ ä»»åŠ¡å·²å®Œæˆ")
        else:
            logger.info("ğŸ”„ ä»»åŠ¡ç»§ç»­")

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
        logger.info("\nğŸ”§ æä¾›æ¨¡æ‹Ÿç”¨æˆ·æ¶ˆæ¯:")
        logger.info("æˆ‘æƒ³åœ¨å¸‚ä¸­å¿ƒæ‰¾ä¸€å®¶ä¸­é¤å…ã€‚")

    logger.info("\nâœ… User Agent æµ‹è¯•å®Œæˆï¼")


==================== FILE: agents/assistant.py ====================
"""
åŠ©æ‰‹æ¨¡æ‹Ÿå™¨ (Assistant Agent)

æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
"""

import json
import re
from typing import List

from sloop.models import ChatMessage, ToolCall, ToolDefinition
from sloop.utils.llm import chat_completion
from sloop.utils.logger import logger
from sloop.utils.template import (
    render_assistant_decide_prompt,
    render_assistant_reply_prompt,
    render_assistant_think_prompt,
    render_tool_call_gen_prompt,
)


class AssistantAgent:
    """
    åŠ©æ‰‹æ™ºèƒ½ä½“

    è´Ÿè´£æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²ç”Ÿæˆå“åº”ï¼Œ
    å¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ã€‚
    """

    def __init__(self, tools: List[ToolDefinition]):
        """
        åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“

        å‚æ•°:
            tools: å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

        logger.info(f"AssistantAgent initialized with {len(tools)} tools")

    def parse_tool_calls(self, response: str) -> List[ToolCall]:
        """
        ä»å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []

        # å°è¯•è§£æJSONæ ¼å¼çš„å·¥å…·è°ƒç”¨
        # æŸ¥æ‰¾ç±»ä¼¼ {"tool_name": "...", "arguments": {...}} çš„æ¨¡å¼ï¼ˆå…¼å®¹nameå­—æ®µï¼‰
        json_pattern = r'\{[^}]*"(?:tool_name|name)"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
        matches = re.findall(json_pattern, response, re.DOTALL)

        for match in matches:
            tool_name, args_str = match
            try:
                arguments = json.loads(args_str)
                if tool_name in self.tool_map:
                    tool_call = ToolCall(name=tool_name, arguments=arguments)
                    tool_calls.append(tool_call)
                    logger.info(f"Parsed tool call: {tool_name}")
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse tool call arguments: {args_str}")

        # å¦‚æœæ²¡æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾å‡½æ•°è°ƒç”¨æ¨¡å¼
        if not tool_calls:
            # æŸ¥æ‰¾ function_call æ¨¡å¼
            func_pattern = r'"function_call"\s*:\s*\{[^}]*"name"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
            func_matches = re.findall(func_pattern, response, re.DOTALL)

            for match in func_matches:
                tool_name, args_str = match
                try:
                    arguments = json.loads(args_str)
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(name=tool_name, arguments=arguments)
                        tool_calls.append(tool_call)
                        logger.info(f"Parsed function call: {tool_name}")
                except json.JSONDecodeError:
                    logger.warning(
                        f"Failed to parse function call arguments: {args_str}"
                    )

        return tool_calls

    def should_call_tools(self, response: str) -> bool:
        """
        åˆ¤æ–­å“åº”æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
        """
        return len(self.parse_tool_calls(response)) > 0

    def generate_thought(
        self, conversation_history: List[ChatMessage], context_hint: str = ""
    ) -> str:
        """
        ç”ŸæˆåŠ©æ‰‹æ€è€ƒè¿‡ç¨‹ (Chain of Thought)

        å‚æ•°:
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨
            context_hint: æ ˆä¸Šä¸‹æ–‡æç¤ºä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        """
        logger.info("Generating assistant thought process (CoT)")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_think_prompt(conversation_history, context_hint)

        # è°ƒç”¨LLMç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thought = chat_completion(
            prompt=prompt,
            system_message="",
            json_mode=False,
        )

        if not thought or thought.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate thought: {thought}")
            return "æˆ‘éœ€è¦åˆ†æç”¨æˆ·çš„è¯·æ±‚å¹¶ç¡®å®šæœ€ä½³å“åº”æ–¹å¼ã€‚"

        logger.info(f"Generated thought: {thought[:100]}...")
        return thought.strip()

    def decide_tool_use(self, thought: str) -> bool:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        """
        logger.info("Deciding whether to use tools based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_decide_prompt(thought, self.tools)

        decision = (
            chat_completion(
                prompt=prompt,
                system_message="",
                json_mode=False,
            )
            .strip()
            .upper()
        )

        needs_tools = decision.startswith("YES")
        logger.info(f"Tool use decision: {needs_tools}")
        return needs_tools

    def generate_tool_calls(
        self, thought: str, tools: List[ToolDefinition]
    ) -> List[ToolCall]:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨

        è¿”å›:
            å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        logger.info("Generating tool calls based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_tool_call_gen_prompt(thought, tools)

        response = chat_completion(
            prompt=prompt,
            system_message="",
            json_mode=True,
        )

        try:
            tool_calls_data = json.loads(response)
            if not isinstance(tool_calls_data, list):
                tool_calls_data = [tool_calls_data]

            tool_calls = []
            for call_data in tool_calls_data:
                if (
                    isinstance(call_data, dict)
                    and "name" in call_data
                    and "arguments" in call_data
                ):
                    tool_name = call_data["name"]
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(
                            name=tool_name, arguments=call_data["arguments"]
                        )
                        tool_calls.append(tool_call)
                        logger.info(f"Generated tool call: {tool_name}")

            return tool_calls

        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Failed to parse generated tool calls: {e}")
            return []

    def generate_reply(
        self, thought: str, conversation_history: List[ChatMessage]
    ) -> str:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            æœ€ç»ˆå›å¤å­—ç¬¦ä¸²
        """
        logger.info("Generating final reply based on thought process")

        # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤º
        prompt = render_assistant_reply_prompt(thought, conversation_history)

        reply = chat_completion(
            prompt=prompt,
            system_message="",
            json_mode=False,
        )

        if not reply or reply.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate reply: {reply}")
            return "æˆ‘å¾ˆä¹æ„ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼æœ‰ä»€ä¹ˆå¯ä»¥æ•ˆåŠ³çš„å—ï¼Ÿ"

        logger.info(f"Generated reply: {reply[:100]}...")
        return reply.strip()


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    logger.info("ğŸ¤– Assistant Agent æµ‹è¯•")
    logger.info("=" * 50)

    from sloop.models import ChatMessage, ToolDefinition

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·
    mock_tools = [
        ToolDefinition(
            name="search_restaurants",
            description="Search for restaurants in a city",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"},
                    "cuisine": {"type": "string", "description": "Type of cuisine"},
                },
                "required": ["city"],
            },
        ),
        ToolDefinition(
            name="book_restaurant",
            description="Book a table at a restaurant",
            parameters={
                "type": "object",
                "properties": {
                    "restaurant_id": {"type": "string", "description": "Restaurant ID"},
                    "date": {"type": "string", "description": "Booking date"},
                    "time": {"type": "string", "description": "Booking time"},
                    "party_size": {
                        "type": "integer",
                        "description": "Number of people",
                    },
                },
                "required": ["restaurant_id", "date", "time"],
            },
        ),
    ]

    # åˆ›å»ºæ¨¡æ‹Ÿå¯¹è¯å†å²
    mock_history = [
        ChatMessage(role="user", content="æˆ‘æƒ³åœ¨ä¸Šæµ·æ‰¾ä¸€å®¶æ„å¤§åˆ©é¤å…åƒé¥­"),
        ChatMessage(
            role="assistant",
            content="æˆ‘æ¥å¸®ä½ æ‰¾ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚ä½ æƒ³è¦ä»€ä¹ˆæ ·çš„ä»·ä½æˆ–åœ°ç‚¹å—ï¼Ÿ",
        ),
        ChatMessage(role="user", content="å¸‚ä¸­å¿ƒå°±å¯ä»¥ï¼Œé€‚åˆ4ä¸ªäºº"),
    ]

    logger.info("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    logger.info(f"  å¯ç”¨å·¥å…·æ•°: {len(mock_tools)}")
    for tool in mock_tools:
        logger.info(f"    - {tool.name}: {tool.description}")
    logger.info(f"  å¯¹è¯å†å²: {len(mock_history)} æ¡æ¶ˆæ¯")
    logger.info("")

    # åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“
    logger.info("ğŸ”§ åˆå§‹åŒ–AssistantAgent...")
    assistant_agent = AssistantAgent(mock_tools)

    logger.info("ğŸ”§ æµ‹è¯•å·¥å…·è°ƒç”¨è§£æ...")
    try:
        # æµ‹è¯•è§£æåŠŸèƒ½
        mock_response = 'æˆ‘æ¥å¸®ä½ æœç´¢ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚{"tool_name": "search_restaurants", "arguments": {"city": "ä¸Šæµ·", "cuisine": "æ„å¤§åˆ©èœ"}}'
        logger.info(f"ğŸ“ æµ‹è¯•å“åº”: {mock_response}")

        # è§£æå·¥å…·è°ƒç”¨
        tool_calls = assistant_agent.parse_tool_calls(mock_response)
        if tool_calls:
            logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for i, tool_call in enumerate(tool_calls, 1):
                logger.info(f"  {i}. {tool_call.name}: {tool_call.arguments}")
        else:
            logger.info("ğŸ’¬ çº¯æ–‡æœ¬å“åº”ï¼Œæ— å·¥å…·è°ƒç”¨")

    except Exception as e:
        logger.error(f"âŒ è§£æå¤±è´¥: {e}")

    logger.info("\nâœ… Assistant Agent æµ‹è¯•å®Œæˆï¼")


==================== FILE: agents/__init__.py ====================
"""
æ™ºèƒ½ä»£ç†æ¨¡å—

åŒ…å«å„ç§AIä»£ç†çš„æ ¸å¿ƒé€»è¾‘ç±»ã€‚
"""

from sloop.agents.assistant import AssistantAgent
from sloop.agents.service import ServiceAgent
from sloop.agents.user import UserAgent

__all__ = [
    "UserAgent",
    "AssistantAgent",
    "ServiceAgent",
]


==================== FILE: utils/__init__.py ====================
"""
å·¥å…·å‡½æ•°åŒ…

å¯¼å‡ºå„ç§å®ç”¨å·¥å…·å‡½æ•°ã€‚
"""

from sloop.utils.llm import completion

__all__ = [
    "completion",
]


==================== FILE: utils/llm.py ====================
"""
LLM è°ƒç”¨å°è£…å·¥å…·

åŸºäº litellm æä¾›ç»Ÿä¸€çš„æ¨¡å‹è°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œé…ç½®ã€‚
"""

import sys
from typing import Any, Dict, List, Optional

import litellm

from sloop.utils.logger import logger

# è®¾ç½®æ—¥å¿—


def completion(
    messages: List[Dict[str, Any]], json_mode: bool = False, **kwargs
) -> str:
    """
    ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£

    å‚æ•°:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒOpenAIæ ¼å¼
        json_mode: æ˜¯å¦å¯ç”¨JSONæ¨¡å¼
        **kwargs: å…¶ä»–å‚æ•°ï¼Œä¼šè¦†ç›–é»˜è®¤è®¾ç½®

    è¿”å›:
        æ¨¡å‹å“åº”å†…å®¹å­—ç¬¦ä¸²

    å¼‚å¸¸:
        å„ç§LLMè°ƒç”¨å¼‚å¸¸ä¼šè¢«æ•è·å¹¶è®°å½•ï¼Œä½†ä¸æŠ›å‡º
    """
    from sloop.config import get_settings

    settings = get_settings()

    # éªŒè¯é…ç½®
    if not settings.validate():
        error_msg = "LLMé…ç½®æ— æ•ˆï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡"
        logger.error(error_msg)
        return f"é…ç½®é”™è¯¯: {error_msg}"

    try:
        # æ£€æŸ¥API keyæ˜¯å¦æœ‰æ•ˆ
        if not settings.openai_api_key or len(str(settings.openai_api_key)) < 10:
            error_msg = "API keyæ— æ•ˆæˆ–æœªé…ç½®ï¼Œè¯·æ£€æŸ¥OPENAI_API_KEYç¯å¢ƒå˜é‡"
            logger.error(error_msg)
            return f"é…ç½®é”™è¯¯: {error_msg}"

        # å‡†å¤‡è°ƒç”¨å‚æ•°
        call_kwargs = {
            "model": settings.model_name,
            "messages": messages,
            "temperature": settings.temperature,
            "max_tokens": settings.max_tokens,
            "timeout": settings.timeout,
            "api_key": settings.openai_api_key,
        }

        # å¦‚æœè®¾ç½®äº†API base URL
        if settings.openai_api_base:
            call_kwargs["api_base"] = settings.openai_api_base

        # JSONæ¨¡å¼å¤„ç†
        if json_mode:
            # å¯¹äºOpenAIå…¼å®¹çš„API
            if (
                "gpt" in settings.model_name.lower()
                or "openai" in settings.model_name.lower()
            ):
                call_kwargs["response_format"] = {"type": "json_object"}
            # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œåœ¨ç³»ç»Ÿæ¶ˆæ¯ä¸­æ·»åŠ JSONæŒ‡ä»¤
            elif messages and messages[0].get("role") == "system":
                messages[0]["content"] += "\n\nè¯·ä»¥JSONæ ¼å¼å“åº”ã€‚"
            else:
                # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
                system_msg = {"role": "system", "content": "è¯·ä»¥JSONæ ¼å¼å“åº”ã€‚"}
                messages.insert(0, system_msg)

        # åˆå¹¶ç”¨æˆ·æä¾›çš„é¢å¤–å‚æ•°
        call_kwargs.update(kwargs)

        logger.info(f"è°ƒç”¨LLM: {settings.model_name}, æ¶ˆæ¯æ•°é‡: {len(messages)}")

        # è°ƒç”¨æ¨¡å‹
        response = litellm.completion(**call_kwargs)

        # æå–å“åº”å†…å®¹
        if hasattr(response, "choices") and response.choices:
            content = response.choices[0].message.content
            if content:
                logger.info(f"LLMå“åº”æˆåŠŸï¼Œé•¿åº¦: {len(content)}")
                return content

        # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        logger.warning("LLMè¿”å›ç©ºå“åº”")
        return ""

    except Exception as e:
        error_msg = f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return f"è°ƒç”¨é”™è¯¯: {error_msg}"


def chat_completion(
    prompt: str, system_message: Optional[str] = None, json_mode: bool = False, **kwargs
) -> str:
    """
    ç®€åŒ–çš„èŠå¤©å®Œæˆæ¥å£

    å‚æ•°:
        prompt: ç”¨æˆ·æç¤º
        system_message: ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
        json_mode: æ˜¯å¦å¯ç”¨JSONæ¨¡å¼
        **kwargs: å…¶ä»–å‚æ•°

    è¿”å›:
        æ¨¡å‹å“åº”å†…å®¹
    """
    messages = []

    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    if system_message:
        messages.append({"role": "system", "content": system_message})

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": prompt})

    return completion(messages, json_mode=json_mode, **kwargs)


def validate_llm_config() -> bool:
    """
    éªŒè¯LLMé…ç½®æ˜¯å¦æœ‰æ•ˆ

    è¿”å›:
        é…ç½®æ˜¯å¦æœ‰æ•ˆ
    """
    from sloop.config import get_settings

    settings = get_settings()
    return settings.validate()


def get_supported_models() -> List[str]:
    """
    è·å–litellmæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼ˆç¤ºä¾‹ï¼‰

    è¿”å›:
        æ”¯æŒçš„æ¨¡å‹åç§°åˆ—è¡¨
    """
    # è¿™é‡Œè¿”å›ä¸€äº›å¸¸è§çš„æ¨¡å‹ä½œä¸ºç¤ºä¾‹
    # å®é™…åº”è¯¥ä»litellmè·å–å®Œæ•´åˆ—è¡¨
    return [
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-3.5-turbo",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307",
        "gemini-pro",
        "deepseek-chat",
        "qwen2-72b-instruct",
    ]


if __name__ == "__main__":
    from sloop.config import get_settings

    logger.info("ğŸ”§ LLM é…ç½®å’Œè°ƒç”¨æµ‹è¯•")
    logger.info("=" * 50)

    # æµ‹è¯•é…ç½®éªŒè¯
    logger.info("ğŸ“‹ é…ç½®çŠ¶æ€:")
    settings = get_settings()
    if settings.validate():
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        safe_config = settings.get_safe_display()
        for key, value in safe_config.items():
            logger.info(f"  {key}: {value}")
    else:
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥")
        logger.info("\nè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        logger.info("  OPENAI_API_KEY=your_api_key_here")
        logger.info("  MODEL_NAME=gpt-4o-mini  # å¯é€‰")
        logger.info("  OPENAI_API_BASE=https://api.openai.com/v1  # å¯é€‰")
        logger.info("  TEMPERATURE=0.7  # å¯é€‰")
        sys.exit(1)

    logger.info("\nğŸ§ª ç®€å•è°ƒç”¨æµ‹è¯•:")

    # æµ‹è¯•ç®€å•è°ƒç”¨ï¼ˆå¦‚æœé…ç½®äº†æœ‰æ•ˆçš„API keyï¼‰
    if settings.openai_api_key and len(settings.openai_api_key) > 10:  # ç®€å•çš„keyéªŒè¯
        try:
            response = chat_completion(
                prompt="è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", system_message="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚"
            )

            if response and not response.startswith("è°ƒç”¨é”™è¯¯"):
                logger.info("âœ… LLMè°ƒç”¨æˆåŠŸ")
                logger.info(f"å“åº”é¢„è§ˆ: {response[:100]}...")
            else:
                logger.warning("âš ï¸ LLMè°ƒç”¨å¤±è´¥æˆ–æ— å“åº”")
                logger.warning(f"å“åº”: {response}")

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è°ƒç”¨å¤±è´¥: {e}")
    else:
        logger.info("â„¹ï¸ æœªé…ç½®æœ‰æ•ˆçš„API Keyï¼Œè·³è¿‡å®é™…è°ƒç”¨æµ‹è¯•")

    logger.info("\nğŸ“š æ”¯æŒçš„æ¨¡å‹ç¤ºä¾‹:")
    models = get_supported_models()
    for i, model in enumerate(models[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
        logger.info(f"  {i}. {model}")
    if len(models) > 5:
        logger.info(f"  ... è¿˜æœ‰ {len(models) - 5} ä¸ªæ¨¡å‹")

    logger.info("\nâœ… LLMå·¥å…·æµ‹è¯•å®Œæˆ")


==================== FILE: utils/logger.py ====================
import os

from loguru import logger
from tqdm import tqdm


def tqdm_sink(msg):
    """è‡ªå®šä¹‰ sinkï¼Œä½¿ç”¨ tqdm.write è¾“å‡ºæ—¥å¿—ï¼Œé¿å…ä¸è¿›åº¦æ¡å†²çª"""
    tqdm.write(str(msg), end="")


# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
log_dir = os.path.join(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "logs"
)
os.makedirs(log_dir, exist_ok=True)

# ç§»é™¤é»˜è®¤çš„ loguru handler
logger.remove()

# æ·»åŠ æ§åˆ¶å°è¾“å‡º
logger.add(
    tqdm_sink,
    level="INFO",
    format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    colorize=True,
)

# æ·»åŠ æ–‡ä»¶è¾“å‡ºï¼Œæ”¯æŒè½®æ¢å’Œå‹ç¼©
logger.add(
    os.path.join(log_dir, "file_{time:YYYY-MM-DD}.log"),
    level="DEBUG",
    rotation="1 day",  # æ¯å¤©è½®æ¢
    compression="zip",  # å‹ç¼©æ—§æ—¥å¿—æ–‡ä»¶
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
    enqueue=True,  # å¼‚æ­¥å†™å…¥
    retention="7 days",  # ä¿ç•™7å¤©æ—¥å¿—
)

# å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šçš„é…ç½®ï¼Œä¾‹å¦‚ä¸åŒçš„æ—¥å¿—çº§åˆ«ã€è¿‡æ»¤å™¨ç­‰

# å¯¼å‡º logger å®ä¾‹
__all__ = ["logger"]


==================== FILE: utils/template.py ====================
"""
ç»Ÿä¸€æ¨¡æ¿ç®¡ç†æ¨¡å—

è´Ÿè´£æ‰€æœ‰Jinja2æ¨¡æ¿çš„åŠ è½½å’Œæ¸²æŸ“ã€‚
"""

import os

from jinja2 import Template


def _get_template_path(template_name: str) -> str:
    """
    è·å–æ¨¡æ¿æ–‡ä»¶è·¯å¾„

    å‚æ•°:
        template_name: æ¨¡æ¿æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰

    è¿”å›:
        æ¨¡æ¿æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    """
    # ä»utilsç›®å½•å‘ä¸ŠæŸ¥æ‰¾templatesç›®å½•
    utils_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(utils_dir)  # src/sloop
    template_path = os.path.join(project_root, "templates", f"{template_name}.j2")
    return template_path


def _load_template(template_name: str) -> Template:
    """
    åŠ è½½æ¨¡æ¿æ–‡ä»¶

    å‚æ•°:
        template_name: æ¨¡æ¿æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    template_path = _get_template_path(template_name)

    with open(template_path, "r", encoding="utf-8") as f:
        template_content = f.read()

    return Template(template_content)


def get_planner_template() -> Template:
    """
    è·å–è“å›¾è§„åˆ’å™¨çš„Jinja2æ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("planner")


def render_planner_prompt(tool_chain: list, tool_definitions: list) -> str:
    """
    æ¸²æŸ“è“å›¾è§„åˆ’å™¨æç¤º

    å‚æ•°:
        tool_chain: å·¥å…·è°ƒç”¨é“¾åˆ—è¡¨
        tool_definitions: å·¥å…·å®šä¹‰åˆ—è¡¨

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_planner_template()

    # å°†ToolDefinitionå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä»¥ä¾¿JSONåºåˆ—åŒ–
    tool_definitions_dict = []
    for tool in tool_definitions:
        tool_dict = {
            "name": tool.name,
            "description": tool.description,
            "parameters": tool.parameters.model_dump()
            if hasattr(tool.parameters, "model_dump")
            else tool.parameters,
        }
        tool_definitions_dict.append(tool_dict)

    return template.render(
        tool_chain=tool_chain, tool_definitions=tool_definitions_dict
    )


def get_user_template():
    """
    è·å–ç”¨æˆ·æ™ºèƒ½ä½“æ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("user")


def render_user_prompt(intent: str, conversation_history: list) -> str:
    """
    æ¸²æŸ“ç”¨æˆ·æ™ºèƒ½ä½“æç¤º

    å‚æ•°:
        intent: ç”¨æˆ·æ„å›¾
        conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_user_template()

    # è½¬æ¢æ¶ˆæ¯å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼ï¼ˆå…¼å®¹å¯¹è±¡å’Œå­—å…¸ï¼‰
    history_dict = []
    for message in conversation_history:
        if hasattr(message, "role") and hasattr(message, "content"):
            # è¿™æ˜¯ChatMessageå¯¹è±¡
            msg_dict = {"role": message.role, "content": message.content}
        else:
            # è¿™å·²ç»æ˜¯å­—å…¸äº†
            msg_dict = message
        history_dict.append(msg_dict)

    return template.render(intent=intent, conversation_history=history_dict)


def get_service_template():
    """
    è·å–æœåŠ¡æ™ºèƒ½ä½“æ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("service")


def render_service_prompt(
    tool_call, current_state, blueprint, conversation_history=None
) -> str:
    """
    æ¸²æŸ“æœåŠ¡æ™ºèƒ½ä½“æç¤º

    å‚æ•°:
        tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
        current_state: å½“å‰çŠ¶æ€å¯¹è±¡
        blueprint: è“å›¾å¯¹è±¡
        conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_service_template()

    # è½¬æ¢å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼ï¼ˆå…¼å®¹å¯¹è±¡å’Œå­—å…¸ï¼‰
    if hasattr(tool_call, "name") and hasattr(tool_call, "arguments"):
        # è¿™æ˜¯ToolCallå¯¹è±¡
        tool_call_dict = {"tool_name": tool_call.name, "arguments": tool_call.arguments}
    else:
        # è¿™å·²ç»æ˜¯å­—å…¸äº†
        tool_call_dict = tool_call

    state_dict = (
        current_state.model_dump()
        if hasattr(current_state, "model_dump")
        else current_state.__dict__
    )

    blueprint_dict = {
        "intent": blueprint.intent,
        "expected_state": blueprint.expected_state,
    }

    # è½¬æ¢å¯¹è¯å†å²ä¸ºå­—å…¸æ ¼å¼
    history_dict = []
    if conversation_history:
        for message in conversation_history:
            if hasattr(message, "role") and hasattr(message, "content"):
                # è¿™æ˜¯ChatMessageå¯¹è±¡
                msg_dict = {"role": message.role, "content": message.content}
            else:
                # è¿™å·²ç»æ˜¯å­—å…¸äº†
                msg_dict = message
            history_dict.append(msg_dict)

    return template.render(
        tool_call=tool_call_dict,
        current_state=state_dict,
        blueprint=blueprint_dict,
        conversation_history=history_dict,
    )


def get_assistant_think_template():
    """
    è·å–åŠ©æ‰‹æ€è€ƒæ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("assistant_think")


def render_assistant_think_prompt(
    conversation_history: list, context_hint: str = ""
) -> str:
    """
    æ¸²æŸ“åŠ©æ‰‹æ€è€ƒæç¤º

    å‚æ•°:
        conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨
        context_hint: æ ˆä¸Šä¸‹æ–‡æç¤ºä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_assistant_think_template()

    # è½¬æ¢æ¶ˆæ¯å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
    history_dict = []
    for message in conversation_history:
        msg_dict = {"role": message.role, "content": message.content}
        history_dict.append(msg_dict)

    return template.render(conversation_history=history_dict, context_hint=context_hint)


def get_assistant_decide_template():
    """
    è·å–åŠ©æ‰‹å†³ç­–æ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("assistant_decide")


def render_assistant_decide_prompt(thought: str, tools: list) -> str:
    """
    æ¸²æŸ“åŠ©æ‰‹å†³ç­–æç¤º

    å‚æ•°:
        thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        tools: å·¥å…·å®šä¹‰åˆ—è¡¨

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_assistant_decide_template()

    # è½¬æ¢å·¥å…·å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
    tools_dict = []
    for tool in tools:
        tool_dict = {
            "name": tool.name,
            "description": tool.description,
            "parameters": tool.parameters.model_dump()
            if hasattr(tool.parameters, "model_dump")
            else tool.parameters,
        }
        tools_dict.append(tool_dict)

    return template.render(thought=thought, tools=tools_dict)


def get_tool_call_gen_template():
    """
    è·å–å·¥å…·è°ƒç”¨ç”Ÿæˆæ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("tool_call_gen")


def render_tool_call_gen_prompt(thought: str, tools: list) -> str:
    """
    æ¸²æŸ“å·¥å…·è°ƒç”¨ç”Ÿæˆæç¤º

    å‚æ•°:
        thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        tools: å·¥å…·å®šä¹‰åˆ—è¡¨

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_tool_call_gen_template()

    # è½¬æ¢å·¥å…·å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
    tools_dict = []
    for tool in tools:
        tool_dict = {
            "name": tool.name,
            "description": tool.description,
            "parameters": tool.parameters.model_dump()
            if hasattr(tool.parameters, "model_dump")
            else tool.parameters,
        }
        tools_dict.append(tool_dict)

    return template.render(thought=thought, tools=tools_dict)


def get_assistant_reply_template():
    """
    è·å–åŠ©æ‰‹å›å¤æ¨¡æ¿

    è¿”å›:
        ç¼–è¯‘åçš„Jinja2æ¨¡æ¿å¯¹è±¡
    """
    return _load_template("assistant_reply")


def render_assistant_reply_prompt(thought: str, conversation_history: list) -> str:
    """
    æ¸²æŸ“åŠ©æ‰‹å›å¤æç¤º

    å‚æ•°:
        thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

    è¿”å›:
        æ¸²æŸ“åçš„æç¤ºå­—ç¬¦ä¸²
    """
    template = get_assistant_reply_template()

    # è½¬æ¢æ¶ˆæ¯å¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
    history_dict = []
    for message in conversation_history:
        msg_dict = {"role": message.role, "content": message.content}
        history_dict.append(msg_dict)

    return template.render(thought=thought, conversation_history=history_dict)


==================== FILE: models/blueprint.py ====================
"""
è“å›¾æ•°æ®æ¨¡å‹ï¼šä»»åŠ¡è“å›¾å®šä¹‰

åŒ…å«ç”¨æˆ·æ„å›¾ã€å¿…éœ€å·¥å…·ã€æ‰§è¡Œè·¯å¾„å’ŒçŠ¶æ€å®šä¹‰ã€‚
"""

from typing import Any, Dict, List

from pydantic import BaseModel, Field


class Blueprint(BaseModel):
    """
    ä»»åŠ¡è“å›¾ï¼šå®šä¹‰å¯¹è¯ç”Ÿæˆçš„ä»»åŠ¡å¤§çº²

    åœ¨æ­£å¼å¯¹è¯å‰å…ˆç”Ÿæˆè“å›¾ï¼Œç¡®ä¿å¤šè½®å¯¹è¯æœ‰æ˜ç¡®çš„ç»ˆç‚¹å’Œé€»è¾‘ä¸€è‡´æ€§ã€‚
    """

    intent: str = Field(..., description="ç”¨æˆ·çš„é«˜å±‚æ„å›¾æè¿°")
    required_tools: List[str] = Field(..., description="å¿…é¡»ä½¿ç”¨çš„å·¥å…·åç§°åˆ—è¡¨")
    ground_truth: List[str] = Field(
        ..., description="é¢„æœŸçš„æ­£ç¡®è°ƒç”¨åºåˆ—ï¼ˆå·¥å…·åç§°åˆ—è¡¨ï¼‰"
    )
    initial_state: Dict[str, Any] = Field(..., description="ç¯å¢ƒåˆå§‹çŠ¶æ€å­—å…¸")
    expected_state: Dict[str, Any] = Field(..., description="ç»“æŸæ—¶æœŸæœ›çŠ¶æ€å­—å…¸")

    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µä»¥æ”¯æŒæ‰©å±•

    def validate_state_transition(self) -> bool:
        """
        éªŒè¯åˆå§‹çŠ¶æ€å’ŒæœŸæœ›çŠ¶æ€çš„é”®æ˜¯å¦ä¸€è‡´

        è¿”å›: bool - çŠ¶æ€è½¬æ¢æ˜¯å¦æœ‰æ•ˆ
        """
        return set(self.initial_state.keys()) == set(self.expected_state.keys())

    def get_tool_sequence_str(self) -> str:
        """
        è·å–å·¥å…·è°ƒç”¨åºåˆ—çš„å­—ç¬¦ä¸²è¡¨ç¤º

        è¿”å›: str - å·¥å…·åºåˆ—æè¿°
        """
        return " -> ".join(self.ground_truth)

    def __str__(self) -> str:
        """è“å›¾çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"Blueprint(intent='{self.intent}', tools={self.required_tools}, sequence={self.get_tool_sequence_str()})"


==================== FILE: models/__init__.py ====================
"""
Sloop æ•°æ®æ¨¡å‹åŒ…

å¯¼å‡ºæ‰€æœ‰æ ¸å¿ƒæ•°æ®æ¨¡å‹ç±»ã€‚
"""

from sloop.models.blueprint import Blueprint
from sloop.models.schema import ChatMessage, ToolCall, ToolDefinition
from sloop.models.state import ConversationContext, EnvState

__all__ = [
    "ToolDefinition",
    "ToolCall",
    "ChatMessage",
    "Blueprint",
    "EnvState",
    "ConversationContext",
]


==================== FILE: models/state.py ====================
"""
çŠ¶æ€æ•°æ®æ¨¡å‹ï¼šç¯å¢ƒçŠ¶æ€å’Œå¯¹è¯ä¸Šä¸‹æ–‡

ç”¨äºæœ‰çŠ¶æ€æœåŠ¡æ¨¡æ‹Ÿå’ŒPDAçŠ¶æ€ä¼ é€’ã€‚
"""

from datetime import datetime
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

from sloop.models.schema import ChatMessage, ToolCall


class EnvState(BaseModel):
    """
    è™šæ‹Ÿç¯å¢ƒçŠ¶æ€ï¼šç»´æŠ¤æœ‰çŠ¶æ€çš„å·¥å…·è°ƒç”¨ç¯å¢ƒ

    æ¨¡æ‹ŸçœŸå®APIçš„çŠ¶æ€å˜æ›´ï¼Œé¿å…LLMäº§ç”Ÿé€»è¾‘å¹»è§‰ã€‚
    """

    state: Dict[str, Any] = Field(default_factory=dict, description="å½“å‰ç¯å¢ƒçŠ¶æ€å­—å…¸")
    history: List[Dict[str, Any]] = Field(
        default_factory=list, description="çŠ¶æ€å˜æ›´å†å²è®°å½•"
    )

    def get(self, key: str, default: Any = None) -> Any:
        """è·å–çŠ¶æ€å€¼"""
        return self.state.get(key, default)

    def set(self, key: str, value: Any) -> None:
        """è®¾ç½®çŠ¶æ€å€¼å¹¶è®°å½•å†å²"""
        old_value = self.state.get(key)
        self.state[key] = value

        # è®°å½•å˜æ›´å†å²
        self.history.append({
            "timestamp": datetime.now().isoformat(),
            "key": key,
            "old_value": old_value,
            "new_value": value,
            "action": "set",
        })

    def update(self, updates: Dict[str, Any]) -> None:
        """æ‰¹é‡æ›´æ–°çŠ¶æ€"""
        for key, value in updates.items():
            self.set(key, value)

    def reset(self) -> None:
        """é‡ç½®çŠ¶æ€"""
        self.state.clear()
        self.history.clear()

    def validate_transition(self, expected_state: Dict[str, Any]) -> bool:
        """
        éªŒè¯å½“å‰çŠ¶æ€æ˜¯å¦ç¬¦åˆæœŸæœ›çŠ¶æ€

        å‚æ•°:
            expected_state: æœŸæœ›çš„çŠ¶æ€å­—å…¸

        è¿”å›: bool - æ˜¯å¦åŒ¹é…
        """
        return self.state == expected_state

    def __str__(self) -> str:
        """çŠ¶æ€çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"EnvState({self.state})"


class ConversationContext(BaseModel):
    """
    å¯¹è¯ä¸Šä¸‹æ–‡ï¼šç”¨äºPDAä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯

    åŒ…å«å¯¹è¯å†å²ã€è½®æ¬¡è®¡æ•°ã€å½“å‰çŠ¶æ€å’Œæ ˆç®¡ç†ç­‰ã€‚
    """

    conversation_id: str = Field(..., description="å¯¹è¯å”¯ä¸€æ ‡è¯†")
    blueprint_id: Optional[str] = Field(None, description="å…³è”çš„è“å›¾ID")

    messages: List[ChatMessage] = Field(
        default_factory=list, description="å¯¹è¯æ¶ˆæ¯å†å²"
    )
    turn_count: int = Field(default=0, description="å½“å‰å¯¹è¯è½®æ¬¡")

    env_state: EnvState = Field(default_factory=EnvState, description="å½“å‰ç¯å¢ƒçŠ¶æ€")
    initial_state: Dict[str, Any] = Field(
        default_factory=dict, description="åˆå§‹ç¯å¢ƒçŠ¶æ€å¿«ç…§"
    )

    current_user_intent: Optional[str] = Field(None, description="å½“å‰ç”¨æˆ·æ„å›¾")
    pending_tool_calls: List[ToolCall] = Field(
        default_factory=list, description="å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨"
    )
    current_thought: Optional[str] = Field(
        None, description="å½“å‰ Assistant çš„æ€è€ƒè¿‡ç¨‹ (CoT) ç¼“å†²åŒº"
    )
    scratchpad: Dict[str, Any] = Field(
        default_factory=dict, description="çŠ¶æ€æœºæµè½¬è¿‡ç¨‹ä¸­çš„ä¸´æ—¶å˜é‡å­˜å‚¨"
    )

    # PDA Stack: ç”¨äºå®ç°Pushdown Automatonï¼Œæ”¯æŒåµŒå¥—å·¥å…·è°ƒç”¨å’Œä¸Šä¸‹æ–‡ç®¡ç†
    stack: List[Dict[str, Any]] = Field(
        default_factory=lambda: [{"type": "ROOT", "data": {}}],
        description="å¯¹è¯æ ˆï¼Œç”¨äºè·Ÿè¸ªå¾…å¤„ç†çš„ä»»åŠ¡ä¸Šä¸‹æ–‡",
    )

    max_turns: int = Field(default=10, description="æœ€å¤§å¯¹è¯è½®æ¬¡é™åˆ¶")
    is_completed: bool = Field(default=False, description="å¯¹è¯æ˜¯å¦å®Œæˆ")

    created_at: datetime = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    updated_at: datetime = Field(
        default_factory=datetime.now, description="æœ€åæ›´æ–°æ—¶é—´"
    )

    def add_message(self, message: ChatMessage) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.messages.append(message)
        self.updated_at = datetime.now()

    def increment_turn(self) -> None:
        """å¢åŠ è½®æ¬¡è®¡æ•°"""
        self.turn_count += 1
        self.updated_at = datetime.now()

    def can_continue(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç»§ç»­å¯¹è¯"""
        return not self.is_completed and self.turn_count < self.max_turns

    def complete_conversation(self) -> None:
        """æ ‡è®°å¯¹è¯å®Œæˆ"""
        self.is_completed = True
        self.updated_at = datetime.now()

    def clear_buffers(self) -> None:
        """æ¸…ç©ºä¸´æ—¶ç¼“å†²åŒºï¼Œä¸ºä¸‹ä¸€è½®å¯¹è¯åšå‡†å¤‡"""
        self.current_thought = None
        self.pending_tool_calls.clear()
        self.scratchpad.clear()
        self.updated_at = datetime.now()

    def get_last_message(self) -> Optional[ChatMessage]:
        """è·å–æœ€åä¸€æ¡æ¶ˆæ¯"""
        return self.messages[-1] if self.messages else None

    def get_tool_call_history(self) -> List[ToolCall]:
        """è·å–å·¥å…·è°ƒç”¨å†å²"""
        tool_calls = []
        for msg in self.messages:
            if msg.tool_call:
                tool_calls.append(msg.tool_call)
        return tool_calls

    def push_context(self, context_type: str, data: Dict[str, Any] = None) -> None:
        """æ¨å…¥æ–°çš„ä¸Šä¸‹æ–‡å¸§åˆ°æ ˆé¡¶"""
        frame = {"type": context_type, "data": data or {}}
        self.stack.append(frame)
        self.updated_at = datetime.now()

    def pop_context(self) -> Optional[Dict[str, Any]]:
        """å¼¹å‡ºæ ˆé¡¶ä¸Šä¸‹æ–‡å¸§"""
        if len(self.stack) > 1:  # ä¿ç•™ROOTå¸§
            frame = self.stack.pop()
            self.updated_at = datetime.now()
            return frame
        return None

    def peek_context(self) -> Optional[Dict[str, Any]]:
        """æŸ¥çœ‹æ ˆé¡¶ä¸Šä¸‹æ–‡å¸§ï¼ˆä¸å¼¹å‡ºï¼‰"""
        return self.stack[-1] if self.stack else None

    def get_stack_depth(self) -> int:
        """è·å–æ ˆæ·±åº¦ï¼ˆä¸åŒ…æ‹¬ROOTï¼‰"""
        return len(self.stack) - 1

    def __str__(self) -> str:
        """ä¸Šä¸‹æ–‡çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"ConversationContext(id='{self.conversation_id}', turns={self.turn_count}, completed={self.is_completed})"


==================== FILE: models/schema.py ====================
"""
æ ¸å¿ƒæ•°æ®æ¨¡å‹ï¼šç¬¦åˆ OpenAI è§„èŒƒçš„å·¥å…·å®šä¹‰å’Œæ¶ˆæ¯æ ¼å¼

ä½¿ç”¨ Pydantic v2 è¿›è¡Œæ•°æ®éªŒè¯å’Œç±»å‹æç¤ºã€‚
"""

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class ToolParameterProperty(BaseModel):
    """å·¥å…·å‚æ•°çš„å±æ€§å®šä¹‰"""

    type: str = Field(..., description="å‚æ•°ç±»å‹ï¼Œå¦‚ 'string', 'number', 'boolean'")
    description: Optional[str] = Field(None, description="å‚æ•°æè¿°")
    enum: Optional[List[str]] = Field(None, description="æšä¸¾å€¼åˆ—è¡¨")
    items: Optional[Dict[str, Any]] = Field(
        None, description="æ•°ç»„é¡¹çš„å®šä¹‰ï¼ˆç”¨äºæ•°ç»„ç±»å‹ï¼‰"
    )


class ToolParameters(BaseModel):
    """å·¥å…·å‚æ•°çš„æ•´ä½“å®šä¹‰"""

    type: str = Field("object", description="å‚æ•°ç»“æ„ç±»å‹ï¼Œé€šå¸¸ä¸º 'object'")
    properties: Dict[str, ToolParameterProperty] = Field(
        ..., description="å‚æ•°å±æ€§å­—å…¸"
    )
    required: Optional[List[str]] = Field(None, description="å¿…éœ€çš„å‚æ•°åˆ—è¡¨")


class ToolDefinition(BaseModel):
    """OpenAI è§„èŒƒçš„å·¥å…·å®šä¹‰"""

    name: str = Field(..., description="å·¥å…·åç§°")
    description: str = Field(..., description="å·¥å…·æè¿°")
    parameters: ToolParameters = Field(..., description="å·¥å…·å‚æ•°å®šä¹‰")

    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µ


class ToolCall(BaseModel):
    """å·¥å…·è°ƒç”¨å®šä¹‰"""

    name: str = Field(..., description="è°ƒç”¨çš„å·¥å…·åç§°")
    arguments: Dict[str, Any] = Field(..., description="å·¥å…·è°ƒç”¨å‚æ•°")


class ChatMessage(BaseModel):
    """èŠå¤©æ¶ˆæ¯å®šä¹‰"""

    role: str = Field(
        ..., description="æ¶ˆæ¯è§’è‰²ï¼š'user', 'assistant', 'tool', 'system'"
    )
    content: Optional[str] = Field(None, description="æ¶ˆæ¯å†…å®¹")
    tool_call: Optional[ToolCall] = Field(
        None, description="å•ä¸ªå·¥å…·è°ƒç”¨ï¼ˆä»…assistantæ¶ˆæ¯ï¼Œå‘åå…¼å®¹ï¼‰"
    )
    tool_calls: Optional[List[ToolCall]] = Field(
        None, description="å¹¶è¡Œå·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆä»…assistantæ¶ˆæ¯ï¼‰"
    )
    tool_call_id: Optional[str] = Field(None, description="å·¥å…·è°ƒç”¨IDï¼ˆä»…toolæ¶ˆæ¯ï¼‰")

    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µä»¥æ”¯æŒæ‰©å±•


==================== FILE: cli/main.py ====================
"""
Sloop CLI å…¥å£

ä½¿ç”¨ typer å®ç°å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºç”Ÿæˆå¤šè½®å·¥å…·è°ƒç”¨å¯¹è¯æ•°æ®ã€‚
"""

import json
from pathlib import Path
from typing import List

import typer
from tqdm import tqdm

from sloop.engine import BlueprintGenerator
from sloop.engine.pda import ConversationPDA
from sloop.models import ChatMessage, ToolDefinition
from sloop.utils.logger import logger

app = typer.Typer()


@app.callback()
def main():
    """
    Sloop - å¤šè½®å·¥å…·è°ƒç”¨æ•°æ®ç”Ÿæˆæ¡†æ¶
    """
    pass


def convert_to_training_format(
    tools: List[ToolDefinition], messages: List[ChatMessage]
) -> dict:
    """
    å°†å†…éƒ¨æ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºæ‰å¹³åŒ–çš„è®­ç»ƒæ•°æ®æ ¼å¼

    å‚æ•°:
        tools: æ´»è·ƒçš„å·¥å…·å®šä¹‰åˆ—è¡¨
        messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨

    è¿”å›:
        è®­ç»ƒæ•°æ®æ ¼å¼çš„å­—å…¸ï¼ˆæ‰å¹³åŒ–æ ¼å¼ï¼‰
    """
    # è½¬æ¢toolsä¸ºJSONå­—ç¬¦ä¸²
    tools_list = [tool.model_dump() for tool in tools]
    tools_str = json.dumps(tools_list, ensure_ascii=False)

    # è½¬æ¢messagesä¸ºæ‰å¹³åŒ–æ ¼å¼
    converted_messages = []
    for msg in messages:
        if msg.role == "user":
            # ç”¨æˆ·æ¶ˆæ¯ä¿æŒä¸å˜
            converted_messages.append({"role": "user", "content": msg.content})
        elif msg.role == "tool_call":
            # å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆFSMä¸­å·²åˆ›å»ºç‹¬ç«‹çš„tool_callæ¶ˆæ¯ï¼‰
            converted_messages.append({"role": "tool_call", "content": msg.content})
        elif msg.role == "tool":
            # å·¥å…·å“åº” -> tool_response
            converted_messages.append({"role": "tool_response", "content": msg.content})
        elif msg.role == "assistant":
            # åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå·²åŒ…å«æ€è€ƒ + å›å¤ï¼‰
            converted_messages.append({"role": "assistant", "content": msg.content})

    return {"tools": tools_str, "messages": converted_messages}


@app.command()
def generate(
    input_file: str = typer.Option(
        "tests/data/tools.json", "--input", "-i", help="å·¥å…·å®šä¹‰æ–‡ä»¶è·¯å¾„"
    ),
    output_file: str = typer.Option(
        "tests/data/output.json", "--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    ),
    count: int = typer.Option(2, "--count", "-c", help="ç”Ÿæˆå¯¹è¯æ•°é‡"),
    max_turns: int = typer.Option(20, "--max-turns", "-t", help="æœ€å¤§å¯¹è¯è½®æ•°"),
    chain_length: int = typer.Option(5, "--chain-length", "-l", help="å·¥å…·é“¾é•¿åº¦"),
):
    """
    ç”Ÿæˆå¤šè½®å·¥å…·è°ƒç”¨å¯¹è¯æ•°æ®

    ä»å·¥å…·å®šä¹‰æ–‡ä»¶ä¸­è¯»å–å·¥å…·ï¼Œè‡ªåŠ¨ç”Ÿæˆå¯¹è¯è“å›¾å’Œå®Œæ•´çš„å¯¹è¯æµç¨‹ã€‚
    """
    typer.echo(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {count} ä¸ªå¯¹è¯æ•°æ®")
    typer.echo(f"   ğŸ“¥ è¾“å…¥æ–‡ä»¶: {input_file}")
    typer.echo(f"   ğŸ“¤ è¾“å‡ºæ–‡ä»¶: {output_file}")
    typer.echo(f"   ğŸ”„ æœ€å¤§è½®æ•°: {max_turns}")
    typer.echo(f"   ğŸ”— å·¥å…·é“¾é•¿åº¦: {chain_length}")

    # 1. åŠ è½½å·¥å…·å®šä¹‰
    typer.echo("ğŸ“‹ åŠ è½½å·¥å…·å®šä¹‰...")
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            tools_data = json.load(f)

        # è½¬æ¢ä¸º ToolDefinition å¯¹è±¡
        tools = [ToolDefinition(**tool) for tool in tools_data]
        typer.echo(f"   âœ… åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·å®šä¹‰")

    except FileNotFoundError:
        typer.echo(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}", err=True)
        raise typer.Exit(1) from None
    except json.JSONDecodeError as e:
        typer.echo(f"âŒ JSONè§£æé”™è¯¯: {e}", err=True)
        raise typer.Exit(1) from None

    # 2. åˆå§‹åŒ–è“å›¾ç”Ÿæˆå™¨
    typer.echo("ğŸ”§ åˆå§‹åŒ–è“å›¾ç”Ÿæˆå™¨...")
    generator = BlueprintGenerator(tools)

    # 3. å‡†å¤‡è¾“å‡ºæ–‡ä»¶
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # 4. ç”Ÿæˆå¯¹è¯æ•°æ®
    typer.echo("ğŸ¬ å¼€å§‹ç”Ÿæˆå¯¹è¯...")

    with tqdm(total=count, desc="ç”Ÿæˆè¿›åº¦") as pbar:
        for i in range(count):
            try:
                # ç”Ÿæˆè“å›¾
                blueprint = generator.generate(chain_length=chain_length)

                # æ ¹æ®blueprint.required_toolsç­›é€‰active_tools
                active_tools = [
                    tool for tool in tools if tool.name in blueprint.required_tools
                ]
                typer.echo(
                    f"   ğŸ”§ ä½¿ç”¨ {len(active_tools)} ä¸ªæ´»è·ƒå·¥å…·: {blueprint.required_tools}"
                )

                # åˆ›å»ºå¯¹è¯å¾ªç¯ï¼ˆåªä¼ å…¥active_toolsï¼Œé˜²æ­¢Contextæº¢å‡ºï¼‰
                conversation_id = f"conv_{i + 1:04d}"
                loop = ConversationPDA(
                    blueprint, active_tools, conversation_id, max_turns=max_turns
                )

                # è¿è¡Œå¯¹è¯
                loop.run()

                # è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®æ ¼å¼
                training_data = convert_to_training_format(
                    active_tools, loop.context.messages
                )

                # è¿½åŠ å†™å…¥è¾“å‡ºæ–‡ä»¶
                with open(output_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps(training_data, ensure_ascii=False) + "\n")

                pbar.set_description(f"ç”Ÿæˆè¿›åº¦ (æœ€è¿‘: {blueprint.intent[:20]}...)")

            except Exception as e:
                logger.error(f"ç”Ÿæˆå¯¹è¯ {i + 1} å¤±è´¥: {e}")
                typer.echo(f"âš ï¸ è·³è¿‡å¤±è´¥çš„å¯¹è¯ {i + 1}: {e}", err=True)
                continue

            pbar.update(1)

    typer.echo(f"âœ… ç”Ÿæˆå®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_file}")


if __name__ == "__main__":
    app()


==================== FILE: templates/assistant_think.j2 ====================
ä½ æ˜¯ä¸€ä¸ªæœ‰é€»è¾‘æ€ç»´èƒ½åŠ›çš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨åˆ†æå¯¹è¯å†å²æ¥ç†è§£ç”¨æˆ·çš„éœ€æ±‚ã€‚

åŸºäºå¯¹è¯å†å²ï¼Œç”Ÿæˆä¸€æ­¥æ­¥çš„æ¨ç†è¿‡ç¨‹æ¥å›åº”ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯ã€‚

## å¯¹è¯å†å²
{% for message in conversation_history %}
{{ message.role }}: {{ message.content }}
{% endfor %}

{% if context_hint %}
## å½“å‰ä¸Šä¸‹æ–‡çŠ¶æ€
{{ context_hint }}
{% endif %}

## æŒ‡ä»¤
è¯·æä¾›è¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹ï¼Œè€ƒè™‘ï¼š
1. ç”¨æˆ·åœ¨é—®ä»€ä¹ˆ
2. æˆ‘ä»¬æœ‰ä»€ä¹ˆä¿¡æ¯
3. å¯èƒ½éœ€è¦ä»€ä¹ˆå·¥å…·
4. å¦‚ä½•æ„å»ºå›å¤

## æ€è€ƒè¿‡ç¨‹


==================== FILE: templates/assistant_decide.j2 ====================
ä½ æ˜¯ä¸€ä¸ªå†³ç­–AIï¼Œè´Ÿè´£æ ¹æ®æ€è€ƒè¿‡ç¨‹åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ã€‚

åŸºäºä»¥ä¸‹æ€è€ƒè¿‡ç¨‹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·æ¥å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚

## æ€è€ƒè¿‡ç¨‹
{{ thought }}

## å¯ç”¨å·¥å…·
{% for tool in tools %}
- {{ tool.name }}: {{ tool.description }}
{% endfor %}

## æŒ‡ä»¤
åªå›ç­”"YES"æˆ–"NO"ï¼šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Ÿ


==================== FILE: templates/__init__.py ====================
"""
æ¨¡æ¿ç›®å½•

å­˜æ”¾æ‰€æœ‰Jinja2æ¨¡æ¿æ–‡ä»¶ã€‚
"""

# è¿™ä¸ªæ–‡ä»¶å¯ä»¥ä¸ºç©ºï¼Œåªç”¨äºæ ‡è®°è¿™æ˜¯ä¸€ä¸ªPythonåŒ…


==================== FILE: templates/assistant_reply.j2 ====================
ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®æ€è€ƒè¿‡ç¨‹ä¸ºç”¨æˆ·ç”Ÿæˆè‡ªç„¶ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚

åŸºäºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆæœ‰å¸®åŠ©å’Œè‡ªç„¶çš„å›å¤ã€‚

## æ€è€ƒè¿‡ç¨‹
{{ thought }}

## å¯¹è¯å†å²
{% for message in conversation_history %}
{{ message.role }}: {{ message.content }}
{% endfor %}

## æŒ‡ä»¤
ç”Ÿæˆå›å¤æ—¶éœ€è¦ï¼š
1. è§£å†³ç”¨æˆ·çš„éœ€æ±‚
2. å›å¤è¦æœ‰å¸®åŠ©ã€å‹å¥½
3. ä½¿ç”¨æ€è€ƒè¿‡ç¨‹ä¸­çš„ä¿¡æ¯
4. ä¸è¦æåŠå†…éƒ¨æ¨ç†è¿‡ç¨‹

## å›å¤


==================== FILE: templates/tool_call_gen.j2 ====================
ä½ æ˜¯ä¸€ä¸ªå·¥å…·è°ƒç”¨ç”ŸæˆAIï¼Œè´Ÿè´£æ ¹æ®æ€è€ƒè¿‡ç¨‹ç”Ÿæˆæ­£ç¡®çš„å·¥å…·è°ƒç”¨å‚æ•°ã€‚

åŸºäºæ€è€ƒè¿‡ç¨‹ï¼Œç”Ÿæˆåˆé€‚çš„å·¥å…·è°ƒç”¨å‚æ•°ã€‚

## æ€è€ƒè¿‡ç¨‹
{{ thought }}

## å¯ç”¨å·¥å…·
{% for tool in tools %}
### {{ tool.name }}
æè¿°: {{ tool.description }}
å‚æ•°: {{ tool.parameters | tojson }}
{% endfor %}

## æŒ‡ä»¤
ç”Ÿæˆå·¥å…·è°ƒç”¨ä¸ºJSONæ•°ç»„ã€‚æ¯ä¸ªå·¥å…·è°ƒç”¨åº”æœ‰'name'å’Œ'arguments'å­—æ®µã€‚
å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œè¿”å›ç©ºæ•°ç»„ã€‚

## å·¥å…·è°ƒç”¨


==================== FILE: templates/planner.j2 ====================
ä½ æ˜¯ä¸€ä¸ªä¸“å®¶çº§çš„ AI æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œä¸“é—¨ç”ŸæˆçœŸå®ã€è‡ªç„¶çš„å¯¹è¯åœºæ™¯ã€‚

## ç›®æ ‡å·¥å…·é“¾
{{ tool_chain | tojson }}

## å·¥å…·å®šä¹‰
{% for tool in tool_definitions %}
### {{ tool.name }}
æè¿°: {{ tool.description }}
å‚æ•°: {{ tool.parameters | tojson }}
{% if tool.category %}é¢†åŸŸ: {{ tool.category }}{% endif %}
{% endfor %}

## ä»»åŠ¡
é¦–å…ˆï¼Œä¸ºè¿™ä¸ªå·¥å…·é“¾æ„æ€ä¸€ä¸ªåˆç†çš„**ç”¨æˆ·ç”»åƒ(Persona)**ï¼Œç„¶ååŸºäºè¿™ä¸ªPersonaè®¾è®¡ä¸€ä¸ª**ä¸­æ–‡**çš„ç”¨æˆ·æ„å›¾ã€‚

1. **åˆ†æå·¥å…·é“¾åˆç†æ€§**ï¼š
   - æ£€æŸ¥ç»™å®šçš„å·¥å…·é“¾æ˜¯å¦èƒ½åœ¨ç°å®åœºæ™¯ä¸­é€»è¾‘è¿è´¯åœ°ç»„åˆä½¿ç”¨
   - å¦‚æœå·¥å…·é“¾ä¸åˆç†ï¼ˆå¦‚"å¯»æ‰¾å®è—" + "æŸ¥è¯¢è‚¡ä»·"ï¼‰ï¼Œè¯·åœ¨è¿”å›ä¸­è®¾ç½® "valid": false

2. **æ„æ€ç”¨æˆ·ç”»åƒ(Persona)**ï¼š
   - é€‰æ‹©ä¸€ä¸ªå…·ä½“çš„ç”¨æˆ·ç±»å‹ï¼ˆå¦‚"å¿™ç¢Œçš„é‡‘èåˆ†æå¸ˆ"ã€"æ­£åœ¨æ—…è¡Œè®¡åˆ’çš„å­¦ç”Ÿ"ã€"å®¶åº­ä¸»å¦‡"ç­‰ï¼‰
   - è¿™ä¸ªPersonaå¿…é¡»ä¸å·¥å…·é“¾çš„é¢†åŸŸé«˜åº¦ç›¸å…³

3. **è®¾è®¡ç”¨æˆ·æ„å›¾(Intent)**ï¼š
   - æ„å›¾å¿…é¡»æ˜¯è¿™ä¸ªPersonaåœ¨ç°å®ç”Ÿæ´»ä¸­ä¼šé‡åˆ°çš„å…·ä½“é—®é¢˜
   - æ„å›¾éœ€è¦ä¸¥æ ¼æŒ‰ç…§å·¥å…·é“¾çš„é¡ºåºæ¥è§£å†³
   - æ„å›¾åº”è¯¥æ˜¯è‡ªç„¶ã€å…·ä½“çš„ä¸­æ–‡æè¿°

4. **å®šä¹‰çŠ¶æ€**ï¼š
   - åˆå§‹çŠ¶æ€ï¼šæ‰§è¡Œå·¥å…·å‰Personaçš„çŠ¶æ€
   - æœŸæœ›çŠ¶æ€ï¼šæ‰§è¡Œæ‰€æœ‰å·¥å…·åä¸–ç•Œåº”è¯¥å‘ç”Ÿçš„å˜åŒ–

## è¦æ±‚
- **é¢†åŸŸä¸€è‡´æ€§**ï¼šPersonaå’Œæ„å›¾å¿…é¡»ä¸å·¥å…·é“¾çš„é¢†åŸŸä¿æŒä¸€è‡´
- **ç°å®åˆç†æ€§**ï¼šåœºæ™¯å¿…é¡»åƒçœŸå®ç”¨æˆ·åœ¨å®é™…ç”Ÿæ´»ä¸­é‡åˆ°çš„é—®é¢˜
- **é€»è¾‘è¿è´¯æ€§**ï¼šå·¥å…·è°ƒç”¨é¡ºåºå¿…é¡»ç¬¦åˆè§£å†³é—®é¢˜çš„è‡ªç„¶æµç¨‹
- **çŠ¶æ€ç²¾ç¡®æ€§**ï¼šåªå®šä¹‰ä¼šè¢«å·¥å…·å®é™…ä¿®æ”¹çš„å˜é‡

## è¾“å‡ºæ ¼å¼
ä¸¥æ ¼æŒ‰ç…§æ­¤JSONæ ¼å¼è¾“å‡ºï¼š

{
  "valid": true|false,
  "persona": "ç”¨æˆ·ç”»åƒæè¿°",
  "intent": "æè¿°ç”¨æˆ·æ„å›¾çš„ä¸­æ–‡å­—ç¬¦ä¸²",
  "required_tools": {{ tool_chain | tojson }},
  "ground_truth": {{ tool_chain | tojson }},
  "initial_state": {"key": "value"},
  "expected_state": {"key": "new_value"}
}

## ç¤ºä¾‹

**æœ‰æ•ˆåœºæ™¯**ï¼š
{
  "valid": true,
  "persona": "æ­£åœ¨å‡†å¤‡å¹´ç»ˆæ±‡æŠ¥çš„é‡‘èåˆ†æå¸ˆ",
  "intent": "è·å–è¿‡å»ä¸€ä¸ªæœˆé¡¶çº§åˆ›ä¸šå…¬å¸çš„æ–°é—»ï¼Œç”¨äºå¹´ç»ˆè¡Œä¸šåˆ†ææŠ¥å‘Š",
  "required_tools": ["search_news", "filter_by_category"],
  "ground_truth": ["search_news", "filter_by_category"],
  "initial_state": {"news_collected": false, "analysis_ready": false},
  "expected_state": {"news_collected": true, "analysis_ready": true}
}

**æ— æ•ˆåœºæ™¯**ï¼š
{
  "valid": false,
  "reason": "å·¥å…·é“¾æ¶‰åŠä¸åŒé¢†åŸŸï¼ˆå¨±ä¹æ¸¸æˆå’Œé‡‘èæŠ•èµ„ï¼‰ï¼Œæ— æ³•å½¢æˆè¿è´¯çš„ç”¨æˆ·åœºæ™¯",
  "intent": "",
  "required_tools": {{ tool_chain | tojson }},
  "ground_truth": {{ tool_chain | tojson }},
  "initial_state": {},
  "expected_state": {}
}


==================== FILE: templates/user.j2 ====================
ä½ æ˜¯ä¸€ä¸ªæ­£åœ¨ä¸ AI åŠ©æ‰‹å¯¹è¯çš„ç”¨æˆ·ã€‚ä½ çš„ç›®æ ‡æ˜¯ï¼š{{ intent }}

## å¯¹è¯å†å²
{% for message in conversation_history %}
{{ message.role }}: {{ message.content }}
{% endfor %}

## ä½ çš„ä»»åŠ¡
æ ¹æ®ä¸Šé¢çš„å¯¹è¯å†å²ï¼Œå†³å®šä½œä¸ºè¿½æ±‚ç›®æ ‡çš„ç”¨æˆ·æ¥ä¸‹æ¥ä¼šè¯´ä»€ä¹ˆã€‚

å¦‚æœä½ è®¤ä¸ºä»»åŠ¡å·²ç»æˆåŠŸå®Œæˆï¼ˆæ‰€æœ‰è¦æ±‚éƒ½å·²æ»¡è¶³ï¼‰ï¼Œè¯·å›å¤ "###STOP###" æ¥ç»“æŸå¯¹è¯ã€‚

å¦åˆ™ï¼Œç”¨è‡ªç„¶ã€æµç•…çš„**ä¸­æ–‡**ç»§ç»­å¯¹è¯ï¼Œæå‡ºä¸€ä¸ªçœŸå®çš„ç”¨æˆ·æ¶ˆæ¯æ¥æœç€å®ç°ç›®æ ‡å‰è¿›ã€‚

ä¿æŒå›å¤è‡ªç„¶ä¸”å¯¹è¯å¼ã€‚ä¸è¦åŒ…å«ä»»ä½•å…³äºä½ è§’è‰²çš„å…ƒè¯„è®ºã€‚


==================== FILE: templates/service.j2 ====================
ä½ æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿ API æœåŠ¡å™¨çš„ Python å‡½æ•°ã€‚ä½ **åªè¿”å›æ•°æ®**ï¼Œç»ä¸ä¸ç”¨æˆ·å¯¹è¯ã€‚

## å¯¹è¯å†å²
{% for message in conversation_history %}
{{ message.role }}: {{ message.content }}
{% endfor %}

## å½“å‰ç¯å¢ƒçŠ¶æ€
{{ current_state | tojson }}

## å·¥å…·è°ƒç”¨ä¿¡æ¯
å·¥å…·åç§°: {{ tool_call.tool_name }}
å‚æ•°: {{ tool_call.arguments | tojson }}

## è“å›¾ä¸Šä¸‹æ–‡
æ„å›¾: {{ blueprint.intent }}
æœŸæœ›æœ€ç»ˆçŠ¶æ€: {{ blueprint.expected_state | tojson }}

## ä»»åŠ¡
1. æ ¹æ®å½“å‰çŠ¶æ€å’Œå¯¹è¯å†å²æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨çš„æ‰§è¡Œ
2. ç”Ÿæˆè¯¥å·¥å…·ä¼šè¿”å›çš„**çº¯JSONæ•°æ®**ï¼ˆæ¨¡æ‹ŸçœŸå®çš„APIè¿”å›ä½“ï¼‰
3. ç¡®å®šæ­¤å·¥å…·æ‰§è¡Œååº”è¯¥æ›´æ–°çš„çŠ¶æ€å˜é‡
4. è¿”å›å“åº”å’ŒçŠ¶æ€æ›´æ–°

## æŒ‡ä»¤
- **Responseå­—æ®µå¿…é¡»æ˜¯çº¯JSONå­—ç¬¦ä¸²æˆ–æ•°å€¼**ï¼Œæ¨¡æ‹ŸçœŸå®çš„APIè¿”å›ä½“
- **ä¸¥ç¦åŒ…å«è‡ªç„¶è¯­è¨€æè¿°**ï¼ˆå¦‚"è®¢å•å·²åˆ›å»º"ã€"å¤©æ°”ä¸é”™"ç­‰ï¼‰
- **ç”Ÿæˆåˆç†çš„æ•°æ®**ï¼Œå‚è€ƒå¯¹è¯å†å²é¿å…é€»è¾‘å†²çªï¼ˆå¦‚ç”¨æˆ·é¢„ç®—300å´ç”Ÿæˆ6999çš„è®¢å•ï¼‰
- ä¾‹å¦‚ï¼š`{"temp": 24, "condition": "Sunny"}` è€Œä¸æ˜¯ `ä»Šå¤©å¤©æ°”æ™´æœ—`
- çŠ¶æ€æ›´æ–°åº”è¯¥åæ˜ å·¥å…·æ‰§è¡Œå¸¦æ¥çš„æœ‰æ„ä¹‰å˜åŒ–
- ä»…æ›´æ–°ä¼šè¢«æ­¤å·¥å…·è°ƒç”¨é€»è¾‘æ”¹å˜çš„çŠ¶æ€å˜é‡
- ä¸ºçŠ¶æ€å€¼ä½¿ç”¨é€‚å½“çš„æ•°æ®ç±»å‹ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—ã€å¸ƒå°”å€¼ï¼‰
- å¦‚æœä¸éœ€è¦çŠ¶æ€å˜åŒ–ï¼Œè¿”å›ç©ºçš„state_updateså¯¹è±¡

## è¾“å‡ºæ ¼å¼
è¿”å›å…·æœ‰å®Œå…¨æ­¤ç»“æ„çš„JSONå¯¹è±¡ï¼š
{
  "response": "çº¯JSONå­—ç¬¦ä¸²æˆ–æ•°å€¼ï¼Œæ¨¡æ‹ŸAPIè¿”å›ä½“",
  "state_updates": {
    "variable_name": "new_value",
    "another_variable": true,
    "numeric_value": 42
  }
}

## ç¤ºä¾‹
å¯¹äºå¤©æ°”æŸ¥è¯¢å·¥å…·ï¼š
{
  "response": "{\"temperature\": 25, \"condition\": \"Sunny\", \"humidity\": 65}",
  "state_updates": {
    "weather_data": "{\"temperature\": 25, \"condition\": \"Sunny\", \"humidity\": 65}",
    "weather_retrieved": true
  }
}

å¯¹äºé¤å…æœç´¢å·¥å…·ï¼š
{
  "response": "[{\"name\": \"èœ€å¤§ä¾ ç«é”…\", \"rating\": 4.8, \"address\": \"æˆéƒ½å¸‚é”¦æ±ŸåŒº\"}, {\"name\": \"è¾£åºœ\", \"rating\": 4.6, \"address\": \"æˆéƒ½å¸‚æ­¦ä¾¯åŒº\"}]",
  "state_updates": {
    "restaurants_found": true,
    "restaurant_count": 2
  }
}


==================== FILE: engine/blueprint.py ====================
"""
è“å›¾ç”Ÿæˆå™¨ (Blueprint Generator)

è¿æ¥å·¥å…·å›¾è°±å’ŒLLMæƒ³è±¡åŠ›ï¼Œè‡ªåŠ¨ç”Ÿæˆåˆç†çš„å¯¹è¯è“å›¾ã€‚
"""

import json
from typing import List

from sloop.engine.graph import ToolGraphBuilder
from sloop.models import Blueprint, ToolDefinition
from sloop.utils.llm import chat_completion
from sloop.utils.logger import logger
from sloop.utils.template import render_planner_prompt


class BlueprintGenerator:
    """
    è“å›¾ç”Ÿæˆå™¨

    åŸºäºå·¥å…·å›¾è°±é‡‡æ ·å’ŒLLMæ¨ç†ï¼Œè‡ªåŠ¨ç”Ÿæˆå¯¹è¯è“å›¾ã€‚
    """

    def __init__(self, tools: List[ToolDefinition]):
        """
        åˆå§‹åŒ–è“å›¾ç”Ÿæˆå™¨

        å‚æ•°:
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

        # åˆå§‹åŒ–å·¥å…·å›¾è°±æ„å»ºå™¨
        self.graph_builder = ToolGraphBuilder(tools)
        self.graph_builder.build()

        logger.info(f"BlueprintGenerator initialized with {len(tools)} tools")

    def generate(self, chain_length: int = 3, max_retries: int = 3) -> Blueprint:
        """
        ç”Ÿæˆå¯¹è¯è“å›¾ï¼ŒåŒ…å«åˆç†æ€§éªŒè¯å’Œé‡è¯•æœºåˆ¶

        å‚æ•°:
            chain_length: å·¥å…·é“¾é•¿åº¦
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        è¿”å›:
            ç”Ÿæˆçš„å¯¹è¯è“å›¾
        """
        logger.info(
            f"Generating blueprint with chain length {chain_length}, max_retries {max_retries}"
        )

        for attempt in range(max_retries):
            try:
                logger.info(f"Attempt {attempt + 1}/{max_retries}")

                # 1. ä»å›¾è°±ä¸­é‡‡æ ·å·¥å…·é“¾
                tool_chain = self.graph_builder.sample_tool_chain(
                    min_length=max(1, chain_length - 1), max_length=chain_length
                )

                if not tool_chain:
                    logger.warning(
                        f"Attempt {attempt + 1}: Failed to sample tool chain, retrying..."
                    )
                    continue

                logger.info(f"Sampled tool chain: {tool_chain}")

                # 2. è·å–å·¥å…·å®šä¹‰
                tool_definitions = []
                for tool_name in tool_chain:
                    if tool_name in self.tool_map:
                        tool_definitions.append(self.tool_map[tool_name])
                    else:
                        logger.warning(f"Tool {tool_name} not found in tool map")

                if not tool_definitions:
                    logger.warning(
                        f"Attempt {attempt + 1}: No valid tool definitions found, retrying..."
                    )
                    continue

                # 3. æ„é€ å’Œå‘é€æç¤º
                prompt = render_planner_prompt(tool_chain, tool_definitions)

                logger.info("Sending prompt to LLM for blueprint generation")

                # 4. è°ƒç”¨LLMç”Ÿæˆè“å›¾
                llm_response = chat_completion(
                    prompt=prompt,
                    system_message="",
                    json_mode=True,
                )

                if not llm_response or llm_response.startswith("è°ƒç”¨é”™è¯¯"):
                    logger.warning(
                        f"Attempt {attempt + 1}: LLM call failed: {llm_response}, retrying..."
                    )
                    continue

                # 5. è§£æå’ŒéªŒè¯å“åº”
                try:
                    blueprint_data = json.loads(llm_response)
                    logger.info("Successfully parsed LLM response")
                except json.JSONDecodeError:
                    logger.warning(
                        f"Attempt {attempt + 1}: Failed to parse LLM response as JSON: {llm_response}, retrying..."
                    )
                    continue

                # 6. æ£€æŸ¥è“å›¾åˆç†æ€§
                if not blueprint_data.get("valid", True):
                    reason = blueprint_data.get("reason", "Unknown reason")
                    logger.warning(
                        f"Attempt {attempt + 1}: Blueprint marked as invalid: {reason}, retrying..."
                    )
                    continue

                # 7. éªŒè¯å’Œä¿®æ­£æ•°æ®
                validated_data = self._validate_blueprint_data(
                    blueprint_data, tool_chain
                )

                # 8. åˆ›å»ºBlueprintå¯¹è±¡
                blueprint = Blueprint(**validated_data)

                logger.info(
                    f"Successfully generated valid blueprint: {blueprint.intent}"
                )
                return blueprint

            except Exception as e:
                logger.warning(f"Attempt {attempt + 1} failed: {e}, retrying...")
                continue

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªç®€å•çš„é»˜è®¤è“å›¾
        logger.error(
            f"All {max_retries} attempts failed, generating fallback blueprint"
        )
        return self._generate_fallback_blueprint(tool_chain)

    def _validate_blueprint_data(self, data: dict, expected_chain: List[str]) -> dict:
        """
        éªŒè¯å’Œä¿®æ­£è“å›¾æ•°æ®

        å‚æ•°:
            data: LLMè¿”å›çš„åŸå§‹æ•°æ®
            expected_chain: æœŸæœ›çš„å·¥å…·é“¾

        è¿”å›:
            éªŒè¯åçš„æ•°æ®å­—å…¸
        """
        validated = {}

        # éªŒè¯intent
        if "intent" not in data or not isinstance(data["intent"], str):
            raise ValueError("ç¼ºå°‘æœ‰æ•ˆçš„intentå­—æ®µ")
        validated["intent"] = data["intent"].strip()

        # éªŒè¯required_toolsï¼ˆå¯ä»¥æ˜¯é‡‡æ ·çš„é“¾æˆ–LLMå»ºè®®çš„é“¾ï¼‰
        if "required_tools" in data and isinstance(data["required_tools"], list):
            validated["required_tools"] = data["required_tools"]
        else:
            validated["required_tools"] = expected_chain

        # å¼ºåˆ¶è®¾ç½®ground_truthä¸ºé‡‡æ ·çš„é“¾
        validated["ground_truth"] = expected_chain

        # éªŒè¯initial_state
        if "initial_state" not in data or not isinstance(data["initial_state"], dict):
            logger.warning("ç¼ºå°‘initial_stateï¼Œä½¿ç”¨é»˜è®¤å€¼")
            validated["initial_state"] = {}
        else:
            validated["initial_state"] = data["initial_state"]

        # éªŒè¯expected_state
        if "expected_state" not in data or not isinstance(data["expected_state"], dict):
            logger.warning("ç¼ºå°‘expected_stateï¼Œä½¿ç”¨é»˜è®¤å€¼")
            validated["expected_state"] = {}
        else:
            validated["expected_state"] = data["expected_state"]

        return validated

    def _generate_fallback_blueprint(self, tool_chain: List[str]) -> Blueprint:
        """
        ç”Ÿæˆåå¤‡è“å›¾ï¼Œå½“æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶ä½¿ç”¨

        å‚æ•°:
            tool_chain: å·¥å…·é“¾åˆ—è¡¨

        è¿”å›:
            ç®€å•çš„åå¤‡è“å›¾
        """
        logger.info("Generating fallback blueprint")

        # æ„å»ºç®€å•çš„intent
        tool_names = list(tool_chain)  # ç›´æ¥ä½¿ç”¨å·¥å…·å
        intent = f"æ‰§è¡Œå·¥å…·é“¾: {' -> '.join(tool_names)}"

        # ç®€å•çš„çŠ¶æ€
        initial_state = {f"{name}_executed": False for name in tool_chain}
        expected_state = {f"{name}_executed": True for name in tool_chain}

        return Blueprint(
            intent=intent,
            required_tools=tool_chain,
            ground_truth=tool_chain,
            initial_state=initial_state,
            expected_state=expected_state,
        )

    def generate_multiple(
        self, count: int = 5, chain_length: int = 3
    ) -> List[Blueprint]:
        """
        ç”Ÿæˆå¤šä¸ªè“å›¾

        å‚æ•°:
            count: ç”Ÿæˆæ•°é‡
            chain_length: å·¥å…·é“¾é•¿åº¦

        è¿”å›:
            è“å›¾åˆ—è¡¨
        """
        blueprints = []
        for i in range(count):
            try:
                blueprint = self.generate(chain_length)
                blueprints.append(blueprint)
                logger.info(f"Generated blueprint {i + 1}/{count}: {blueprint.intent}")
            except Exception as e:
                logger.error(f"Failed to generate blueprint {i + 1}: {e}")
                continue

        return blueprints


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    logger.info("ğŸ”§ Blueprint Generator æµ‹è¯•")
    logger.info("=" * 50)

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·æ•°æ®
    mock_tools = [
        ToolDefinition(
            name="find_restaurants",
            description="Find restaurants and return restaurant_id",
            parameters={
                "type": "object",
                "properties": {"city": {"type": "string", "description": "City name"}},
                "required": ["city"],
            },
        ),
        ToolDefinition(
            name="get_menu",
            description="Get menu for a restaurant",
            parameters={
                "type": "object",
                "properties": {
                    "restaurant_id": {"type": "string", "description": "Restaurant ID"}
                },
                "required": ["restaurant_id"],
            },
        ),
        ToolDefinition(
            name="order_food",
            description="Order food from menu",
            parameters={
                "type": "object",
                "properties": {
                    "dish_id": {"type": "string", "description": "Dish ID"},
                    "restaurant_id": {"type": "string", "description": "Restaurant ID"},
                },
                "required": ["dish_id"],
            },
        ),
    ]

    logger.info("ğŸ“‹ æ¨¡æ‹Ÿå·¥å…·æ•°æ®:")
    for tool in mock_tools:
        logger.info(f"  - {tool.name}: {tool.description}")
    logger.info("")

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    logger.info("ğŸ”§ åˆå§‹åŒ–BlueprintGenerator...")
    generator = BlueprintGenerator(mock_tools)

    logger.info("ğŸ“Š å›¾è°±ç»Ÿè®¡:")
    stats = generator.graph_builder.get_graph_stats()
    logger.info(f"  èŠ‚ç‚¹æ•°é‡: {stats['nodes']}")
    logger.info(f"  è¾¹æ•°é‡: {stats['edges']}")
    logger.info("")

    # ç”Ÿæˆè“å›¾
    logger.info("ğŸ¯ ç”ŸæˆBlueprint...")
    try:
        blueprint = generator.generate(chain_length=2)

        logger.info("âœ… ç”ŸæˆæˆåŠŸï¼")
        logger.info("\nğŸ“‹ Blueprintè¯¦æƒ…:")
        logger.info(f"  æ„å›¾: {blueprint.intent}")
        logger.info(f"  å¿…éœ€å·¥å…·: {blueprint.required_tools}")
        logger.info(f"  çœŸå®å·¥å…·é“¾: {blueprint.ground_truth}")
        logger.info(f"  åˆå§‹çŠ¶æ€: {blueprint.initial_state}")
        logger.info(f"  æœŸæœ›çŠ¶æ€: {blueprint.expected_state}")

        logger.info("\nğŸ“„ å®Œæ•´JSON:")
        logger.info(blueprint.model_dump_json(indent=2))

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
        logger.info("\nğŸ”§ æä¾›æ¨¡æ‹ŸBlueprintä½œä¸ºç¤ºä¾‹:")
        mock_blueprint = Blueprint(
            intent="æŸ¥æ‰¾é¤å…å¹¶ç‚¹é¤",
            required_tools=["find_restaurants", "get_menu"],
            ground_truth=["find_restaurants", "get_menu"],
            initial_state={"restaurant_found": False, "menu_loaded": False},
            expected_state={"restaurant_found": True, "menu_loaded": True},
        )
        logger.info(mock_blueprint.model_dump_json(indent=2))

    logger.info("\nâœ… Blueprint Generator æµ‹è¯•å®Œæˆï¼")


==================== FILE: engine/graph.py ====================
"""
å‚æ•°çº§å·¥å…·å›¾è°±æ„å»ºå™¨ (Tool Graph Builder)

å®ç°å·¥å…·ä¹‹é—´çš„ä¾èµ–å…³ç³»åˆ†æå’Œå›¾è°±æ„å»ºï¼Œç”¨äºç”Ÿæˆåˆç†çš„å·¥å…·è°ƒç”¨é“¾ã€‚
"""

import random
from typing import Dict, List, Optional

import matplotlib.pyplot as plt
import networkx as nx

from sloop.models import ToolDefinition
from sloop.utils.logger import logger


class ToolGraphBuilder:
    """
    å·¥å…·å›¾è°±æ„å»ºå™¨

    åŸºäºå·¥å…·æè¿°å’Œå‚æ•°åˆ†æï¼Œæ„å»ºå·¥å…·ä¹‹é—´çš„ä¾èµ–å…³ç³»å›¾ã€‚
    ç”¨äºç”Ÿæˆåˆç†çš„å·¥å…·è°ƒç”¨åºåˆ—ã€‚
    """

    def __init__(self, tools: List[ToolDefinition]):
        """
        åˆå§‹åŒ–æ„å»ºå™¨

        å‚æ•°:
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}
        self.graph: Optional[nx.DiGraph] = None

    def build(self) -> nx.DiGraph:
        """
        æ„å»ºå·¥å…·ä¾èµ–å›¾

        è¿”å›:
            æœ‰å‘å›¾ï¼šèŠ‚ç‚¹ä¸ºå·¥å…·åï¼Œè¾¹è¡¨ç¤ºä¾èµ–å…³ç³»
        """
        # åˆ›å»ºæœ‰å‘å›¾
        self.graph = nx.DiGraph()

        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        for tool in self.tools:
            self.graph.add_node(tool.name, tool=tool)

        # åˆ†æä¾èµ–å…³ç³»å¹¶æ·»åŠ è¾¹
        for tool_a in self.tools:
            for tool_b in self.tools:
                if tool_a.name != tool_b.name and self._has_dependency(tool_a, tool_b):
                    self.graph.add_edge(tool_a.name, tool_b.name)

        return self.graph

    def _has_dependency(self, tool_a: ToolDefinition, tool_b: ToolDefinition) -> bool:
        """
        åˆ¤æ–­å·¥å…·Aæ˜¯å¦æ˜¯å·¥å…·Bçš„ä¾èµ–

        é€»è¾‘ï¼šå¦‚æœBçš„å¿…éœ€å‚æ•°åå‡ºç°åœ¨Açš„æè¿°ä¸­ï¼Œåˆ™A -> B

        å‚æ•°:
            tool_a: å¯èƒ½çš„ä¾èµ–å·¥å…·
            tool_b: è¢«ä¾èµ–çš„å·¥å…·

        è¿”å›:
            æ˜¯å¦å­˜åœ¨ä¾èµ–å…³ç³»
        """
        # è·å–Bçš„å¿…éœ€å‚æ•°å
        required_params = self._get_required_params(tool_b)
        if not required_params:
            return False

        # æ£€æŸ¥Açš„æè¿°æ˜¯å¦åŒ…å«Bçš„å¿…éœ€å‚æ•°å
        description_a = tool_a.description.lower()
        return any(param.lower() in description_a for param in required_params)

    def _get_required_params(self, tool: ToolDefinition) -> List[str]:
        """
        è·å–å·¥å…·çš„å¿…éœ€å‚æ•°ååˆ—è¡¨

        å‚æ•°:
            tool: å·¥å…·å®šä¹‰

        è¿”å›:
            å¿…éœ€å‚æ•°ååˆ—è¡¨
        """
        required = []
        if hasattr(tool.parameters, "required") and tool.parameters.required:
            required = tool.parameters.required
        return required

    def sample_tool_chain(self, min_length: int = 2, max_length: int = 5) -> List[str]:
        """
        ä»å›¾ä¸­é‡‡æ ·ä¸€æ¡å·¥å…·è°ƒç”¨é“¾ï¼Œè€ƒè™‘é¢†åŸŸç²˜æ€§

        å‚æ•°:
            min_length: æœ€å°é“¾é•¿åº¦
            max_length: æœ€å¤§é“¾é•¿åº¦

        è¿”å›:
            å·¥å…·ååˆ—è¡¨ï¼Œè¡¨ç¤ºè°ƒç”¨é¡ºåº
        """
        if self.graph is None:
            raise ValueError("å›¾å°šæœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨ build() æ–¹æ³•")

        if len(self.graph.nodes) == 0:
            return []

        # æ‰¾åˆ°å…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼ˆèµ·å§‹èŠ‚ç‚¹ï¼‰
        start_nodes = [
            node for node in self.graph.nodes if self.graph.in_degree(node) == 0
        ]

        if not start_nodes:
            # å¦‚æœæ²¡æœ‰å…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
            start_nodes = list(self.graph.nodes)

        # éšæœºé€‰æ‹©èµ·å§‹èŠ‚ç‚¹
        current_node = random.choice(start_nodes)
        chain = [current_node]

        # è·å–å½“å‰å·¥å…·çš„categoryä½œä¸ºåŸºå‡†
        current_category = self._get_tool_category(current_node)

        # éšæœºæ¸¸èµ°æ„å»ºé“¾ï¼ˆå¢åŠ æœ€å¤§å°è¯•æ¬¡æ•°é¿å…æ­»å¾ªç¯ï¼‰
        max_attempts = 50
        attempts = 0

        while len(chain) < max_length and attempts < max_attempts:
            # è·å–å½“å‰èŠ‚ç‚¹çš„åç»§èŠ‚ç‚¹
            successors = list(self.graph.successors(current_node))

            if not successors:
                # æ²¡æœ‰åç»§èŠ‚ç‚¹ï¼Œç»“æŸ
                break

            # æŒ‰é¢†åŸŸç²˜æ€§å¯¹åç»§èŠ‚ç‚¹è¿›è¡Œæ’åº
            # åŒé¢†åŸŸæˆ–ç›¸å…³é¢†åŸŸçš„èŠ‚ç‚¹ä¼˜å…ˆçº§æ›´é«˜
            scored_successors_with_random = []
            for successor in successors:
                score = self._calculate_domain_stickiness(current_category, successor)
                scored_successors_with_random.append((
                    successor,
                    score,
                    random.random(),
                ))

            # æŒ‰åˆ†æ•°é™åºæ’åºï¼Œç„¶åæŒ‰éšæœºå€¼é™åºæ’åºä»¥æ‰“ç ´å¹³å±€
            scored_successors_with_random.sort(key=lambda x: (x[1], x[2]), reverse=True)
            final_successors = [s[0] for s in scored_successors_with_random]

            # æŒ‰80%çš„æ¦‚ç‡é€‰æ‹©é«˜ç²˜æ€§èŠ‚ç‚¹ï¼Œ20%æ¦‚ç‡éšæœºé€‰æ‹©
            HIGH_STICKINESS_PROB = 0.8
            if random.random() < HIGH_STICKINESS_PROB and final_successors:
                next_node = final_successors[0]  # é€‰æ‹©æœ€ç›¸å…³çš„èŠ‚ç‚¹
            else:
                next_node = random.choice(successors)  # éšæœºé€‰æ‹©ä»¥ä¿æŒå¤šæ ·æ€§

            # é¿å…ç¯è·¯
            if next_node in chain:
                attempts += 1
                continue

            chain.append(next_node)
            current_node = next_node
            current_category = self._get_tool_category(current_node)

        # ç¡®ä¿æœ€å°é•¿åº¦ï¼ˆç®€åŒ–é€»è¾‘ï¼‰
        if len(chain) < min_length:
            # å¦‚æœå¤ªçŸ­ï¼Œè¿”å›å½“å‰é“¾ï¼ˆé¿å…å¤æ‚æ‰©å±•é€»è¾‘å¯¼è‡´é—®é¢˜ï¼‰
            pass

        return chain

    def _get_tool_category(self, tool_name: str) -> str:
        """
        è·å–å·¥å…·çš„category

        å‚æ•°:
            tool_name: å·¥å…·å

        è¿”å›:
            å·¥å…·çš„categoryï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›"general"
        """
        if tool_name in self.tool_map:
            tool = self.tool_map[tool_name]
            # ä»toolçš„é¢å¤–å­—æ®µä¸­è·å–category
            if hasattr(tool, "category") and tool.category:
                return tool.category
            # æˆ–è€…ä»model_extraä¸­è·å–
            if (
                hasattr(tool, "model_extra")
                and tool.model_extra
                and "category" in tool.model_extra
            ):
                return tool.model_extra["category"]

        return "general"

    def _calculate_domain_stickiness(
        self, current_category: str, candidate_tool: str
    ) -> float:
        """
        è®¡ç®—é¢†åŸŸç²˜æ€§åˆ†æ•°

        å‚æ•°:
            current_category: å½“å‰å·¥å…·çš„category
            candidate_tool: å€™é€‰å·¥å…·å

        è¿”å›:
            ç²˜æ€§åˆ†æ•° (0-1)ï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šç›¸å…³
        """
        candidate_category = self._get_tool_category(candidate_tool)

        if current_category == candidate_category:
            # åŒé¢†åŸŸï¼Œæœ€é«˜åˆ†æ•°
            return 1.0
        elif self._are_related_categories(current_category, candidate_category):
            # ç›¸å…³é¢†åŸŸï¼Œä¸­ç­‰åˆ†æ•°
            return 0.7
        else:
            # æ— å…³é¢†åŸŸï¼Œä½åˆ†æ•°
            return 0.3

    def _are_related_categories(self, cat1: str, cat2: str) -> bool:
        """
        åˆ¤æ–­ä¸¤ä¸ªcategoryæ˜¯å¦ç›¸å…³

        å‚æ•°:
            cat1: ç±»åˆ«1
            cat2: ç±»åˆ«2

        è¿”å›:
            æ˜¯å¦ç›¸å…³
        """
        # å®šä¹‰ç›¸å…³ç±»åˆ«çš„æ˜ å°„
        related_categories = {
            "finance": ["business", "investment", "stock", "banking"],
            "business": ["finance", "investment", "company"],
            "investment": ["finance", "business", "stock"],
            "stock": ["finance", "investment"],
            "banking": ["finance", "payment"],
            "travel": ["booking", "hotel", "flight", "transport"],
            "booking": ["travel", "hotel", "flight", "restaurant"],
            "hotel": ["travel", "booking"],
            "flight": ["travel", "booking", "transport"],
            "transport": ["travel", "flight"],
            "food": ["restaurant", "cooking", "delivery"],
            "restaurant": ["food", "booking"],
            "cooking": ["food", "recipe"],
            "delivery": ["food", "restaurant"],
            "music": ["audio", "entertainment"],
            "audio": ["music", "entertainment"],
            "entertainment": ["music", "audio", "game"],
            "game": ["entertainment", "gaming"],
            "gaming": ["game", "entertainment"],
            "health": ["medical", "fitness"],
            "medical": ["health", "doctor"],
            "fitness": ["health", "exercise"],
            "education": ["learning", "study"],
            "learning": ["education", "study"],
            "study": ["education", "learning"],
            "shopping": ["ecommerce", "retail"],
            "ecommerce": ["shopping", "retail"],
            "retail": ["shopping", "ecommerce"],
        }

        # æ£€æŸ¥åŒå‘å…³ç³»
        return (cat1 in related_categories and cat2 in related_categories[cat1]) or (
            cat2 in related_categories and cat1 in related_categories[cat2]
        )

    def get_graph_stats(self) -> Dict:
        """
        è·å–å›¾çš„ç»Ÿè®¡ä¿¡æ¯

        è¿”å›:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if self.graph is None:
            return {"error": "å›¾å°šæœªæ„å»º"}

        return {
            "nodes": len(self.graph.nodes),
            "edges": len(self.graph.edges),
            "start_nodes": len([
                n for n in self.graph.nodes if self.graph.in_degree(n) == 0
            ]),
            "end_nodes": len([
                n for n in self.graph.nodes if self.graph.out_degree(n) == 0
            ]),
        }

    def visualize_graph(self, output_path: str = "tool_graph.png"):
        """
        å¯è§†åŒ–å·¥å…·å›¾ï¼ˆéœ€è¦matplotlibï¼‰

        å‚æ•°:
            output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        """
        if self.graph is None:
            logger.info("å›¾å°šæœªæ„å»º")
            return

        try:
            plt.figure(figsize=(12, 8))

            # è®¡ç®—èŠ‚ç‚¹ä½ç½®
            pos = nx.spring_layout(self.graph, k=2, iterations=50)

            # ç»˜åˆ¶èŠ‚ç‚¹
            nx.draw_networkx_nodes(
                self.graph, pos, node_size=2000, node_color="lightblue", alpha=0.7
            )

            # ç»˜åˆ¶è¾¹
            nx.draw_networkx_edges(
                self.graph, pos, arrows=True, arrowsize=20, alpha=0.6
            )

            # ç»˜åˆ¶æ ‡ç­¾
            nx.draw_networkx_labels(self.graph, pos, font_size=10, font_weight="bold")

            plt.title("Tool Dependency Graph", fontsize=16)
            plt.axis("off")
            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches="tight")
            plt.close()

            logger.info(f"âœ… å›¾å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")

        except ImportError:
            logger.error("âŒ éœ€è¦å®‰è£…matplotlibæ‰èƒ½å¯è§†åŒ–å›¾è°±")
        except Exception as e:
            logger.error(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")


# æ³¨æ„ï¼šæµ‹è¯•ä»£ç å·²ç§»è‡³ tests/test_graph.py


==================== FILE: engine/__init__.py ====================
"""
Sloop å¼•æ“åŒ…

å¯¼å‡ºæ ¸å¿ƒå¼•æ“ç»„ä»¶ã€‚
"""

from sloop.engine.blueprint import BlueprintGenerator
from sloop.engine.graph import ToolGraphBuilder
from sloop.engine.pda import ConversationPDA, PDAStates

__all__ = [
    "ConversationPDA",
    "PDAStates",
    "ToolGraphBuilder",
    "BlueprintGenerator",
]


==================== FILE: engine/pda.py ====================
"""
ä¸‹æ¨è‡ªåŠ¨æœº (PDA) æ ¸å¿ƒå¼•æ“

å®ç°å¯¹è¯ç”Ÿæˆçš„æ ¸å¿ƒå¾ªç¯é€»è¾‘ï¼Œä½¿ç”¨ transitions åº“ç®¡ç†çŠ¶æ€æµè½¬ï¼Œæ”¯æŒæ ˆæ“ä½œã€‚
"""

import json
import random
from typing import List

from transitions import Machine

from sloop.agents import AssistantAgent, ServiceAgent, UserAgent
from sloop.models import (
    Blueprint,
    ChatMessage,
    ConversationContext,
    ToolDefinition,
)
from sloop.utils.logger import logger

# è®¾ç½®æ—¥å¿—


# çŠ¶æ€å¸¸é‡å®šä¹‰
class PDAStates:
    """PDA çŠ¶æ€å¸¸é‡ - ç»†ç²’åº¦çŠ¶æ€ç®¡ç†"""

    USER_GEN = "user_gen"
    ASSISTANT_THINK = "assistant_think"
    ASSISTANT_DECIDE = "assistant_decide"
    TOOL_CALL_GEN = "tool_call_gen"
    TOOL_EXEC = "tool_exec"
    ASSISTANT_REPLY_GEN = "assistant_reply_gen"
    EVALUATION = "evaluation"
    FINISH = "finish"


class ConversationPDA:
    """
    å¯¹è¯å¾ªç¯ä¸‹æ¨è‡ªåŠ¨æœº

    ç®¡ç†å®Œæ•´çš„å¯¹è¯ç”Ÿæˆæµç¨‹ï¼Œä»åˆå§‹åŒ–åˆ°ç»“æŸã€‚
    ä½¿ç”¨ transitions.Machine å®ç°çŠ¶æ€æµè½¬ï¼Œæ”¯æŒæ ˆæ“ä½œã€‚
    """

    def __init__(
        self,
        blueprint: Blueprint,
        tools: List[ToolDefinition],
        conversation_id: str = None,
        max_turns: int = 20,
    ):
        """
        åˆå§‹åŒ–å¯¹è¯å¾ªç¯

        å‚æ•°:
            blueprint: ä»»åŠ¡è“å›¾
            tools: å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
            conversation_id: å¯¹è¯IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
            max_turns: æœ€å¤§å¯¹è¯è½®æ•°
        """
        self.blueprint = blueprint
        self.tools = tools
        self.conversation_id = conversation_id or f"conv_{random.randint(1000, 9999)}"

        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.user_agent = UserAgent()
        self.assistant_agent = AssistantAgent(tools)
        self.service_agent = ServiceAgent()

        # åˆå§‹åŒ–å¯¹è¯ä¸Šä¸‹æ–‡
        self.context = ConversationContext(
            conversation_id=self.conversation_id,
            blueprint_id=getattr(blueprint, "id", None),
            initial_state=blueprint.initial_state.copy(),
            current_user_intent=blueprint.intent,
            max_turns=max_turns,
        )

        # åˆå§‹åŒ–ç¯å¢ƒçŠ¶æ€
        self.context.env_state.update(blueprint.initial_state)

        # åˆå§‹åŒ–ç”¨æˆ·è½®æ•°è®¡æ•°å™¨
        self.user_turn_count = 0

        # è®¾ç½®çŠ¶æ€æœº
        self._setup_state_machine()

        # æ‰‹åŠ¨è§¦å‘åˆå§‹çŠ¶æ€çš„å›è°ƒï¼ˆtransitionsä¸ä¼šè‡ªåŠ¨è°ƒç”¨ï¼‰
        self.on_enter_user_gen()

        logger.info(f"ğŸ¬ ConversationPDA initialized: {self.conversation_id}")

    def _setup_state_machine(self):
        """è®¾ç½®çŠ¶æ€æœº"""
        # å®šä¹‰çŠ¶æ€
        states = [
            PDAStates.USER_GEN,
            PDAStates.ASSISTANT_THINK,
            PDAStates.ASSISTANT_DECIDE,
            PDAStates.TOOL_CALL_GEN,
            PDAStates.TOOL_EXEC,
            PDAStates.ASSISTANT_REPLY_GEN,
            PDAStates.EVALUATION,
            PDAStates.FINISH,
        ]

        # å®šä¹‰çŠ¶æ€æœº
        self.machine = Machine(
            model=self,
            states=states,
            initial=PDAStates.USER_GEN,
            model_attribute="current_state",
        )

        # å®šä¹‰çŠ¶æ€è½¬æ¢
        self.machine.add_transition(
            "user_generated", PDAStates.USER_GEN, PDAStates.ASSISTANT_THINK
        )
        self.machine.add_transition(
            "thought_generated", PDAStates.ASSISTANT_THINK, PDAStates.ASSISTANT_DECIDE
        )
        self.machine.add_transition(
            "decide_tool_call", PDAStates.ASSISTANT_DECIDE, PDAStates.TOOL_CALL_GEN
        )
        self.machine.add_transition(
            "decide_reply", PDAStates.ASSISTANT_DECIDE, PDAStates.ASSISTANT_REPLY_GEN
        )
        self.machine.add_transition(
            "tool_calls_generated", PDAStates.TOOL_CALL_GEN, PDAStates.TOOL_EXEC
        )
        self.machine.add_transition(
            "skip_tools_reply", PDAStates.TOOL_CALL_GEN, PDAStates.ASSISTANT_REPLY_GEN
        )  # æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶ç›´æ¥å›å¤
        self.machine.add_transition(
            "tools_executed", PDAStates.TOOL_EXEC, PDAStates.ASSISTANT_THINK
        )  # ReAct é—­ç¯
        self.machine.add_transition(
            "reply_generated", PDAStates.ASSISTANT_REPLY_GEN, PDAStates.EVALUATION
        )
        self.machine.add_transition(
            "continue_dialogue", PDAStates.EVALUATION, PDAStates.USER_GEN
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.EVALUATION, PDAStates.FINISH
        )
        # å…è®¸ä»ä»»ä½•çŠ¶æ€ç›´æ¥ç»“æŸå¯¹è¯
        self.machine.add_transition(
            "finish_dialogue", PDAStates.USER_GEN, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_THINK, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_DECIDE, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.TOOL_CALL_GEN, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.TOOL_EXEC, PDAStates.FINISH
        )
        self.machine.add_transition(
            "finish_dialogue", PDAStates.ASSISTANT_REPLY_GEN, PDAStates.FINISH
        )

        # æ³¨æ„ï¼štransitionsåº“ä¼šè‡ªåŠ¨ç»‘å®šåä¸º on_enter_{state_name} çš„æ–¹æ³•ä½œä¸ºçŠ¶æ€è¿›å…¥å›è°ƒ
        # æ— éœ€æ‰‹åŠ¨ç»‘å®šï¼Œä»¥é¿å…é‡å¤ç»‘å®šå¯¼è‡´çš„å›è°ƒæ‰§è¡Œé—®é¢˜

    def _generate_context_hint(self) -> str:
        """ç”Ÿæˆæ ˆä¸Šä¸‹æ–‡æç¤ºä¿¡æ¯"""
        stack_top = self.context.peek_context()
        if not stack_top or stack_top["type"] == "ROOT":
            return ""

        if stack_top["type"] == "WAITING_FOR_TOOLS":
            tool_names = stack_top["data"].get("tool_names", [])
            intent = stack_top["data"].get("intent", "æœªçŸ¥æ„å›¾")
            nested_level = stack_top["data"].get("nested_level", 0)
            indent = "  " * nested_level
            return f"{indent}ç³»ç»Ÿæç¤ºï¼šä½ æ­£åœ¨ç­‰å¾…å·¥å…·ç»“æœæ¥å®Œæˆå­ä»»åŠ¡ã€‚ç­‰å¾…çš„å·¥å…·ï¼š{', '.join(tool_names)}ã€‚ä»»åŠ¡æ„å›¾ï¼š{intent}ã€‚è¯·åŸºäºæœ€æ–°å·¥å…·ç»“æœç»§ç»­æ¨ç†ã€‚"

        return ""

    def _extract_intent_from_thought(self, thought: str) -> str:
        """ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–æ„å›¾æ‘˜è¦"""
        if not thought:
            return "æœªçŸ¥æ„å›¾"
        # ç®€å•æå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ„å›¾æ‘˜è¦
        return thought[:50].strip() + "..." if len(thought) > 50 else thought.strip()

    # ==================== çŠ¶æ€å›è°ƒæ–¹æ³• ====================

    def on_enter_user_gen(self):
        """è¿›å…¥ç”¨æˆ·æ¶ˆæ¯ç”ŸæˆçŠ¶æ€"""
        logger.info("ğŸ‘¤ [USER_GEN] ç”¨æˆ·æ¶ˆæ¯ç”Ÿæˆ")
        self.user_turn_count += 1
        logger.info(f"ğŸ‘¤ [USER_GEN] ç”¨æˆ·è½®æ¬¡ {self.user_turn_count}")

        # æ¸…ç©ºä¸Šä¸€è½®çš„ç¼“å†²åŒº
        self.context.clear_buffers()

        # è°ƒç”¨ç”¨æˆ·æ™ºèƒ½ä½“ç”Ÿæˆæ¶ˆæ¯
        user_message_content = self.user_agent.generate_message(
            self.blueprint, self.context.messages
        )

        # æ£€æŸ¥æ˜¯å¦ä»»åŠ¡å®Œæˆï¼Œå¹¶å¤„ç†åœæ­¢æ ‡è®°
        should_stop = self.user_agent.is_task_complete(user_message_content)
        if should_stop:
            # å‰¥ç¦»åœæ­¢æ ‡è®°ï¼Œä¿ç•™å¹²å‡€çš„æ¶ˆæ¯å†…å®¹
            user_message_content = user_message_content.replace(
                "###STOP###", ""
            ).strip()
            logger.info("   âœ… ç”¨æˆ·è¡¨ç¤ºä»»åŠ¡å®Œæˆ")

        # å¦‚æœæ¶ˆæ¯å†…å®¹ä¸ä¸ºç©ºï¼Œå§‹ç»ˆæ·»åŠ åˆ°å¯¹è¯å†å²
        if user_message_content:
            # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡å¹¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            user_message = ChatMessage(role="user", content=user_message_content)
            self.context.add_message(user_message)
            logger.info(f"   ğŸ’¬ ç”¨æˆ·: {user_message.content}")

        # å¦‚æœéœ€è¦åœæ­¢ï¼Œåˆ™æ ‡è®°å®Œæˆå¹¶ç»“æŸå¯¹è¯
        if should_stop:
            self.context.is_completed = True
            self.finish_dialogue()
            return

        # è§¦å‘åˆ°åŠ©æ‰‹æ€è€ƒ
        self.user_generated()

    def on_enter_assistant_think(self):
        """è¿›å…¥åŠ©æ‰‹æ€è€ƒçŠ¶æ€ - ç”Ÿæˆ CoT"""
        logger.info("ğŸ¤– [ASSISTANT_THINK] åŠ©æ‰‹æ­£åœ¨ç”Ÿæˆæ€è€ƒè¿‡ç¨‹")
        logger.info("ğŸ¤– [ASSISTANT_THINK] åŠ©æ‰‹æ­£åœ¨ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ (CoT)...")
        logger.info(
            f"   ğŸ“š å½“å‰æ ˆçŠ¶æ€: {[frame['type'] for frame in self.context.stack]}"
        )

        # ç”Ÿæˆæ ˆä¸Šä¸‹æ–‡æç¤º
        context_hint = self._generate_context_hint()

        # è°ƒç”¨åŠ©æ‰‹æ™ºèƒ½ä½“ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thought_content = self.assistant_agent.generate_thought(
            self.context.messages, context_hint
        )

        # å­˜å‚¨åˆ°ä¸Šä¸‹æ–‡ç¼“å†²åŒº
        self.context.current_thought = thought_content
        logger.info(f"   ğŸ’­ æ€è€ƒè¿‡ç¨‹: {thought_content[:100]}...")

        # è§¦å‘åˆ°å†³ç­–çŠ¶æ€
        self.thought_generated()

    def on_enter_assistant_decide(self):
        """è¿›å…¥åŠ©æ‰‹å†³ç­–çŠ¶æ€ - åŸºäºæ€è€ƒå†³å®šä¸‹ä¸€æ­¥"""
        logger.info("ğŸ¤– [ASSISTANT_DECIDE] åŠ©æ‰‹æ­£åœ¨å†³ç­–")
        logger.info("ğŸ¤– [ASSISTANT_DECIDE] åŸºäºæ€è€ƒè¿‡ç¨‹è¿›è¡Œå†³ç­–...")

        # æ£€æŸ¥æ ˆé¡¶æ˜¯å¦ä¸ºWAITING_FOR_TOOLSï¼Œå¦‚æœæ˜¯åˆ™æ ¹æ®å†³ç­–è¿›è¡ŒPOPæ“ä½œ
        stack_top = self.context.peek_context()
        was_waiting = stack_top and stack_top["type"] == "WAITING_FOR_TOOLS"

        # åŸºäºæ€è€ƒè¿‡ç¨‹å†³å®šæ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
        needs_tools = self.assistant_agent.decide_tool_use(self.context.current_thought)

        if needs_tools:
            if was_waiting:
                # ä»»åŠ¡è¿›å±•ï¼šPOPæ—§çš„WAITINGå¸§ï¼Œä¸ºæ–°çš„å·¥å…·è°ƒç”¨è®©è·¯
                popped = self.context.pop_context()
                logger.info(f"   ğŸ“š POP æ ˆ: {popped['type']} - ä»»åŠ¡è¿›å±•ï¼Œç»§ç»­è°ƒç”¨å·¥å…·")
            logger.info("   ğŸ”§ å†³ç­–: éœ€è¦è°ƒç”¨å·¥å…·")
            self.decide_tool_call()
        else:
            if was_waiting:
                # å­ä»»åŠ¡å®Œæˆï¼šPOP WAITINGå¸§
                popped = self.context.pop_context()
                logger.info(f"   ğŸ“š POP æ ˆ: {popped['type']} - å­ä»»åŠ¡å®Œæˆ")
            logger.info("   ğŸ’¬ å†³ç­–: ç›´æ¥å›å¤")
            self.decide_reply()

    def on_enter_tool_call_gen(self):
        """è¿›å…¥å·¥å…·è°ƒç”¨ç”ŸæˆçŠ¶æ€ - ç”Ÿæˆå…·ä½“çš„å·¥å…·è°ƒç”¨å‚æ•°"""
        logger.info("ğŸ”§ [TOOL_CALL_GEN] ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°")
        logger.info("ğŸ”§ [TOOL_CALL_GEN] åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°...")

        # åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨
        tool_calls = self.assistant_agent.generate_tool_calls(
            self.context.current_thought, self.tools
        )

        if tool_calls:
            # PUSH ç­‰å¾…å·¥å…·ç»“æœçš„ä¸Šä¸‹æ–‡å¸§
            tool_names = [tc.name for tc in tool_calls]
            nested_level = self.context.get_stack_depth()
            self.context.push_context(
                "WAITING_FOR_TOOLS",
                {
                    "tool_names": tool_names,
                    "intent": self._extract_intent_from_thought(
                        self.context.current_thought
                    ),
                    "nested_level": nested_level,
                },
            )
            logger.info(f"   ğŸ“š PUSH æ ˆ: WAITING_FOR_TOOLS - å·¥å…·: {tool_names}")

            # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºç‹¬ç«‹çš„ tool_call æ¶ˆæ¯ï¼ˆæ‰å¹³åŒ–æ ¼å¼ï¼‰
            for tool_call in tool_calls:
                tool_call_data = {
                    "name": tool_call.name,
                    "arguments": tool_call.arguments,
                }
                tool_call_message = ChatMessage(
                    role="tool_call",
                    content=json.dumps(tool_call_data, ensure_ascii=False),
                )
                self.context.add_message(tool_call_message)

            # åŒæ—¶å­˜å‚¨åˆ°pendingåˆ—è¡¨ä¾›åç»­æ‰§è¡Œ
            self.context.pending_tool_calls.extend(tool_calls)
            logger.info(f"   ğŸ“ ç”Ÿæˆ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯")

            # è§¦å‘å·¥å…·æ‰§è¡Œ
            self.tool_calls_generated()
        else:
            logger.info("   ğŸ“ æ²¡æœ‰ç”Ÿæˆå·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿›å…¥å›å¤ç”Ÿæˆ")
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿›å…¥å›å¤ç”ŸæˆçŠ¶æ€
            self.skip_tools_reply()

    def on_enter_tool_exec(self):
        """è¿›å…¥å·¥å…·æ‰§è¡ŒçŠ¶æ€"""
        logger.info("ğŸ› ï¸ [TOOL_EXEC] æ­£åœ¨æ‰§è¡Œå·¥å…·")
        logger.info("ğŸ› ï¸ [TOOL_EXEC] æ‰§è¡Œå·¥å…·è°ƒç”¨...")

        # å¤„ç†æ‰€æœ‰pendingçš„å·¥å…·è°ƒç”¨
        while self.context.pending_tool_calls:
            tool_call = self.context.pending_tool_calls.pop(0)

            logger.info(f"   ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call.name}")

            # è°ƒç”¨æœåŠ¡æ™ºèƒ½ä½“æ‰§è¡Œå·¥å…·
            execution_result = self.service_agent.execute_tool(
                tool_call, self.context.env_state, self.blueprint
            )

            # æ›´æ–°ç¯å¢ƒçŠ¶æ€
            if execution_result["state_updates"]:
                self.service_agent.update_state(
                    self.context.env_state, execution_result["state_updates"]
                )
                logger.info(f"   ğŸ“Š çŠ¶æ€æ›´æ–°: {execution_result['state_updates']}")

            # åˆ›å»ºå·¥å…·æ¶ˆæ¯
            tool_message = ChatMessage(
                role="tool",
                content=execution_result["response"],
                tool_call_id=f"call_{random.randint(1000, 9999)}",
            )
            self.context.add_message(tool_message)

            logger.info(f"   âœ… å·¥å…·æ‰§è¡Œç»“æœ: {execution_result['response']}")

        # è¿”å›åˆ°åŠ©æ‰‹æ€è€ƒï¼ˆReActé—­ç¯ï¼‰
        self.tools_executed()

    def on_enter_assistant_reply_gen(self):
        """è¿›å…¥åŠ©æ‰‹å›å¤ç”ŸæˆçŠ¶æ€ - ç”Ÿæˆæœ€ç»ˆå›å¤æ–‡æœ¬"""
        logger.info("ğŸ¤– [ASSISTANT_REPLY_GEN] ç”Ÿæˆæœ€ç»ˆå›å¤")
        logger.info("ğŸ¤– [ASSISTANT_REPLY_GEN] åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤...")

        # åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤
        reply_content = self.assistant_agent.generate_reply(
            self.context.current_thought, self.context.messages
        )

        # å°†æ€è€ƒè¿‡ç¨‹å’Œå›å¤æ‹¼æ¥ä¸ºå®Œæ•´å†…å®¹ï¼ˆç”¨äºè®­ç»ƒæ•°æ®æ ¼å¼ï¼‰
        full_content = (
            f"<think>\n{self.context.current_thought}\n</think>\n\n{reply_content}"
        )

        # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆåŒ…å«æ€è€ƒå’Œå›å¤ï¼‰
        assistant_message = ChatMessage(role="assistant", content=full_content)
        self.context.add_message(assistant_message)

        logger.info(f"   ğŸ’¬ åŠ©æ‰‹å›å¤: {full_content[:100]}...")

        # è§¦å‘åˆ°è¯„ä¼°çŠ¶æ€
        self.reply_generated()

    def on_enter_evaluation(self):
        """è¿›å…¥è¯„ä¼°çŠ¶æ€"""
        logger.info("ğŸ“Š [EVALUATION] è¯„ä¼°å¯¹è¯çŠ¶æ€")
        logger.info("ğŸ“Š [EVALUATION] è¯„ä¼°å¯¹è¯çŠ¶æ€...")

        # å¦‚æœå·²ç»å®Œæˆï¼Œä¸è¦é‡å¤å¤„ç†
        if self.context.is_completed:
            logger.info("   âœ… å¯¹è¯å·²å®Œæˆï¼Œè·³è¿‡è¯„ä¼°")
            return

        self.context.increment_turn()

        # è¯„ä¼°ç»“æŸæ¡ä»¶ï¼ˆç§»é™¤éšæœºç»“æŸé€»è¾‘ï¼Œç¡®ä¿å¯¹è¯å……åˆ†å±•å¼€ï¼‰
        should_finish = (
            self.context.turn_count >= self.context.max_turns
            or self.context.env_state.validate_transition(self.blueprint.expected_state)
        )

        if should_finish:
            logger.info("   ğŸ æ»¡è¶³ç»“æŸæ¡ä»¶ï¼Œå®Œæˆå¯¹è¯")
            self.finish_dialogue()
            return  # ç«‹å³è¿”å›ï¼Œé¿å…åç»­é€»è¾‘
        else:
            logger.info("   ğŸ”„ ç»§ç»­ä¸‹ä¸€è½®å¯¹è¯")
            self.continue_dialogue()

    def on_enter_finish(self):
        """è¿›å…¥ç»“æŸçŠ¶æ€"""
        logger.info("âœ… [FINISH] å¯¹è¯å®Œæˆ")
        logger.info(f"âœ… [FINISH] å¯¹è¯ {self.conversation_id} å®Œæˆ")
        logger.info(f"   ğŸ“ˆ æ€»è½®æ¬¡: {self.context.turn_count}")
        logger.info(f"   ğŸ“ æ¶ˆæ¯æ•°é‡: {len(self.context.messages)}")
        logger.info(f"   ğŸ¯ æœ€ç»ˆçŠ¶æ€: {self.context.env_state.state}")

    def run(self):
        """è¿è¡Œå®Œæ•´çš„å¯¹è¯å¾ªç¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç«‹å³æ‰§è¡Œæ‰€æœ‰çŠ¶æ€è½¬æ¢ï¼‰"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œå¯¹è¯å¾ªç¯")
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œå¯¹è¯å¾ªç¯...")

        # åœ¨å ä½ç¬¦å®ç°ä¸­ï¼Œæ‰€æœ‰çŠ¶æ€è½¬æ¢éƒ½æ˜¯åŒæ­¥çš„
        # çŠ¶æ€æœºå·²ç»åœ¨åˆå§‹åŒ–æ—¶å¯åŠ¨(on_enter_initä¼šè°ƒç”¨start_conversation)
        # è¿™é‡Œåªéœ€è¦ç­‰å¾…çŠ¶æ€æœºå®Œæˆæ‰€æœ‰è½¬æ¢

        # ç­‰å¾…ç›´åˆ°è¾¾åˆ°ç»“æŸçŠ¶æ€ï¼ˆæœ€å¤šç­‰å¾…100æ¬¡ï¼Œé¿å…æ— é™å¾ªç¯ï¼‰
        max_wait = 100
        wait_count = 0
        while self.current_state != PDAStates.FINISH and wait_count < max_wait:
            wait_count += 1

        if self.current_state == PDAStates.FINISH:
            logger.info("ğŸ‰ å¯¹è¯å¾ªç¯è¿è¡Œå®Œæˆ")
            logger.info("ğŸ‰ å¯¹è¯å¾ªç¯è¿è¡Œå®Œæˆ")
        else:
            logger.warning(
                f"âš ï¸ å¯¹è¯å¾ªç¯æœªåœ¨{max_wait}æ­¥å†…å®Œæˆï¼Œå½“å‰çŠ¶æ€: {self.current_state}"
            )
            logger.warning(
                f"âš ï¸ å¯¹è¯å¾ªç¯æœªåœ¨{max_wait}æ­¥å†…å®Œæˆï¼Œå½“å‰çŠ¶æ€: {self.current_state}"
            )

    # æ³¨æ„ï¼šcurrent_state ç”± transitions åº“è‡ªåŠ¨è®¾ç½®ï¼Œæ— éœ€ property

    def get_status(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return {
            "conversation_id": self.conversation_id,
            "current_state": self.current_state,
            "turn_count": self.context.turn_count,
            "is_completed": self.context.is_completed,
            "message_count": len(self.context.messages),
        }


# ==================== è‡ªæµ‹ä»£ç  ====================

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—

    # åˆ›å»ºæµ‹è¯•å·¥å…·
    test_tools = [
        ToolDefinition(
            name="get_weather",
            description="Get weather information",
            parameters={
                "type": "object",
                "properties": {"location": {"type": "string"}},
                "required": ["location"],
            },
        ),
        ToolDefinition(
            name="get_location",
            description="Get user location",
            parameters={"type": "object", "properties": {}, "required": []},
        ),
    ]

    # åˆ›å»ºæµ‹è¯•è“å›¾
    test_blueprint = Blueprint(
        intent="æŸ¥è¯¢å¤©æ°”",
        required_tools=["get_weather", "get_location"],
        ground_truth=["get_weather"],
        initial_state={"weather_data": None},
        expected_state={"weather_data": "sunny"},
    )

    # åˆ›å»ºå¯¹è¯å¾ªç¯
    loop = ConversationPDA(test_blueprint, test_tools, "test_conv_001")

    # è¿è¡Œå¯¹è¯
    logger.info("=" * 50)
    logger.info("ğŸ¬ å¼€å§‹PDAæµ‹è¯•")
    logger.info("=" * 50)

    loop.run()

    logger.info("=" * 50)
    logger.info("ğŸ“Š æœ€ç»ˆçŠ¶æ€:")
    logger.info(loop.get_status())
    logger.info("=" * 50)
