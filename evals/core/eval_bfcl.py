import os
import json
import sys
from evalscope import TaskConfig, run_task

def main():
    # --- è¯»å–ç¯å¢ƒå˜é‡ ---
    model_name = os.getenv('EVAL_MODEL_NAME')
    api_url = os.getenv('EVAL_API_URL')
    api_key = os.getenv('EVAL_API_KEY', 'EMPTY')
    output_dir = os.getenv('EVAL_OUTPUT_DIR')
    
    # è·å– eval_limitï¼Œå¦‚æœæœªè®¾ç½®æˆ–ä¸º -1 åˆ™ä¸º None (è·‘å…¨é‡)
    limit_env = os.getenv('EVAL_LIMIT')
    eval_limit = int(limit_env) if limit_env and int(limit_env) > 0 else None

    print(f"ğŸ”§ Config: Model={model_name}, URL={api_url}, Limit={eval_limit}")

    # --- é…ç½®ä»»åŠ¡ ---
    task_cfg = TaskConfig(
        model=model_name,
        api_url=api_url,
        api_key=api_key,
        eval_type='openai_api',
        datasets=['bfcl_v3'],
        eval_batch_size=int(os.getenv('EVAL_BATCH_SIZE', '10')),
        dataset_args={
            'bfcl_v3': {
                'extra_params': {
                    'underscore_to_dot': True,
                    'is_fc_model': True,
                }
            }
        },
        generation_config={
            'temperature': 0,
            'max_tokens': 32000,
            'parallel_tool_calls': True,
        },
        limit=eval_limit, 
    )

    # --- æ‰§è¡Œè¯„æµ‹ ---
    try:
        # run_task å†…éƒ¨ä¼šè‡ªåŠ¨æ‰“å°å¾ˆå¤šæ—¥å¿—
        result = run_task(task_cfg=task_cfg)
        
        # ä¹Ÿå¯ä»¥é€‰æ‹©æ€§åœ°æŠŠ result å­˜æˆ jsonï¼Œè™½ç„¶ EvalScope é€šå¸¸è‡ªå·±ä¹Ÿä¼šå­˜
        if output_dir:
            res_path = os.path.join(output_dir, "result_summary.json")
            with open(res_path, "w") as f:
                json.dump(result, f, indent=4, ensure_ascii=False)
            print(f"âœ… Python Script Finished. Summary saved to {res_path}")

    except Exception as e:
        print(f"âŒ Python Execution Failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()