"""
Sloop CLI ä¸»å…¥å£
åŸºäºCrewAIçš„æ•°æ®ç”Ÿæˆå·¥å…·
"""

import json
import typer
from pathlib import Path
from typing import Optional

from sloop.core.config import config
from sloop.core.api_structure import load_apis_from_file
from sloop.core.data_generator import BatchDataGenerator

app = typer.Typer(
    help="Sloop: åŸºäºCrewAIçš„æ™ºèƒ½å·¥å…·è°ƒç”¨æ•°æ®ç”Ÿæˆå™¨",
    add_completion=False
)


@app.command()
def gen(
    services_file: str = typer.Option(
        "services.json", "--services", "-s",
        help="APIæœåŠ¡å®šä¹‰æ–‡ä»¶è·¯å¾„"
    ),
    output_file: str = typer.Option(
        "dataset.json", "--output", "-o",
        help="è¾“å‡ºæ•°æ®é›†æ–‡ä»¶è·¯å¾„"
    ),
    num_conversations: int = typer.Option(
        10, "--num-conversations", "-n",
        help="ç”Ÿæˆå¯¹è¯æ•°é‡", min=1, max=1000
    ),
    apis_per_conversation: int = typer.Option(
        3, "--apis-per-conversation", "-k",
        help="æ¯ä¸ªå¯¹è¯ä½¿ç”¨çš„APIæ•°é‡", min=1, max=10
    ),
    target_turns: int = typer.Option(
        10, "--target-turns", "-t",
        help="ç›®æ ‡å¯¹è¯è½®æ•°ï¼ˆå…è®¸Â±40%åå·®ï¼‰", min=3, max=50
    ),
    sampling_strategy: str = typer.Option(
        "balanced", "--sampling-strategy",
        help="APIé‡‡æ ·ç­–ç•¥ (random/balanced/connected)"
    ),
    structure_type: str = typer.Option(
        "tree", "--structure-type",
        help="APIç»“æ„åŒ–ç±»å‹ (tree/graph/auto)"
    ),
    verbose: bool = typer.Option(
        True, "--verbose", "-v",
        help="å¯ç”¨è¯¦ç»†è¾“å‡º"
    ),
):
    """
    ä½¿ç”¨CrewAIç”Ÿæˆé«˜è´¨é‡çš„å¤šè½®å·¥å…·è°ƒç”¨å¯¹è¯æ•°æ®é›†

    å·¥ä½œæµç¨‹:
    1. åŠ è½½å¹¶ç»“æ„åŒ–APIå®šä¹‰ï¼ˆæ ‘å½¢/å›¾å½¢ï¼‰
    2. æ™ºèƒ½é‡‡æ ·ç›¸å…³APIç»„åˆ
    3. å¤šAgentåä½œç”Ÿæˆå¯¹è¯æ•°æ®
    4. è¾“å‡ºæ ‡å‡†æ ¼å¼çš„æ•°æ®é›†
    """
    # éªŒè¯é…ç½®
    if not config.validate():
        typer.secho(
            "âŒ é…ç½®é”™è¯¯: è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ SLOOP_STRONG_API_KEY å’Œ SLOOP_STRONG_BASE_URL",
            fg=typer.colors.RED,
            err=True
        )
        raise typer.Exit(1)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    services_path = Path(services_file)
    if not services_path.exists():
        typer.secho(
            f"âŒ æœåŠ¡æ–‡ä»¶ä¸å­˜åœ¨: {services_file}",
            fg=typer.colors.RED,
            err=True
        )
        raise typer.Exit(1)

    # è®¾ç½®verbose
    config.verbose = verbose

    try:
        # åŠ è½½APIå®šä¹‰
        typer.echo("ğŸ“š åŠ è½½APIæœåŠ¡å®šä¹‰...")
        apis = load_apis_from_file(services_file)
        if not apis:
            typer.secho("âŒ APIæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯", fg=typer.colors.RED)
            raise typer.Exit(1)

        typer.echo(f"âœ… åŠ è½½äº† {len(apis)} ä¸ªAPIå®šä¹‰")

        # æ˜¾ç¤ºAPIç»“æ„ä¿¡æ¯
        from sloop.core.api_structure import APICollection
        api_collection = APICollection(apis, structure_type)
        structure_info = api_collection.get_structure_info()

        typer.echo(f"ğŸ—ï¸  APIç»“æ„åŒ–ç±»å‹: {structure_info['type']}")
        if structure_info['type'] == 'tree':
            typer.echo(f"ğŸ“ è¯†åˆ«å‡º {len(structure_info['categories'])} ä¸ªåŠŸèƒ½ç±»åˆ«: {', '.join(structure_info['categories'][:5])}{'...' if len(structure_info['categories']) > 5 else ''}")
        else:
            typer.echo(f"ğŸ”— å›¾ç»“æ„: {structure_info['nodes']} èŠ‚ç‚¹, {structure_info['edges']} è¾¹")

        # åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨
        typer.echo("ğŸ¤– åˆå§‹åŒ–CrewAIæ•°æ®ç”Ÿæˆå™¨...")
        generator = BatchDataGenerator(apis, structure_type)

        # æ˜¾ç¤ºç”Ÿæˆè®¡åˆ’
        typer.echo(f"ğŸ¯ ç”Ÿæˆè®¡åˆ’:")
        typer.echo(f"   â€¢ å¯¹è¯æ•°é‡: {num_conversations}")
        typer.echo(f"   â€¢ æ¯å¯¹è¯APIæ•°: {apis_per_conversation}")
        typer.echo(f"   â€¢ é‡‡æ ·ç­–ç•¥: {sampling_strategy}")
        typer.echo(f"   â€¢ è¾“å‡ºæ–‡ä»¶: {output_file}")

        # ç¡®è®¤å¼€å§‹ç”Ÿæˆ
        if not typer.confirm("\nğŸš€ å¼€å§‹ç”Ÿæˆæ•°æ®é›†?", default=True):
            typer.echo("å·²å–æ¶ˆ")
            return

        # ç”Ÿæˆæ•°æ®é›†
        typer.echo("\nâš¡ å¼€å§‹ç”Ÿæˆå¯¹è¯æ•°æ®...")
        dataset = generator.generate_dataset(
            num_conversations=num_conversations,
            apis_per_conversation=apis_per_conversation,
            sampling_strategy=sampling_strategy,
            target_turns=target_turns,
            output_file=output_file
        )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if dataset:
            total_conversations = len(dataset)
            avg_quality = sum(conv.get('quality_score', 0) for conv in dataset) / total_conversations
            api_usage = {}
            for conv in dataset:
                for api_name in conv.get('apis_used', []):
                    api_usage[api_name] = api_usage.get(api_name, 0) + 1

            typer.echo(f"\nğŸ‰ ç”Ÿæˆå®Œæˆ!")
            typer.echo(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            typer.echo(f"   â€¢ æˆåŠŸç”Ÿæˆå¯¹è¯: {total_conversations}")
            typer.echo(f"   â€¢ å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.2f}")
            typer.echo(f"   â€¢ APIä½¿ç”¨é¢‘ç‡: {dict(sorted(api_usage.items(), key=lambda x: x[1], reverse=True)[:5])}")
            typer.echo(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
        else:
            typer.secho("âŒ ç”Ÿæˆå¤±è´¥: æœªäº§ç”Ÿä»»ä½•å¯¹è¯æ•°æ®", fg=typer.colors.RED)

    except Exception as e:
        typer.secho(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}", fg=typer.colors.RED, err=True)
        if verbose:
            import traceback
            typer.echo(traceback.format_exc())
        raise typer.Exit(1)


@app.command()
def analyze(
    services_file: str = typer.Option(
        "services.json", "--services", "-s",
        help="APIæœåŠ¡å®šä¹‰æ–‡ä»¶è·¯å¾„"
    ),
    structure_type: str = typer.Option(
        "auto", "--structure-type",
        help="APIç»“æ„åŒ–ç±»å‹ (tree/graph/auto)"
    ),
):
    """
    åˆ†æAPIæœåŠ¡å®šä¹‰ï¼Œæ˜¾ç¤ºç»“æ„åŒ–ä¿¡æ¯
    """
    try:
        apis = load_apis_from_file(services_file)
        api_collection = APICollection(apis, structure_type)
        structure_info = api_collection.get_structure_info()

        typer.echo("ğŸ“Š APIåˆ†æç»“æœ:"        typer.echo(f"   â€¢ æ€»APIæ•°é‡: {structure_info['total_apis']}")
        typer.echo(f"   â€¢ ç»“æ„ç±»å‹: {structure_info['type']}")

        if structure_info['type'] == 'tree':
            typer.echo(f"   â€¢ åŠŸèƒ½ç±»åˆ«: {len(structure_info['categories'])}")
            for category in structure_info['categories'][:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                apis_in_category = len([api for api in apis if api.get('category') == category or
                                      api_collection.structure._extract_category(api) == category])
                typer.echo(f"     - {category}: {apis_in_category} ä¸ªAPI")

        # æ˜¾ç¤ºAPIè¯¦æƒ…
        typer.echo("
ğŸ”§ APIè¯¦æƒ…:"        for i, api in enumerate(apis[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
            typer.echo(f"   {i}. {api['name']}: {api.get('description', 'No description')[:50]}...")

        if len(apis) > 5:
            typer.echo(f"   ... è¿˜æœ‰ {len(apis) - 5} ä¸ªAPI")

    except Exception as e:
        typer.secho(f"âŒ åˆ†æå¤±è´¥: {e}", fg=typer.colors.RED, err=True)
        raise typer.Exit(1)


@app.command()
def validate(
    dataset_file: str = typer.Option(
        ..., "--dataset", "-d",
        help="è¦éªŒè¯çš„æ•°æ®é›†æ–‡ä»¶è·¯å¾„"
    ),
):
    """
    éªŒè¯ç”Ÿæˆçš„æ•°æ®é›†æ ¼å¼å’Œè´¨é‡
    """
    try:
        with open(dataset_file, 'r', encoding='utf-8') as f:
            dataset = json.load(f)

        if not isinstance(dataset, list):
            typer.secho("âŒ æ•°æ®é›†æ ¼å¼é”™è¯¯: åº”ä¸ºæ•°ç»„", fg=typer.colors.RED)
            return

        typer.echo(f"ğŸ“Š æ•°æ®é›†éªŒè¯ç»“æœ:")
        typer.echo(f"   â€¢ å¯¹è¯æ•°é‡: {len(dataset)}")

        # æ£€æŸ¥æ ¼å¼
        valid_conversations = 0
        total_quality = 0

        for i, conv in enumerate(dataset):
            is_valid = True
            errors = []

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['conversation', 'label']
            for field in required_fields:
                if field not in conv:
                    is_valid = False
                    errors.append(f"ç¼ºå°‘å­—æ®µ: {field}")

            # æ£€æŸ¥conversationæ ¼å¼
            if 'conversation' in conv:
                conv_data = conv['conversation']
                if not isinstance(conv_data, list):
                    is_valid = False
                    errors.append("conversationåº”ä¸ºæ•°ç»„")
                elif conv_data and not all(isinstance(msg, dict) and 'role' in msg and 'content' in msg for msg in conv_data):
                    is_valid = False
                    errors.append("conversationæ¶ˆæ¯æ ¼å¼é”™è¯¯")

            # æ£€æŸ¥labelæ ¼å¼
            if 'label' in conv and isinstance(conv['label'], dict):
                label = conv['label']
                if 'tool_call' not in label or 'thought_process' not in label:
                    errors.append("labelç¼ºå°‘å¿…éœ€å­—æ®µ")
                else:
                    total_quality += conv.get('quality_score', 0.5)
            else:
                is_valid = False
                errors.append("labelæ ¼å¼é”™è¯¯")

            if is_valid:
                valid_conversations += 1
            elif i < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                typer.echo(f"   âš ï¸ å¯¹è¯ {i+1} æ ¼å¼é—®é¢˜: {', '.join(errors)}")

        validity_rate = valid_conversations / len(dataset) * 100
        avg_quality = total_quality / len(dataset)

        typer.echo(f"   â€¢ æ ¼å¼æœ‰æ•ˆç‡: {validity_rate:.1f}% ({valid_conversations}/{len(dataset)})")
        typer.echo(f"   â€¢ å¹³å‡è´¨é‡åˆ†: {avg_quality:.2f}")

        if validity_rate >= 95:
            typer.echo("âœ… æ•°æ®é›†è´¨é‡è‰¯å¥½")
        elif validity_rate >= 80:
            typer.echo("âš ï¸ æ•°æ®é›†è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®æ£€æŸ¥")
        else:
            typer.secho("âŒ æ•°æ®é›†è´¨é‡è¾ƒå·®ï¼Œéœ€è¦æ”¹è¿›", fg=typer.colors.RED)

    except Exception as e:
        typer.secho(f"âŒ éªŒè¯å¤±è´¥: {e}", fg=typer.colors.RED, err=True)
        raise typer.Exit(1)


if __name__ == "__main__":
    app()
