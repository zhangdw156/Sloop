"""
åŠ©æ‰‹æ¨¡æ‹Ÿå™¨ (Assistant Agent)

æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
"""

import logging
import json
import re
from typing import List, Optional, Dict, Any
from ..models import ToolDefinition, ChatMessage, ToolCall
from ..utils.llm import chat_completion
from ..utils.template import render_assistant_prompt

logger = logging.getLogger(__name__)


class AssistantAgent:
    """
    åŠ©æ‰‹æ™ºèƒ½ä½“

    è´Ÿè´£æ¨¡æ‹Ÿè¢«æµ‹è¯•çš„åŠ©æ‰‹æ¨¡å‹ï¼Œæ ¹æ®å·¥å…·å®šä¹‰å’Œå¯¹è¯å†å²ç”Ÿæˆå“åº”ï¼Œ
    å¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ã€‚
    """

    def __init__(self, tools: List[ToolDefinition]):
        """
        åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“

        å‚æ•°:
            tools: å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

        logger.info(f"AssistantAgent initialized with {len(tools)} tools")

    def generate_response(
        self,
        conversation_history: List[ChatMessage]
    ) -> str:
        """
        ç”ŸæˆåŠ©æ‰‹å“åº”

        å‚æ•°:
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²ï¼Œå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
        """
        logger.info("Generating assistant response")

        # æ„é€ æç¤º
        prompt = render_assistant_prompt(self.tools, conversation_history)

        # è°ƒç”¨LLMç”Ÿæˆå“åº”
        response = chat_completion(
            prompt=prompt,
            system_message="You are a helpful AI assistant with access to various tools. Use tools when appropriate to help the user.",
            json_mode=False  # è®©æ¨¡å‹è‡ªç”±è¾“å‡ºï¼Œå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨
        )

        if not response or response.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate assistant response: {response}")
            return "I'm sorry, I encountered an error. How can I help you?"  # é»˜è®¤å“åº”

        logger.info(f"Generated assistant response: {response[:100]}...")
        return response.strip()

    def parse_tool_calls(self, response: str) -> List[ToolCall]:
        """
        ä»å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []

        # å°è¯•è§£æJSONæ ¼å¼çš„å·¥å…·è°ƒç”¨
        # æŸ¥æ‰¾ç±»ä¼¼ {"tool_name": "...", "arguments": {...}} çš„æ¨¡å¼ï¼ˆå…¼å®¹nameå­—æ®µï¼‰
        json_pattern = r'\{[^}]*"(?:tool_name|name)"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
        matches = re.findall(json_pattern, response, re.DOTALL)

        for match in matches:
            tool_name, args_str = match
            try:
                arguments = json.loads(args_str)
                if tool_name in self.tool_map:
                    tool_call = ToolCall(
                        name=tool_name,
                        arguments=arguments
                    )
                    tool_calls.append(tool_call)
                    logger.info(f"Parsed tool call: {tool_name}")
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse tool call arguments: {args_str}")

        # å¦‚æœæ²¡æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾å‡½æ•°è°ƒç”¨æ¨¡å¼
        if not tool_calls:
            # æŸ¥æ‰¾ function_call æ¨¡å¼
            func_pattern = r'"function_call"\s*:\s*\{[^}]*"name"\s*:\s*"([^"]+)"[^}]*"arguments"\s*:\s*(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})\}'
            func_matches = re.findall(func_pattern, response, re.DOTALL)

            for match in func_matches:
                tool_name, args_str = match
                try:
                    arguments = json.loads(args_str)
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(
                            name=tool_name,
                            arguments=arguments
                        )
                        tool_calls.append(tool_call)
                        logger.info(f"Parsed function call: {tool_name}")
                except json.JSONDecodeError:
                    logger.warning(f"Failed to parse function call arguments: {args_str}")

        return tool_calls

    def should_call_tools(self, response: str) -> bool:
        """
        åˆ¤æ–­å“åº”æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨

        å‚æ•°:
            response: åŠ©æ‰‹å“åº”å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
        """
        return len(self.parse_tool_calls(response)) > 0

    def generate_thought(self, conversation_history: List[ChatMessage]) -> str:
        """
        ç”ŸæˆåŠ©æ‰‹æ€è€ƒè¿‡ç¨‹ (Chain of Thought)

        å‚æ•°:
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
        """
        logger.info("Generating assistant thought process (CoT)")

        # æ„é€ æ€è€ƒæç¤º
        prompt = f"""Based on the conversation history, generate a step-by-step reasoning process for how to respond to the user's latest message.

Conversation History:
{self._format_history(conversation_history)}

Please provide a detailed thought process considering:
1. What the user is asking for
2. What information you have
3. What tools might be needed
4. How to structure your response

Thought Process:"""

        # è°ƒç”¨LLMç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thought = chat_completion(
            prompt=prompt,
            system_message="You are a reasoning AI that generates detailed thought processes. Be thorough and logical.",
            json_mode=False
        )

        if not thought or thought.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate thought: {thought}")
            return "I need to analyze the user's request and determine the best way to respond."

        logger.info(f"Generated thought: {thought[:100]}...")
        return thought.strip()

    def decide_tool_use(self, thought: str) -> bool:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²

        è¿”å›:
            æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        """
        logger.info("Deciding whether to use tools based on thought process")

        prompt = f"""Based on the following thought process, determine if tools are needed to fulfill the user's request.

Thought Process:
{thought}

Available Tools:
{self._format_tools()}

Answer with only 'YES' or 'NO': Do tools need to be called?"""

        decision = chat_completion(
            prompt=prompt,
            system_message="You are a decision-making AI. Answer only with YES or NO.",
            json_mode=False
        ).strip().upper()

        needs_tools = decision.startswith('YES')
        logger.info(f"Tool use decision: {needs_tools}")
        return needs_tools

    def generate_tool_calls(self, thought: str, tools: List[ToolDefinition]) -> List[ToolCall]:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨

        è¿”å›:
            å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        logger.info("Generating tool calls based on thought process")

        prompt = f"""Based on the thought process, generate the appropriate tool calls in JSON format.

Thought Process:
{thought}

Available Tools:
{self._format_tools()}

Generate tool calls as a JSON array. Each tool call should have 'name' and 'arguments' fields.
If no tools are needed, return an empty array.

Tool Calls:"""

        response = chat_completion(
            prompt=prompt,
            system_message="You are a tool-calling AI. Generate tool calls in valid JSON format.",
            json_mode=True
        )

        try:
            tool_calls_data = json.loads(response)
            if not isinstance(tool_calls_data, list):
                tool_calls_data = [tool_calls_data]

            tool_calls = []
            for call_data in tool_calls_data:
                if isinstance(call_data, dict) and 'name' in call_data and 'arguments' in call_data:
                    tool_name = call_data['name']
                    if tool_name in self.tool_map:
                        tool_call = ToolCall(
                            name=tool_name,
                            arguments=call_data['arguments']
                        )
                        tool_calls.append(tool_call)
                        logger.info(f"Generated tool call: {tool_name}")

            return tool_calls

        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Failed to parse generated tool calls: {e}")
            return []

    def generate_reply(self, thought: str, conversation_history: List[ChatMessage]) -> str:
        """
        åŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆæœ€ç»ˆå›å¤

        å‚æ•°:
            thought: æ€è€ƒè¿‡ç¨‹å­—ç¬¦ä¸²
            conversation_history: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            æœ€ç»ˆå›å¤å­—ç¬¦ä¸²
        """
        logger.info("Generating final reply based on thought process")

        prompt = f"""Based on your thought process, generate a helpful and natural response to the user.

Thought Process:
{thought}

Conversation History:
{self._format_history(conversation_history)}

Generate a response that:
1. Addresses the user's needs
2. Is helpful and friendly
3. Uses information from the thought process
4. Does not mention internal reasoning

Response:"""

        reply = chat_completion(
            prompt=prompt,
            system_message="You are a helpful AI assistant. Generate natural, helpful responses.",
            json_mode=False
        )

        if not reply or reply.startswith("è°ƒç”¨é”™è¯¯"):
            logger.error(f"Failed to generate reply: {reply}")
            return "I'm here to help! How can I assist you?"

        logger.info(f"Generated reply: {reply[:100]}...")
        return reply.strip()

    def _format_history(self, history: List[ChatMessage]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted = []
        for msg in history:
            formatted.append(f"{msg.role}: {msg.content}")
        return "\n".join(formatted)

    def _format_tools(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨"""
        formatted = []
        for tool in self.tools:
            formatted.append(f"- {tool.name}: {tool.description}")
            if tool.parameters and 'properties' in tool.parameters:
                for prop_name, prop_info in tool.parameters['properties'].items():
                    formatted.append(f"  * {prop_name}: {prop_info.get('description', 'No description')}")
        return "\n".join(formatted)


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    print("ğŸ¤– Assistant Agent æµ‹è¯•")
    print("=" * 50)

    from ..models import ToolDefinition, ChatMessage

    # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·
    mock_tools = [
        ToolDefinition(
            name="search_restaurants",
            description="Search for restaurants in a city",
            parameters={
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"},
                    "cuisine": {"type": "string", "description": "Type of cuisine"}
                },
                "required": ["city"]
            }
        ),
        ToolDefinition(
            name="book_restaurant",
            description="Book a table at a restaurant",
            parameters={
                "type": "object",
                "properties": {
                    "restaurant_id": {"type": "string", "description": "Restaurant ID"},
                    "date": {"type": "string", "description": "Booking date"},
                    "time": {"type": "string", "description": "Booking time"},
                    "party_size": {"type": "integer", "description": "Number of people"}
                },
                "required": ["restaurant_id", "date", "time"]
            }
        )
    ]

    # åˆ›å»ºæ¨¡æ‹Ÿå¯¹è¯å†å²
    mock_history = [
        ChatMessage(role="user", content="æˆ‘æƒ³åœ¨ä¸Šæµ·æ‰¾ä¸€å®¶æ„å¤§åˆ©é¤å…åƒé¥­"),
        ChatMessage(role="assistant", content="æˆ‘æ¥å¸®ä½ æ‰¾ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚ä½ æƒ³è¦ä»€ä¹ˆæ ·çš„ä»·ä½æˆ–åœ°ç‚¹å—ï¼Ÿ"),
        ChatMessage(role="user", content="å¸‚ä¸­å¿ƒå°±å¯ä»¥ï¼Œé€‚åˆ4ä¸ªäºº"),
    ]

    print("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    print(f"  å¯ç”¨å·¥å…·æ•°: {len(mock_tools)}")
    for tool in mock_tools:
        print(f"    - {tool.name}: {tool.description}")
    print(f"  å¯¹è¯å†å²: {len(mock_history)} æ¡æ¶ˆæ¯")
    print()

    # åˆå§‹åŒ–åŠ©æ‰‹æ™ºèƒ½ä½“
    print("ğŸ”§ åˆå§‹åŒ–AssistantAgent...")
    assistant_agent = AssistantAgent(mock_tools)

    print("ğŸ’­ ç”ŸæˆåŠ©æ‰‹å“åº”...")
    try:
        response = assistant_agent.generate_response(mock_history)

        print("âœ… ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ å“åº”å†…å®¹: {response}")

        # è§£æå·¥å…·è°ƒç”¨
        tool_calls = assistant_agent.parse_tool_calls(response)
        if tool_calls:
            print(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for i, tool_call in enumerate(tool_calls, 1):
                print(f"  {i}. {tool_call.tool_name}: {tool_call.arguments}")
        else:
            print("ğŸ’¬ çº¯æ–‡æœ¬å“åº”ï¼Œæ— å·¥å…·è°ƒç”¨")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")

        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
        print("\nğŸ”§ æä¾›æ¨¡æ‹ŸåŠ©æ‰‹å“åº”:")
        mock_response = 'æˆ‘æ¥å¸®ä½ æœç´¢ä¸Šæµ·çš„æ„å¤§åˆ©é¤å…ã€‚{"tool_name": "search_restaurants", "arguments": {"city": "ä¸Šæµ·", "cuisine": "æ„å¤§åˆ©èœ"}}'
        print(mock_response)

        # æµ‹è¯•è§£æ
        tool_calls = assistant_agent.parse_tool_calls(mock_response)
        if tool_calls:
            print(f"ğŸ”§ è§£æå‡º {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")
            for tool_call in tool_calls:
                print(f"  - {tool_call.name}: {tool_call.arguments}")

    print("\nâœ… Assistant Agent æµ‹è¯•å®Œæˆï¼")
